{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54ec254e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from copy import deepcopy\n",
    "import regex as re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from importlib import reload\n",
    "import cleaning as c\n",
    "import logs\n",
    "import configs\n",
    "import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e551b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rimov/anaconda3/envs/que_drop/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "940ccd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'auxiliary'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('aux')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5e8df44",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs.setup_logger('tidy-cleaning',\n",
    "                  desc='Id duplication checks added to TwitterData. Continuing work on standardizing cleaning section.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3fe6e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'files' from '/home/rimov/Documents/Code/NLP/lin-que-dropping/src/utils/files.py'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Reload changed modules without restarting kernel \"\"\"\n",
    "reload(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "390d7156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration files\n",
    "gen_conf = configs.read_conf()\n",
    "conf = configs.read_conf('c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea75b6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose from the available folders, comma-separated (or \"a\" for all):\n",
      "0. 26072021-at-1905\n",
      "1. 07072021-at-1050\n",
      "2. 2023-02-08-at-23:05:39\n",
      "3. 26072021-at-2345\n",
      "4. 2023-02-22-at-18:46:25\n",
      "5. 07112021-at-2210\n",
      "6. 26072021-at-1546\n",
      "7. 2023-02-22-at-18:13:40\n",
      "Return folder(s): 4\n"
     ]
    }
   ],
   "source": [
    "# Extracted folder to clean\n",
    "e_path = files.get_saved_data_path('e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81b519e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-02-22-at-18:46:25'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_name = e_path[0].stem\n",
    "e_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0b80f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the verb conjugations\n",
    "conjug_es = files.get_verb_conjugations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f2f59d",
   "metadata": {},
   "source": [
    "### Organize Extracted Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6e6acb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/rimov/Documents/Code/NLP/lin-que-dropping/data/cleaned/saved/twitter/es/2023-02-22-at-18:46:25')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_path = files.get_save_path('c', 'twitter')/f'{e_name}'\n",
    "files.make_dir(files.get_save_path('c', 'twitter'), e_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212deb1e",
   "metadata": {},
   "source": [
    "if conf['flags']['separate_by_verb']:\n",
    "    logger.info('Creating separate verb directories')\n",
    "    for v in conjug_es['verb'].values:\n",
    "        try:\n",
    "            utils.make_dir(cleaned_path, v)\n",
    "        except:\n",
    "            logger.exception(f'Couldn\\'t create directory for \"{v}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af5eaf4",
   "metadata": {},
   "source": [
    "if conf['flags']['separate_by_verb']:\n",
    "    # MODIFY AS NEEDED\n",
    "    verb_pat = conf['verb_pat_corpes']\n",
    "    \n",
    "    for folder in extracted_folders:\n",
    "        p = extracted_path/folder\n",
    "        logger.info(f'Copying files from {p}')\n",
    "        \n",
    "        for file in p.iterdir():\n",
    "            match = regex.search(verb_pat, file.name)\n",
    "            v = match['keyword'].lower().strip()\n",
    "            \n",
    "            try:\n",
    "                new_name = file.name.replace(' ', '')\n",
    "                shutil.copyfile(file, cleaned_path/v/new_name)\n",
    "            except FileNotFoundError as fe:\n",
    "                logger.exception(fe.args)\n",
    "                logger.exception(f'Probably no directory for verb: {v}')\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad93329e",
   "metadata": {},
   "source": [
    "### Cleaning Users\n",
    "\n",
    "#### TODO: create cleaning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "323ed255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(conf['flags']['clean_users'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "77f64883",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f57ce21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "56afa58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if conf['flags']['clean_users']:\n",
    "    logger.info(f'Marked to clean users.')\n",
    "    \n",
    "    cleaned = cleaning.folder_dup_clean(\n",
    "        cleaned=cleaned, \n",
    "        path=dir_cleaned, \n",
    "        file_identifier='users', \n",
    "        dup_subset='user_id', \n",
    "        file_csv_sep='~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "34ac105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f'Cleaned {len(cleaned)} user folders.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef82c436",
   "metadata": {},
   "outputs": [],
   "source": [
    "if conf['flags']['clean_users'] is True:\n",
    "    try:\n",
    "        conf['flags']['clean_users'] = False\n",
    "        conf = utils.get_updated_config(conf, \n",
    "                                        utils.get_project_root()\\\n",
    "                                          /'cleaning'/'cleaning_config.yml')\n",
    "    except Exception as e:\n",
    "        logger.exception(f'Failed to write config file! {e.args}')\n",
    "    finally:\n",
    "        logger.info('CONFIG UPDATED: flags.clean_users=False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eeff08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0cfa116",
   "metadata": {},
   "source": [
    "### Cleaning Places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "660f7387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "os.chdir(dir_cleaned)\n",
    "\n",
    "print(conf['flags']['clean_places'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d87e96af",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "afcd88d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5ab01b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "if conf['flags']['clean_places']:\n",
    "    logger.info(f'Marked to clean places.')\n",
    "    \n",
    "    cleaned = cleaning.folder_dup_clean(\n",
    "        cleaned=cleaned, \n",
    "        path=dir_cleaned, \n",
    "        file_identifier='places', \n",
    "        dup_subset='place_id', \n",
    "        file_csv_sep='~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "03e3c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f'Cleaned {len(cleaned)} place folders.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f4d5453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if conf['flags']['clean_places'] is True:\n",
    "    try:\n",
    "        conf['flags']['clean_places'] = False\n",
    "        conf = utils.get_updated_config(conf, \n",
    "                                        utils.get_project_root()\\\n",
    "                                          /'cleaning'/'cleaning_config.yml')\n",
    "    except Exception as e:\n",
    "        logger.exception(f'Failed to write config file! {e.args}')\n",
    "    finally:\n",
    "        logger.info('CONFIG UPDATED: flags.clean_places=False')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92c1e57",
   "metadata": {},
   "source": [
    "### Cleaning Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "872cab11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "os.chdir(dir_cleaned)\n",
    "\n",
    "print(conf['flags']['clean_meta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4afeb071",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "be9cd830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d60bb782",
   "metadata": {},
   "outputs": [],
   "source": [
    "if conf['flags']['clean_meta']:\n",
    "    logger.info(f'Marked to clean metadata.')\n",
    "    \n",
    "    cleaned = cleaning.folder_dup_clean(\n",
    "        cleaned=cleaned, \n",
    "        path=dir_cleaned, \n",
    "        file_identifier='twitterdata', \n",
    "        dup_subset='resource_id', \n",
    "        file_csv_sep='~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5bbc2c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f'Cleaned {len(cleaned)} meta folders.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f2d6d339",
   "metadata": {},
   "outputs": [],
   "source": [
    "if conf['flags']['clean_meta'] is True:\n",
    "    try:\n",
    "        conf['flags']['clean_meta'] = False\n",
    "        conf = utils.get_updated_config(conf, \n",
    "                                        utils.get_project_root()\\\n",
    "                                          /'cleaning'/'cleaning_config.yml')\n",
    "    except Exception as e:\n",
    "        logger.exception(f'Failed to write config file! {e.args}')\n",
    "    finally:\n",
    "        logger.info('CONFIG UPDATED: flags.clean_meta=False')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2849e9b6",
   "metadata": {},
   "source": [
    "### Cleaning Tweets\n",
    "\n",
    "## TODO: \n",
    "author_id -> user_id in tweets<br>\n",
    "format mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979298dc",
   "metadata": {},
   "source": [
    "#### Removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dd5f4f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "os.chdir(dir_cleaned)\n",
    "\n",
    "print(conf['flags']['clean_dups'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "309c42b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9afe2616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b001ab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if conf['flags']['clean_dups']:\n",
    "    logger.info(f'Marked to clean tweets.')\n",
    "    \n",
    "    cleaned = cleaning.folder_dup_clean(\n",
    "        cleaned=cleaned, \n",
    "        path=dir_cleaned, \n",
    "        delete_original=True,\n",
    "        file_identifier='tweets', \n",
    "        dup_subset='tweet_id', \n",
    "        file_csv_sep='~',\n",
    "        batch=False,\n",
    "        batch_size=1000,\n",
    "        name_scheme='original-tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b6f0af03",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f'Cleaned {len(cleaned)} tweet folders.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0f22a127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(436577, 0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0982e69",
   "metadata": {},
   "source": [
    "#### NOTE: \n",
    "Above steps only remove duplicates within the partitioned folders, not across them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fca7fe",
   "metadata": {},
   "source": [
    "## TODO: \n",
    "clean 'mentions' column <br>\n",
    "drop some entries with null values (eg. null author_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1a6c5b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'retweet_reply_like_quote': ['public_metrics.retweet_count', 'public_metrics.reply_count', 'public_metrics.like_count', 'public_metrics.quote_count']}\n",
      "['geo.coordinates.type', 'geo.coordinates.coordinates', 'public_metrics.retweet_count', 'public_metrics.reply_count', 'public_metrics.like_count', 'public_metrics.quote_count']\n"
     ]
    }
   ],
   "source": [
    "print(conf['clean']['tweet_combine_col_map'])\n",
    "print(conf['clean']['drop_cols'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "954830ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df, combine_col_map:dict, drop_cols:list) -> pd.DataFrame:\n",
    "    \n",
    "    try:\n",
    "        # Reformat 'referenced_tweets' column\n",
    "        df['referenced_tweets'] = df['referenced_tweets'].str.findall(r'\\'id\\': \\'(\\d+)')\n",
    "        \n",
    "        # Convert dates to datetime object\n",
    "        df['created_at'] = pd.to_datetime(df['created_at'], format='%Y-%m-%dT%H:%M:%S', errors='coerce')\n",
    "        \n",
    "        for col_map in combine_col_map.items():\n",
    "            # Combine public metrics into 1 column\n",
    "            df[col_map[0]] = df.apply(cleaning.combine_cols, axis=1, cols=col_map[1])\n",
    "        \n",
    "        df.drop(drop_cols, axis=1, inplace=True, errors='ignore')\n",
    "        \n",
    "    except ValueError as ve:\n",
    "        nat = time[time.isnull()]\n",
    "        \n",
    "        logging.debug(f'Failed to convert:\\n{nat}\\n to datetime')\n",
    "        \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d5cb40da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "10e22a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b435940a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if conf['flags']['clean_table']:\n",
    "    for folder in Path('.').iterdir():\n",
    "        if folder in cleaned:\n",
    "            logging.debug(f'({folder}) is clean')\n",
    "            continue\n",
    "            \n",
    "        logging.info(f'Cleaning ({folder})')\n",
    "        \n",
    "        try:\n",
    "            path = next(Path(folder).rglob('*tweets*.csv'))\n",
    "            tweets = pd.read_csv(path, sep='~', lineterminator='\\n')\n",
    "            \n",
    "            df_clean = clean(tweets.copy(), \n",
    "                             conf['clean']['tweet_combine_col_map'], \n",
    "                             conf['clean']['drop_cols'])\n",
    "            \n",
    "            utils.save_csv(path.parent, \n",
    "                           df_clean, \n",
    "                           f'{folder}-cleaned-original-tweets')\n",
    "            \n",
    "        except StopIteration as si:\n",
    "            logging.exception(f'Folder ({folder}) has no tweets file')\n",
    "            continue\n",
    "        \n",
    "        cleaned.add(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b1dc27bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if conf['flags']['clean_table'] is True:\n",
    "    try:\n",
    "        conf['flags']['clean_table'] = False\n",
    "        conf = utils.get_updated_config(conf, \n",
    "                                           utils.get_project_root()\\\n",
    "                                             /'cleaning'/'cleaning_config.yml')\n",
    "    except Exception as e:\n",
    "        logger.exception(f'Failed to write config file! {e.args}')\n",
    "    finally:\n",
    "        logger.info('CONFIG UPDATED: flags.clean_table=False')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b80f330",
   "metadata": {},
   "source": [
    "### Checking for Query Match\n",
    "\n",
    "Verify that the query term was used in retrieving tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "49cc5539",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "885169d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[0m\u001B[01;34macordar\u001B[0m/    \u001B[01;34mconfesar\u001B[0m/    \u001B[01;34mdudar\u001B[0m/     \u001B[01;34mmandar\u001B[0m/     \u001B[01;34mpedir\u001B[0m/       \u001B[01;34mresponder\u001B[0m/  \u001B[01;34mtemer\u001B[0m/\r\n",
      "\u001B[01;34madivinar\u001B[0m/   \u001B[01;34mconfirmar\u001B[0m/   \u001B[01;34mentender\u001B[0m/  \u001B[01;34mmencionar\u001B[0m/  \u001B[01;34mpredecir\u001B[0m/    \u001B[01;34mrogar\u001B[0m/\r\n",
      "\u001B[01;34madmitir\u001B[0m/    \u001B[01;34mconseguir\u001B[0m/   \u001B[01;34mgritar\u001B[0m/    \u001B[01;34mmostrar\u001B[0m/    \u001B[01;34mprever\u001B[0m/      \u001B[01;34msentir\u001B[0m/\r\n",
      "\u001B[01;34mafirmar\u001B[0m/    \u001B[01;34mconsiderar\u001B[0m/  \u001B[01;34mimaginar\u001B[0m/  \u001B[01;34mnegar\u001B[0m/      \u001B[01;34mprometer\u001B[0m/    \u001B[01;34msolicitar\u001B[0m/\r\n",
      "\u001B[01;34mapostar\u001B[0m/    \u001B[01;34mcontar\u001B[0m/      \u001B[01;34mjurar\u001B[0m/     \u001B[01;34mojala\u001B[0m/      \u001B[01;34mreclamar\u001B[0m/    \u001B[01;34msuplicar\u001B[0m/\r\n",
      "\u001B[01;34masegurar\u001B[0m/   \u001B[01;34mdemostrar\u001B[0m/   \u001B[01;34mlamentar\u001B[0m/  \u001B[01;34mordenar\u001B[0m/    \u001B[01;34mrecomendar\u001B[0m/  \u001B[01;34msuponer\u001B[0m/\r\n",
      "\u001B[01;34mcomprobar\u001B[0m/  \u001B[01;34mdesear\u001B[0m/      \u001B[01;34mlograr\u001B[0m/    \u001B[01;34mparecer\u001B[0m/    \u001B[01;34mrecordar\u001B[0m/    \u001B[01;34msuspirar\u001B[0m/\r\n"
     ]
    }
   ],
   "source": [
    "os.chdir(utils.get_save_path('c', lang='es', is_test=False)/extracted_save_folders[0])\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "74a9f302",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_230557/3720025898.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  indicatives['indicativo'] = indicatives.loc[:, 'indicativo'].apply(unidecode)\n"
     ]
    }
   ],
   "source": [
    "indicatives = es_verbs_conjug[['verb', 'indicativo']]\n",
    "indicatives['indicativo'] = indicatives.loc[:, 'indicativo'].apply(unidecode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bf50f976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def purify_text(tweet):\n",
    "    purified = tweet.strip().lower()\n",
    "    pat_punct = r'[^\\w\\d\\s]+'\n",
    "    pat_space = r'\\s+'\n",
    "    \n",
    "    purified = regex.sub(pat_punct, '', purified)\n",
    "    purified = regex.sub(pat_space, ' ', purified)\n",
    "    return set(purified.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "de25cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_conjug(tweet, *conjugs):\n",
    "    intersect = tweet.intersection(conjugs)\n",
    "    \n",
    "    return len(intersect)>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9a97f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "extr_conf = utils.get_config(utils.get_project_root()/'extraction'/'extraction_config.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "047889cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'creer', 'decir', 'esperar', 'pensar', 'querer', 'saber', 'ver'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned = set(extr_conf['filled_verbs'])\n",
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "32fae760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(confirmar) yielded: 4751 out of 4801\n",
      "(dudar) yielded: 20420 out of 20723\n",
      "(suplicar) yielded: 291 out of 295\n",
      "(parecer) yielded: 47629 out of 48102\n",
      "(solicitar) yielded: 1703 out of 1708\n",
      "(afirmar) yielded: 1194 out of 1218\n",
      "(temer) yielded: 1880 out of 1915\n",
      "(mencionar) yielded: 2641 out of 2660\n",
      "(suspirar) yielded: 356 out of 360\n",
      "(contar) yielded: 49848 out of 50293\n",
      "(prometer) yielded: 3907 out of 3956\n",
      "(jurar) yielded: 6272 out of 6357\n",
      "(admitir) yielded: 917 out of 926\n",
      "(rogar) yielded: 955 out of 987\n",
      "(asegurar) yielded: 2754 out of 2778\n",
      "(comprobar) yielded: 1109 out of 1125\n",
      "(mostrar) yielded: 6907 out of 6956\n",
      "(conseguir) yielded: 6665 out of 6721\n",
      "(recomendar) yielded: 4736 out of 4772\n",
      "(lamentar) yielded: 2133 out of 2165\n",
      "(apostar) yielded: 2889 out of 2923\n",
      "(predecir) yielded: 152 out of 154\n",
      "(desear) yielded: 11285 out of 11389\n",
      "(pedir) yielded: 26506 out of 26685\n",
      "(acordar) yielded: 28703 out of 28966\n",
      "(sentir) yielded: 50036 out of 50282\n",
      "(adivinar) yielded: 772 out of 790\n",
      "(suponer) yielded: 12790 out of 12963\n",
      "(gritar) yielded: 4179 out of 4238\n",
      "(negar) yielded: 3376 out of 3416\n",
      "(reclamar) yielded: 2568 out of 2621\n",
      "(ojala) yielded: 32 out of 34\n",
      "(lograr) yielded: 9550 out of 9605\n",
      "(ordenar) yielded: 1335 out of 1355\n",
      "(recordar) yielded: 18079 out of 18270\n",
      "(demostrar) yielded: 6274 out of 6325\n",
      "(entender) yielded: 37403 out of 37720\n",
      "(considerar) yielded: 4004 out of 4013\n",
      "(confesar) yielded: 891 out of 905\n",
      "(responder) yielded: 7813 out of 7982\n",
      "(imaginar) yielded: 11552 out of 11675\n",
      "(mandar) yielded: 24208 out of 24410\n",
      "(prever) yielded: 1030 out of 1038\n"
     ]
    }
   ],
   "source": [
    "matching_tweets = dict()\n",
    "\n",
    "for folder in Path('.').iterdir():\n",
    "    if folder in cleaned:\n",
    "        logging.debug(f'({folder}) is clean')\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    logging.info(f'Counting properly matched queries in: ({folder})')\n",
    "    \n",
    "    match = indicatives['verb']==str(folder)\n",
    "    conjugs = indicatives[match]['indicativo'].str.split().to_numpy()[0]\n",
    "    conjugs = set(conjugs)\n",
    "    \n",
    "    try:\n",
    "        path = next(Path(folder).rglob('*cleaned*tweets*.csv'))\n",
    "        tweets = pd.read_csv(path, sep='~', lineterminator='\\n')['text_norm']\n",
    "        tweets = tweets.apply(purify_text)\n",
    "        \n",
    "        has_conjug = tweets.apply(check_conjug, args=(conjugs)).rename('has_conjug')\n",
    "        matching_tweets[folder] = has_conjug.sum()\n",
    "        \n",
    "        print(f'({folder}) yielded: {has_conjug.sum()} out of {tweets.shape[0]}')\n",
    "        \n",
    "    except StopIteration as si:\n",
    "        logging.exception(f'Folder ({folder}) has no tweets file')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aed206",
   "metadata": {},
   "source": [
    "### Merging whole query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b12752b",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "Generalize above and below duplication finding steps and add to cleaning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "410a597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_save_dir = utils.get_save_path('c', is_test=False, lang='es')\n",
    "os.chdir(es_save_dir)\n",
    "\n",
    "utils.make_dir(es_save_dir/f'{extracted_save_folders[0]}-combined')\n",
    "os.chdir(es_save_dir/f'{extracted_save_folders[0]}-combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e8785cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_paths = Path(dir_cleaned).rglob('*cleaned*tweets*.csv')\n",
    "user_paths = Path(dir_cleaned).rglob('*users*.csv')\n",
    "places_paths = Path(dir_cleaned).rglob('*places*.csv')\n",
    "meta_paths = Path(dir_cleaned).rglob('*twitterdata*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ecac21d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.concat([pd.read_csv(p, sep='~') for p in user_paths]).reset_index(drop=True)\n",
    "places = pd.concat([pd.read_csv(p, sep='~') for p in places_paths]).reset_index(drop=True)\n",
    "meta = pd.concat([pd.read_csv(p, sep='~') for p in meta_paths]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "70c30dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 671167 entries, 0 to 671166\n",
      "Data columns (total 10 columns):\n",
      " #   Column                          Non-Null Count   Dtype \n",
      "---  ------                          --------------   ----- \n",
      " 0   name                            671124 non-null  object\n",
      " 1   username                        671167 non-null  object\n",
      " 2   user_id                         671167 non-null  int64 \n",
      " 3   created_at                      671167 non-null  object\n",
      " 4   user_location                   493598 non-null  object\n",
      " 5   public_metrics.followers_count  671167 non-null  int64 \n",
      " 6   public_metrics.following_count  671167 non-null  int64 \n",
      " 7   public_metrics.tweet_count      671167 non-null  int64 \n",
      " 8   public_metrics.listed_count     671167 non-null  int64 \n",
      " 9   withheld.country_codes          3 non-null       object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 51.2+ MB\n"
     ]
    }
   ],
   "source": [
    "users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e8a87a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64790 entries, 0 to 64789\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   country             64789 non-null  object\n",
      " 1   location_full_name  64790 non-null  object\n",
      " 2   place_id            64790 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "places.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "47560974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105 entries, 0 to 104\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   value          105 non-null    object\n",
      " 1   detail         105 non-null    object\n",
      " 2   title          105 non-null    object\n",
      " 3   resource_type  105 non-null    object\n",
      " 4   parameter      105 non-null    object\n",
      " 5   resource_id    105 non-null    object\n",
      " 6   type           105 non-null    object\n",
      "dtypes: object(7)\n",
      "memory usage: 5.9+ KB\n"
     ]
    }
   ],
   "source": [
    "meta.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d9ee1043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 436577 entries, 0 to 436576\n",
      "Data columns (total 10 columns):\n",
      " #   Column                    Non-Null Count   Dtype \n",
      "---  ------                    --------------   ----- \n",
      " 0   created_at                436577 non-null  object\n",
      " 1   text_orig                 436577 non-null  object\n",
      " 2   author_id                 436577 non-null  int64 \n",
      " 3   lang                      436577 non-null  object\n",
      " 4   tweet_id                  436577 non-null  int64 \n",
      " 5   tweet_place_id            436573 non-null  object\n",
      " 6   referenced_tweets         271143 non-null  object\n",
      " 7   mentions                  278317 non-null  object\n",
      " 8   text_norm                 436577 non-null  object\n",
      " 9   retweet_reply_like_quote  436577 non-null  object\n",
      "dtypes: int64(2), object(8)\n",
      "memory usage: 33.3+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets = pd.concat([pd.read_csv(p, sep='~', lineterminator='\\n') for p in tweet_paths]).reset_index(drop=True)\n",
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7a87f752",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dups = users.duplicated(subset='user_id')\n",
    "place_dups = places.duplicated(subset='place_id')\n",
    "meta_dups = meta.duplicated(subset='resource_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1ddb271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_dups = tweets.duplicated(subset='tweet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "31a8658e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dups_total = user_dups.sum()\n",
    "place_dups_total = place_dups.sum()\n",
    "meta_dups_total = meta_dups.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e48992e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_dups_total = tweet_dups.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cd36f9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28213 373131 53732 24\n"
     ]
    }
   ],
   "source": [
    "print(tweet_dups_total, user_dups_total, place_dups_total, meta_dups_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1b66d46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "users.drop(users[user_dups].index, inplace=True)\n",
    "places.drop(places[place_dups].index, inplace=True)\n",
    "meta.drop(meta[meta_dups].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4a730c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.drop(tweets[tweet_dups].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9e4dee54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408364 298036 11058 81\n"
     ]
    }
   ],
   "source": [
    "print(tweets.shape[0], users.shape[0], places.shape[0], meta.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "527ead2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_csv(Path('.'), tweets, 'tweets')\n",
    "utils.save_csv(Path('.'), users, 'users')\n",
    "utils.save_csv(Path('.'), places, 'places')\n",
    "utils.save_csv(Path('.'), meta, 'twitterdata')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc822c5",
   "metadata": {},
   "source": [
    "#### Mark flagged accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4f899964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flagged_users = set(meta['value'])\n",
    "\n",
    "flagged = users['username'].isin(flagged_users)\n",
    "flagged.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6244e463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>username</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_location</th>\n",
       "      <th>public_metrics.followers_count</th>\n",
       "      <th>public_metrics.following_count</th>\n",
       "      <th>public_metrics.tweet_count</th>\n",
       "      <th>public_metrics.listed_count</th>\n",
       "      <th>withheld.country_codes</th>\n",
       "      <th>flagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reztre🎄</td>\n",
       "      <td>Reztre</td>\n",
       "      <td>141323312</td>\n",
       "      <td>2010-05-07T19:44:51.000Z</td>\n",
       "      <td>Pereira, Risaralda</td>\n",
       "      <td>1016</td>\n",
       "      <td>687</td>\n",
       "      <td>27049</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carmen</td>\n",
       "      <td>carmen_flurry</td>\n",
       "      <td>49454158</td>\n",
       "      <td>2009-06-21T22:42:22.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2533</td>\n",
       "      <td>3425</td>\n",
       "      <td>158751</td>\n",
       "      <td>79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Karla Peregrina</td>\n",
       "      <td>karlapo</td>\n",
       "      <td>26833188</td>\n",
       "      <td>2009-03-26T19:54:35.000Z</td>\n",
       "      <td>Cancún, Q. Roo / CDMX</td>\n",
       "      <td>818</td>\n",
       "      <td>1760</td>\n",
       "      <td>6112</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gabriela Damián Miravete</td>\n",
       "      <td>gabrielintica</td>\n",
       "      <td>146562887</td>\n",
       "      <td>2010-05-21T19:15:47.000Z</td>\n",
       "      <td>Falso Bosque</td>\n",
       "      <td>9164</td>\n",
       "      <td>3530</td>\n",
       "      <td>36661</td>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rebeca Jiménez Calero</td>\n",
       "      <td>rebecajc</td>\n",
       "      <td>157111888</td>\n",
       "      <td>2010-06-18T22:16:20.000Z</td>\n",
       "      <td>México, D.F.</td>\n",
       "      <td>1845</td>\n",
       "      <td>1610</td>\n",
       "      <td>36772</td>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name       username    user_id  \\\n",
       "0                   Reztre🎄         Reztre  141323312   \n",
       "1                    Carmen  carmen_flurry   49454158   \n",
       "2           Karla Peregrina        karlapo   26833188   \n",
       "3  Gabriela Damián Miravete  gabrielintica  146562887   \n",
       "4     Rebeca Jiménez Calero       rebecajc  157111888   \n",
       "\n",
       "                 created_at          user_location  \\\n",
       "0  2010-05-07T19:44:51.000Z     Pereira, Risaralda   \n",
       "1  2009-06-21T22:42:22.000Z                    NaN   \n",
       "2  2009-03-26T19:54:35.000Z  Cancún, Q. Roo / CDMX   \n",
       "3  2010-05-21T19:15:47.000Z           Falso Bosque   \n",
       "4  2010-06-18T22:16:20.000Z           México, D.F.   \n",
       "\n",
       "   public_metrics.followers_count  public_metrics.following_count  \\\n",
       "0                            1016                             687   \n",
       "1                            2533                            3425   \n",
       "2                             818                            1760   \n",
       "3                            9164                            3530   \n",
       "4                            1845                            1610   \n",
       "\n",
       "   public_metrics.tweet_count  public_metrics.listed_count  \\\n",
       "0                       27049                           13   \n",
       "1                      158751                           79   \n",
       "2                        6112                            8   \n",
       "3                       36661                          105   \n",
       "4                       36772                           47   \n",
       "\n",
       "  withheld.country_codes  flagged  \n",
       "0                    NaN    False  \n",
       "1                    NaN    False  \n",
       "2                    NaN    False  \n",
       "3                    NaN    False  \n",
       "4                    NaN    False  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users['flagged'] = flagged\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2005e379",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_csv(Path('.'), users, 'users')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbcfef9",
   "metadata": {},
   "source": [
    "### Checking against previous pulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5e281af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_save_folder = ['combined']\n",
    "es_save_path = utils.get_save_path('c', lang='es')/'20210726'/es_save_folder[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "17f6c73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rimov/anaconda3/envs/nlp/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3169: DtypeWarning: Columns (9) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "prev_tweets = pd.read_csv(es_save_path/'tweets.csv', sep='~')\n",
    "prev_users = pd.read_csv(es_save_path/'users.csv', sep='~')\n",
    "prev_places = pd.read_csv(es_save_path/'places.csv', sep='~')\n",
    "prev_meta = pd.read_csv(es_save_path/'twitterdata.csv', sep='~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "88fc8a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 560093 entries, 0 to 560092\n",
      "Data columns (total 10 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   created_at                560089 non-null  object \n",
      " 1   lang                      560091 non-null  object \n",
      " 2   author_id                 560087 non-null  float64\n",
      " 3   referenced_tweets         353987 non-null  object \n",
      " 4   tweet_id                  560088 non-null  float64\n",
      " 5   text_orig                 560090 non-null  object \n",
      " 6   mentions                  366625 non-null  object \n",
      " 7   place_id                  560067 non-null  object \n",
      " 8   text_norm                 560090 non-null  object \n",
      " 9   retweet_reply_like_quote  560088 non-null  object \n",
      "dtypes: float64(2), object(8)\n",
      "memory usage: 42.7+ MB\n"
     ]
    }
   ],
   "source": [
    "prev_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "75661e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename non-matching columns\n",
    "prev_tweets.rename(columns={'place_id': 'tweet_place_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ca7dc400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 327265 entries, 0 to 327264\n",
      "Data columns (total 11 columns):\n",
      " #   Column                          Non-Null Count   Dtype \n",
      "---  ------                          --------------   ----- \n",
      " 0   name                            327234 non-null  object\n",
      " 1   author_id                       327265 non-null  int64 \n",
      " 2   username                        327265 non-null  object\n",
      " 3   created_at                      327265 non-null  object\n",
      " 4   user_location                   230091 non-null  object\n",
      " 5   public_metrics.followers_count  327265 non-null  int64 \n",
      " 6   public_metrics.following_count  327265 non-null  int64 \n",
      " 7   public_metrics.tweet_count      327265 non-null  int64 \n",
      " 8   public_metrics.listed_count     327265 non-null  int64 \n",
      " 9   withheld.country_codes          3 non-null       object\n",
      " 10  flagged                         327265 non-null  bool  \n",
      "dtypes: bool(1), int64(5), object(5)\n",
      "memory usage: 25.3+ MB\n"
     ]
    }
   ],
   "source": [
    "prev_users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e7157a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename non-matching columns\n",
    "prev_users.rename(columns={'author_id': 'user_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f10c6b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14381 entries, 0 to 14380\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   country   14377 non-null  object\n",
      " 1   location  14381 non-null  object\n",
      " 2   place_id  14381 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 337.2+ KB\n"
     ]
    }
   ],
   "source": [
    "prev_places.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "dfed41a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename non-matching columns\n",
    "prev_places.rename(columns={'location': 'location_full_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "aa2d899a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1035 entries, 0 to 1034\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   parameter      1035 non-null   object\n",
      " 1   resource_id    1035 non-null   object\n",
      " 2   value          1035 non-null   object\n",
      " 3   detail         1035 non-null   object\n",
      " 4   title          1035 non-null   object\n",
      " 5   resource_type  1035 non-null   object\n",
      " 6   type           1035 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 56.7+ KB\n"
     ]
    }
   ],
   "source": [
    "prev_meta.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a87e6dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 968457 entries, 0 to 968456\n",
      "Data columns (total 10 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   created_at                968453 non-null  object \n",
      " 1   text_orig                 968454 non-null  object \n",
      " 2   author_id                 968451 non-null  float64\n",
      " 3   lang                      968455 non-null  object \n",
      " 4   tweet_id                  968452 non-null  float64\n",
      " 5   tweet_place_id            968427 non-null  object \n",
      " 6   referenced_tweets         607203 non-null  object \n",
      " 7   mentions                  626598 non-null  object \n",
      " 8   text_norm                 968454 non-null  object \n",
      " 9   retweet_reply_like_quote  968452 non-null  object \n",
      "dtypes: float64(2), object(8)\n",
      "memory usage: 73.9+ MB\n"
     ]
    }
   ],
   "source": [
    "merged_tweets = pd.concat([tweets, prev_tweets], axis=0).reset_index(drop=True)\n",
    "merged_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "33f98d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_users = pd.concat([users, prev_users], axis=0).reset_index(drop=True)\n",
    "merged_places = pd.concat([places, prev_places], axis=0).reset_index(drop=True)\n",
    "merged_meta = pd.concat([meta, prev_meta], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8ea840c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dups = merged_users.duplicated(subset='user_id')\n",
    "place_dups = merged_places.duplicated(subset='place_id')\n",
    "meta_dups = merged_meta.duplicated(subset='resource_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1baf7e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_dups = merged_tweets.duplicated(subset='tweet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c9c17952",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dups_total = user_dups.sum()\n",
    "place_dups_total = place_dups.sum()\n",
    "meta_dups_total = meta_dups.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a112bcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_dups_total = tweet_dups.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "10bdd88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88356 96125 7147 12\n"
     ]
    }
   ],
   "source": [
    "print(tweet_dups_total, user_dups_total, place_dups_total, meta_dups_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "61a72333",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_users.drop(merged_users[user_dups].index, inplace=True)\n",
    "merged_places.drop(merged_places[place_dups].index, inplace=True)\n",
    "merged_meta.drop(merged_meta[meta_dups].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a65417cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_tweets.drop(merged_tweets[tweet_dups].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fe841026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880101 529176 18292 1104\n"
     ]
    }
   ],
   "source": [
    "print(merged_tweets.shape[0], merged_users.shape[0], merged_places.shape[0], merged_meta.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c1bcb5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_csv(Path('.'), tweets, 'tweets')\n",
    "utils.save_csv(Path('.'), users, 'users')\n",
    "utils.save_csv(Path('.'), places, 'places')\n",
    "utils.save_csv(Path('.'), meta, 'twitterdata')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca623b4",
   "metadata": {},
   "source": [
    "#### Separate and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "69e48494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets: 408362, users: 201911, places: 3911, meta: 69\n"
     ]
    }
   ],
   "source": [
    "new_tweets = ~merged_tweets['tweet_id'].isin(prev_tweets['tweet_id'])\n",
    "new_users = ~merged_users['user_id'].isin(prev_users['user_id'])\n",
    "new_places = ~merged_places['place_id'].isin(prev_places['place_id'])\n",
    "new_meta = ~merged_meta['resource_id'].isin(prev_meta['resource_id'])\n",
    "print(f'tweets: {new_tweets.sum()}, users: {new_users.sum()}, places: {new_places.sum()}, meta: {new_meta.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "13f2ad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = merged_tweets[new_tweets].copy()\n",
    "users = merged_users[new_users].copy()\n",
    "places = merged_places[new_places].copy()\n",
    "meta = merged_meta[new_meta].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c0f3dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(es_save_dir)\n",
    "os.chdir(es_save_dir/f'{extracted_save_folders[0]}-combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "465ac6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_csv(Path('.'), tweets, 'tweets')\n",
    "utils.save_csv(Path('.'), users, 'users')\n",
    "utils.save_csv(Path('.'), places, 'places')\n",
    "utils.save_csv(Path('.'), meta, 'twitterdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5e4f04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
