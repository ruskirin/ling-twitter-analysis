{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "950d7d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rimov/anaconda3/envs/que_drop/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import regex as re\n",
    "from unidecode import unidecode\n",
    "import yaml\n",
    "import logging\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from IPython.display import Markdown\n",
    "from datetime import datetime as dt\n",
    "from time import sleep\n",
    "from importlib import reload\n",
    "from ast import literal_eval\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "spacy.require_gpu()\n",
    "\n",
    "import files, configs, logs\n",
    "import twitter_data as td\n",
    "import tweets as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38bc9f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs.setup_logger(\n",
    "    file_name='adding-verb-spacing', \n",
    "    desc='After meeting with Dr Jacqueline Serigos. Decided to instead add column indicating V2 and the distance from CCOMP VOI'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95962b96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acordar',\n",
       " 'adivinar',\n",
       " 'admitir',\n",
       " 'afirmar',\n",
       " 'apostar',\n",
       " 'asegurar',\n",
       " 'comprobar',\n",
       " 'confesar',\n",
       " 'confirmar',\n",
       " 'conseguir',\n",
       " 'considerar',\n",
       " 'contar',\n",
       " 'creer',\n",
       " 'decir',\n",
       " 'demostrar',\n",
       " 'desear',\n",
       " 'dudar',\n",
       " 'entender',\n",
       " 'esperar',\n",
       " 'gritar',\n",
       " 'imaginar',\n",
       " 'jurar',\n",
       " 'lamentar',\n",
       " 'lograr',\n",
       " 'mandar',\n",
       " 'mencionar',\n",
       " 'mostrar',\n",
       " 'negar',\n",
       " 'ojala',\n",
       " 'ordenar',\n",
       " 'parecer',\n",
       " 'pedir',\n",
       " 'pensar',\n",
       " 'predecir',\n",
       " 'prever',\n",
       " 'prometer',\n",
       " 'querer',\n",
       " 'reclamar',\n",
       " 'recomendar',\n",
       " 'recordar',\n",
       " 'responder',\n",
       " 'rogar',\n",
       " 'saber',\n",
       " 'sentir',\n",
       " 'solicitar',\n",
       " 'suplicar',\n",
       " 'suponer',\n",
       " 'suspirar',\n",
       " 'temer',\n",
       " 'ver'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbs = set(files.get_verb_conjugations()['verb'].to_numpy())\n",
    "verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99590829",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_conf = configs.read_conf()\n",
    "conf = configs.read_conf('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43cd8e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(conf['spacy']['es'], disable=conf['spacy']['pipeline']['disable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e6c475c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose from the available folders, comma-separated (or \"a\" for all):\n",
      "0. twitter-es-esperar-43769-postagged-20-7-2021\n",
      "1. 2022-04-19 15:41:08\n",
      "2. backup\n",
      "3. 2022-07-07 15:16:47\n",
      "4. 2022-03-08 15:15:06\n",
      "5. 2022-04-22 21:18:32\n",
      "6. 2022-06-30 15:48:37\n",
      "7. 20210726\n",
      "8. 2022-02-08 16:34:36\n",
      "9. samples\n",
      "10. 07112021-at-2210\n",
      "Return folder(s): 9\n"
     ]
    }
   ],
   "source": [
    "data_dir = files.choose_save_path('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c8f1938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = data_dir[0]/'FOR ADRIAN twitter-es-creer-5-912 (1)CLEAR ANNOTATION.xlsx'\n",
    "data_path.is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a3ab318d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verbs</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>ccomp_head</th>\n",
       "      <th>text_orig</th>\n",
       "      <th>in comp</th>\n",
       "      <th>normalized</th>\n",
       "      <th>dependencies</th>\n",
       "      <th>pos</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['entender', 'creer']</td>\n",
       "      <td>1453514708506525952</td>\n",
       "      <td>['entender', 'creer', 'hacer']</td>\n",
       "      <td>@nabbp08 @IvanCepedaCast No entiendo porqué al...</td>\n",
       "      <td>que</td>\n",
       "      <td>@nabbp08 @ivancepedacast no ENTIENDO porqué a...</td>\n",
       "      <td>@nabbp08[ROOT] @ivancepedacast[flat] no[advmo...</td>\n",
       "      <td>@nabbp08(PROPN) @IvanCepedaCast(PROPN) No(ADV)...</td>\n",
       "      <td>&lt;@nabbp08&gt;(@nabbp08,False) &lt;@IvanCepedaCast&gt;(@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['mostrar', 'creer']</td>\n",
       "      <td>1455655561773690880</td>\n",
       "      <td>['creer']</td>\n",
       "      <td>@alferdez habla de país y su deuda. Muestra in...</td>\n",
       "      <td>que</td>\n",
       "      <td>@alferdez habla de país y su deuda. MUESTRA i...</td>\n",
       "      <td>@alferdez[nsubj] habla[ROOT] de[case] país[ob...</td>\n",
       "      <td>@alferdez(PROPN) habla(VERB) de(ADP) país(NOUN...</td>\n",
       "      <td>&lt;@alferdez&gt;(@alferdez,False) &lt;habla&gt;(hablar,Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['pedir', 'entender', 'creer']</td>\n",
       "      <td>1455544578203913984</td>\n",
       "      <td>['creer', 'entender', 'refirio', 'preferir', '...</td>\n",
       "      <td>@diego_espacio @E_FLEISCHMAN Creo q ni tú has ...</td>\n",
       "      <td>que</td>\n",
       "      <td>@diego_espacio @e_fleischman CREO Q ni tú has...</td>\n",
       "      <td>@diego_espacio[ROOT] @e_fleischman[flat] CREO...</td>\n",
       "      <td>@diego_espacio(PROPN) @E_FLEISCHMAN(PROPN) Cre...</td>\n",
       "      <td>&lt;@diego_espacio&gt;(@diego_espacio,False) &lt;@E_FLE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            verbs             tweet_id  \\\n",
       "0           ['entender', 'creer']  1453514708506525952   \n",
       "1            ['mostrar', 'creer']  1455655561773690880   \n",
       "2  ['pedir', 'entender', 'creer']  1455544578203913984   \n",
       "\n",
       "                                          ccomp_head  \\\n",
       "0                     ['entender', 'creer', 'hacer']   \n",
       "1                                          ['creer']   \n",
       "2  ['creer', 'entender', 'refirio', 'preferir', '...   \n",
       "\n",
       "                                           text_orig in comp   \\\n",
       "0  @nabbp08 @IvanCepedaCast No entiendo porqué al...      que   \n",
       "1  @alferdez habla de país y su deuda. Muestra in...      que   \n",
       "2  @diego_espacio @E_FLEISCHMAN Creo q ni tú has ...      que   \n",
       "\n",
       "                                          normalized  \\\n",
       "0   @nabbp08 @ivancepedacast no ENTIENDO porqué a...   \n",
       "1   @alferdez habla de país y su deuda. MUESTRA i...   \n",
       "2   @diego_espacio @e_fleischman CREO Q ni tú has...   \n",
       "\n",
       "                                        dependencies  \\\n",
       "0   @nabbp08[ROOT] @ivancepedacast[flat] no[advmo...   \n",
       "1   @alferdez[nsubj] habla[ROOT] de[case] país[ob...   \n",
       "2   @diego_espacio[ROOT] @e_fleischman[flat] CREO...   \n",
       "\n",
       "                                                 pos  \\\n",
       "0  @nabbp08(PROPN) @IvanCepedaCast(PROPN) No(ADV)...   \n",
       "1  @alferdez(PROPN) habla(VERB) de(ADP) país(NOUN...   \n",
       "2  @diego_espacio(PROPN) @E_FLEISCHMAN(PROPN) Cre...   \n",
       "\n",
       "                                             details  \n",
       "0  <@nabbp08>(@nabbp08,False) <@IvanCepedaCast>(@...  \n",
       "1  <@alferdez>(@alferdez,False) <habla>(hablar,Tr...  \n",
       "2  <@diego_espacio>(@diego_espacio,False) <@E_FLE...  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(data_path)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ee14c186",
   "metadata": {},
   "outputs": [],
   "source": [
    "procd = data['text_orig'].apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "503552c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERB_POS = {'VB','VBD','VBG','VBN','VBP','VBZ','VERB'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c6ae1eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(token):\n",
    "    info = dict()\n",
    "    \n",
    "    try:\n",
    "        for t in token:\n",
    "            info[t.i] = {\n",
    "                'text': t.text, \n",
    "                'lemma': t.lemma_, \n",
    "                'dep': t.dep_,\n",
    "                'pos': t.tag_, \n",
    "                'morph': t.morph\n",
    "            }\n",
    "    except AttributeError as e:\n",
    "        print('Rerun the spacy processing; something went wrong and some elements '\\\n",
    "              'converted to dict instead of Token')\n",
    "        \n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "429d3cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ccomp_head_detail(token):\n",
    "    \"\"\"Get dict of tuples <ccomp head lemma>: ((<ccomp head text>, index), (<ccomp>, index))\"\"\"\n",
    "    ccomp_head = dict()\n",
    "    \n",
    "    for t in token:\n",
    "        if t.dep_ == 'ccomp':\n",
    "            head = t.head\n",
    "            if (head.pos_ in VERB_POS) and (head.lemma_ in verbs):\n",
    "                ccomp_head[head.lemma_] = (((head.text, head.i), (t.text, t.i)))\n",
    "    \n",
    "    return ccomp_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ceaf0f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    {0: {'text': '@nabbp08', 'lemma': '@nabbp08', ...\n",
      "1    {0: {'text': '@alferdez', 'lemma': '@alferdez'...\n",
      "2    {0: {'text': '@diego_espacio', 'lemma': '@dieg...\n",
      "Name: details, dtype: object\n",
      "0    {'entender': (('entiendo', 3), ('creen', 6)), ...\n",
      "1         {'creer': (('Creerá', 32), ('idiotas', 38))}\n",
      "2    {'creer': (('Creo', 2), ('entendido', 7)), 'en...\n",
      "Name: head, dtype: object\n",
      "0    {'entender': (('entiendo', 3), ('creen', 6)), ...\n",
      "1         {'creer': (('Creerá', 32), ('idiotas', 38))}\n",
      "2    {'creer': (('Creo', 2), ('entendido', 7)), 'en...\n",
      "Name: ccomp_head, dtype: object\n"
     ]
    }
   ],
   "source": [
    "details = procd.apply(get_data).rename('details')\n",
    "print(details.head(3))\n",
    "head = procd.apply(ccomp_head_detail).rename('head')\n",
    "print(head.head(3))\n",
    "ccomp_head_detail = procd.apply(ccomp_head_detail).rename('ccomp_head_detail')\n",
    "print(ccomp_head.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1b343a17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'text': '@nabbp08', 'lemma': '@nabbp08', 'dep': 'ROOT', 'pos': 'PROPN', 'morph': }, 1: {'text': '@IvanCepedaCast', 'lemma': '@IvanCepedaCast', 'dep': 'flat', 'pos': 'PROPN', 'morph': }, 2: {'text': 'No', 'lemma': 'no', 'dep': 'advmod', 'pos': 'ADV', 'morph': Polarity=Neg}, 3: {'text': 'entiendo', 'lemma': 'entender', 'dep': 'ROOT', 'pos': 'VERB', 'morph': Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin}, 4: {'text': 'porqué', 'lemma': 'porqué', 'dep': 'obl', 'pos': 'PRON', 'morph': PronType=Ind}, 5: {'text': 'algunos', 'lemma': 'alguno', 'dep': 'nsubj', 'pos': 'PRON', 'morph': Gender=Masc|Number=Plur|PronType=Ind}, 6: {'text': 'creen', 'lemma': 'creer', 'dep': 'ccomp', 'pos': 'VERB', 'morph': Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin}, 7: {'text': 'que', 'lemma': 'que', 'dep': 'mark', 'pos': 'SCONJ', 'morph': }, 8: {'text': 'cualquier', 'lemma': 'cualquiera', 'dep': 'det', 'pos': 'DET', 'morph': Number=Sing|PronType=Ind}, 9: {'text': 'personaje', 'lemma': 'personaje', 'dep': 'nsubj', 'pos': 'NOUN', 'morph': Gender=Masc|Number=Sing}, 10: {'text': 'destacado', 'lemma': 'destacado', 'dep': 'amod', 'pos': 'ADJ', 'morph': Gender=Masc|Number=Sing|VerbForm=Part}, 11: {'text': 'en', 'lemma': 'en', 'dep': 'case', 'pos': 'ADP', 'morph': }, 12: {'text': 'cualquier', 'lemma': 'cualquiera', 'dep': 'det', 'pos': 'DET', 'morph': Number=Sing|PronType=Ind}, 13: {'text': 'ámbito', 'lemma': 'ámbito', 'dep': 'obl', 'pos': 'NOUN', 'morph': Gender=Masc|Number=Sing}, 14: {'text': '(', 'lemma': '(', 'dep': 'punct', 'pos': 'PUNCT', 'morph': PunctSide=Ini|PunctType=Brck}, 15: {'text': 'literatura', 'lemma': 'literatura', 'dep': 'appos', 'pos': 'NOUN', 'morph': Gender=Fem|Number=Sing}, 16: {'text': ',', 'lemma': ',', 'dep': 'punct', 'pos': 'PUNCT', 'morph': PunctType=Comm}, 17: {'text': 'arte', 'lemma': 'arte', 'dep': 'conj', 'pos': 'NOUN', 'morph': Number=Sing}, 18: {'text': ',', 'lemma': ',', 'dep': 'punct', 'pos': 'PUNCT', 'morph': PunctType=Comm}, 19: {'text': 'deporte', 'lemma': 'deporte', 'dep': 'conj', 'pos': 'NOUN', 'morph': Gender=Masc|Number=Sing}, 20: {'text': ')', 'lemma': ')', 'dep': 'punct', 'pos': 'PUNCT', 'morph': PunctSide=Fin|PunctType=Brck}, 21: {'text': 'tiene', 'lemma': 'tener', 'dep': 'ccomp', 'pos': 'VERB', 'morph': Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin}, 22: {'text': 'la', 'lemma': 'el', 'dep': 'det', 'pos': 'DET', 'morph': Definite=Def|Gender=Fem|Number=Sing|PronType=Art}, 23: {'text': 'obligación', 'lemma': 'obligación', 'dep': 'obj', 'pos': 'NOUN', 'morph': Gender=Fem|Number=Sing}, 24: {'text': 'de', 'lemma': 'de', 'dep': 'mark', 'pos': 'ADP', 'morph': }, 25: {'text': 'hacer', 'lemma': 'hacer', 'dep': 'acl', 'pos': 'VERB', 'morph': VerbForm=Inf}, 26: {'text': 'lo', 'lemma': 'él', 'dep': 'det', 'pos': 'PRON', 'morph': Case=Acc|Definite=Def|Gender=Masc|Number=Sing|Person=3|PrepCase=Npr|PronType=Prs}, 27: {'text': 'que', 'lemma': 'que', 'dep': 'nsubj', 'pos': 'PRON', 'morph': PronType=Int,Rel}, 28: {'text': 'sí', 'lemma': 'sí', 'dep': 'advcl', 'pos': 'INTJ', 'morph': }, 29: {'text': 'es', 'lemma': 'ser', 'dep': 'cop', 'pos': 'AUX', 'morph': Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin}, 30: {'text': 'obligación', 'lemma': 'obligación', 'dep': 'ccomp', 'pos': 'NOUN', 'morph': Gender=Fem|Number=Sing}, 31: {'text': 'del', 'lemma': 'del', 'dep': 'case', 'pos': 'ADP', 'morph': Definite=Def|Gender=Masc|Number=Sing|PronType=Art}, 32: {'text': 'Estado', 'lemma': 'Estado', 'dep': 'nmod', 'pos': 'PROPN', 'morph': }, 33: {'text': '.', 'lemma': '.', 'dep': 'punct', 'pos': 'PUNCT', 'morph': PunctType=Peri}, 34: {'text': 'Llevar', 'lemma': 'llevar', 'dep': 'ROOT', 'pos': 'VERB', 'morph': VerbForm=Inf}, 35: {'text': 'desarrollo', 'lemma': 'desarrollo', 'dep': 'obj', 'pos': 'NOUN', 'morph': Gender=Masc|Number=Sing}, 36: {'text': ',', 'lemma': ',', 'dep': 'punct', 'pos': 'PUNCT', 'morph': PunctType=Comm}, 37: {'text': 'economía', 'lemma': 'economía', 'dep': 'appos', 'pos': 'NOUN', 'morph': Gender=Fem|Number=Sing}, 38: {'text': 'o', 'lemma': 'o', 'dep': 'cc', 'pos': 'CCONJ', 'morph': }, 39: {'text': 'lo', 'lemma': 'él', 'dep': 'det', 'pos': 'PRON', 'morph': Case=Acc|Definite=Def|Gender=Masc|Number=Sing|Person=3|PrepCase=Npr|PronType=Prs}, 40: {'text': 'que', 'lemma': 'que', 'dep': 'conj', 'pos': 'PRON', 'morph': PronType=Int,Rel}, 41: {'text': 'sea', 'lemma': 'ser', 'dep': 'cop', 'pos': 'AUX', 'morph': Mood=Sub|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin}, 42: {'text': 'a', 'lemma': 'a', 'dep': 'case', 'pos': 'ADP', 'morph': }, 43: {'text': 'su', 'lemma': 'su', 'dep': 'det', 'pos': 'DET', 'morph': Number=Sing|Person=3|Poss=Yes|PronType=Prs}, 44: {'text': 'región', 'lemma': 'región', 'dep': 'obl', 'pos': 'NOUN', 'morph': Gender=Fem|Number=Sing}, 45: {'text': '.', 'lemma': '.', 'dep': 'punct', 'pos': 'PUNCT', 'morph': PunctType=Peri}, 46: {'text': 'Es', 'lemma': 'ser', 'dep': 'cop', 'pos': 'AUX', 'morph': Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin}, 47: {'text': 'obligación', 'lemma': 'obligación', 'dep': 'ROOT', 'pos': 'NOUN', 'morph': Gender=Fem|Number=Sing}, 48: {'text': 'de', 'lemma': 'de', 'dep': 'case', 'pos': 'ADP', 'morph': }, 49: {'text': 'los', 'lemma': 'el', 'dep': 'det', 'pos': 'DET', 'morph': Definite=Def|Gender=Masc|Number=Plur|PronType=Art}, 50: {'text': 'gobiernos', 'lemma': 'gobierno', 'dep': 'nmod', 'pos': 'NOUN', 'morph': Gender=Masc|Number=Plur}, 51: {'text': 'Nal', 'lemma': 'Nal', 'dep': 'appos', 'pos': 'PROPN', 'morph': }, 52: {'text': 'y', 'lemma': 'y', 'dep': 'cc', 'pos': 'CCONJ', 'morph': }, 53: {'text': 'regional', 'lemma': 'regional', 'dep': 'conj', 'pos': 'ADJ', 'morph': Number=Sing}, 54: {'text': '.', 'lemma': '.', 'dep': 'punct', 'pos': 'PUNCT', 'morph': PunctType=Peri}}\n"
     ]
    }
   ],
   "source": [
    "print(details[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ae5ac287",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['ccomp_head'] = data['ccomp_head'].apply(literal_eval)\n",
    "data = data.rename(columns={'in comp ': 'in_comp'})\n",
    "data = data.drop(columns=['ccomp_head'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "5dd0b275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_comp</th>\n",
       "      <th>verbs</th>\n",
       "      <th>head</th>\n",
       "      <th>ccomp_head_detail</th>\n",
       "      <th>text_orig</th>\n",
       "      <th>dependencies</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1453514708506525952</td>\n",
       "      <td>que</td>\n",
       "      <td>['entender', 'creer']</td>\n",
       "      <td>{'entender': (('entiendo', 3), ('creen', 6)), ...</td>\n",
       "      <td>{'entender': (('entiendo', 3), ('creen', 6)), ...</td>\n",
       "      <td>@nabbp08 @IvanCepedaCast No entiendo porqué al...</td>\n",
       "      <td>@nabbp08[ROOT] @ivancepedacast[flat] no[advmo...</td>\n",
       "      <td>{0: {'text': '@nabbp08', 'lemma': '@nabbp08', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1455655561773690880</td>\n",
       "      <td>que</td>\n",
       "      <td>['mostrar', 'creer']</td>\n",
       "      <td>{'creer': (('Creerá', 32), ('idiotas', 38))}</td>\n",
       "      <td>{'creer': (('Creerá', 32), ('idiotas', 38))}</td>\n",
       "      <td>@alferdez habla de país y su deuda. Muestra in...</td>\n",
       "      <td>@alferdez[nsubj] habla[ROOT] de[case] país[ob...</td>\n",
       "      <td>{0: {'text': '@alferdez', 'lemma': '@alferdez'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1455544578203913984</td>\n",
       "      <td>que</td>\n",
       "      <td>['pedir', 'entender', 'creer']</td>\n",
       "      <td>{'creer': (('Creo', 2), ('entendido', 7)), 'en...</td>\n",
       "      <td>{'creer': (('Creo', 2), ('entendido', 7)), 'en...</td>\n",
       "      <td>@diego_espacio @E_FLEISCHMAN Creo q ni tú has ...</td>\n",
       "      <td>@diego_espacio[ROOT] @e_fleischman[flat] CREO...</td>\n",
       "      <td>{0: {'text': '@diego_espacio', 'lemma': '@dieg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id in_comp                           verbs  \\\n",
       "0  1453514708506525952     que           ['entender', 'creer']   \n",
       "1  1455655561773690880     que            ['mostrar', 'creer']   \n",
       "2  1455544578203913984     que  ['pedir', 'entender', 'creer']   \n",
       "\n",
       "                                                head  \\\n",
       "0  {'entender': (('entiendo', 3), ('creen', 6)), ...   \n",
       "1       {'creer': (('Creerá', 32), ('idiotas', 38))}   \n",
       "2  {'creer': (('Creo', 2), ('entendido', 7)), 'en...   \n",
       "\n",
       "                                   ccomp_head_detail  \\\n",
       "0  {'entender': (('entiendo', 3), ('creen', 6)), ...   \n",
       "1       {'creer': (('Creerá', 32), ('idiotas', 38))}   \n",
       "2  {'creer': (('Creo', 2), ('entendido', 7)), 'en...   \n",
       "\n",
       "                                           text_orig  \\\n",
       "0  @nabbp08 @IvanCepedaCast No entiendo porqué al...   \n",
       "1  @alferdez habla de país y su deuda. Muestra in...   \n",
       "2  @diego_espacio @E_FLEISCHMAN Creo q ni tú has ...   \n",
       "\n",
       "                                        dependencies  \\\n",
       "0   @nabbp08[ROOT] @ivancepedacast[flat] no[advmo...   \n",
       "1   @alferdez[nsubj] habla[ROOT] de[case] país[ob...   \n",
       "2   @diego_espacio[ROOT] @e_fleischman[flat] CREO...   \n",
       "\n",
       "                                             details  \n",
       "0  {0: {'text': '@nabbp08', 'lemma': '@nabbp08', ...  \n",
       "1  {0: {'text': '@alferdez', 'lemma': '@alferdez'...  \n",
       "2  {0: {'text': '@diego_espacio', 'lemma': '@dieg...  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndata = pd.concat([data.loc[:, ['tweet_id','in_comp','verbs']], head, ccomp_head_detail, data.loc[:, ['text_orig','dependencies']], details], axis=1)\n",
    "ndata.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "8da1cfda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_comp</th>\n",
       "      <th>verbs</th>\n",
       "      <th>head</th>\n",
       "      <th>ccomp_head_detail</th>\n",
       "      <th>text_orig</th>\n",
       "      <th>dependencies</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1453514708506525952</td>\n",
       "      <td>que</td>\n",
       "      <td>['entender', 'creer']</td>\n",
       "      <td>entender</td>\n",
       "      <td>{'entender': (('entiendo', 3), ('creen', 6)), ...</td>\n",
       "      <td>@nabbp08 @IvanCepedaCast No entiendo porqué al...</td>\n",
       "      <td>@nabbp08[ROOT] @ivancepedacast[flat] no[advmo...</td>\n",
       "      <td>{0: {'text': '@nabbp08', 'lemma': '@nabbp08', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1453514708506525952</td>\n",
       "      <td>que</td>\n",
       "      <td>['entender', 'creer']</td>\n",
       "      <td>creer</td>\n",
       "      <td>{'entender': (('entiendo', 3), ('creen', 6)), ...</td>\n",
       "      <td>@nabbp08 @IvanCepedaCast No entiendo porqué al...</td>\n",
       "      <td>@nabbp08[ROOT] @ivancepedacast[flat] no[advmo...</td>\n",
       "      <td>{0: {'text': '@nabbp08', 'lemma': '@nabbp08', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1455655561773690880</td>\n",
       "      <td>que</td>\n",
       "      <td>['mostrar', 'creer']</td>\n",
       "      <td>creer</td>\n",
       "      <td>{'creer': (('Creerá', 32), ('idiotas', 38))}</td>\n",
       "      <td>@alferdez habla de país y su deuda. Muestra in...</td>\n",
       "      <td>@alferdez[nsubj] habla[ROOT] de[case] país[ob...</td>\n",
       "      <td>{0: {'text': '@alferdez', 'lemma': '@alferdez'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id in_comp                  verbs      head  \\\n",
       "0  1453514708506525952     que  ['entender', 'creer']  entender   \n",
       "1  1453514708506525952     que  ['entender', 'creer']     creer   \n",
       "2  1455655561773690880     que   ['mostrar', 'creer']     creer   \n",
       "\n",
       "                                   ccomp_head_detail  \\\n",
       "0  {'entender': (('entiendo', 3), ('creen', 6)), ...   \n",
       "1  {'entender': (('entiendo', 3), ('creen', 6)), ...   \n",
       "2       {'creer': (('Creerá', 32), ('idiotas', 38))}   \n",
       "\n",
       "                                           text_orig  \\\n",
       "0  @nabbp08 @IvanCepedaCast No entiendo porqué al...   \n",
       "1  @nabbp08 @IvanCepedaCast No entiendo porqué al...   \n",
       "2  @alferdez habla de país y su deuda. Muestra in...   \n",
       "\n",
       "                                        dependencies  \\\n",
       "0   @nabbp08[ROOT] @ivancepedacast[flat] no[advmo...   \n",
       "1   @nabbp08[ROOT] @ivancepedacast[flat] no[advmo...   \n",
       "2   @alferdez[nsubj] habla[ROOT] de[case] país[ob...   \n",
       "\n",
       "                                             details  \n",
       "0  {0: {'text': '@nabbp08', 'lemma': '@nabbp08', ...  \n",
       "1  {0: {'text': '@nabbp08', 'lemma': '@nabbp08', ...  \n",
       "2  {0: {'text': '@alferdez', 'lemma': '@alferdez'...  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndata = ndata.explode('head', ignore_index=True)\n",
    "ndata.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "a5bc3013",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_comp</th>\n",
       "      <th>verbs</th>\n",
       "      <th>head</th>\n",
       "      <th>ccomp_head_detail</th>\n",
       "      <th>text_orig</th>\n",
       "      <th>dependencies</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1455486694006960128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>Yo creo q d la brisa del mar xd</td>\n",
       "      <td>yo[nsubj] CREO[ROOT] q[mark] D[CCOMP] la[det]...</td>\n",
       "      <td>{0: {'text': 'Yo', 'lemma': 'yo', 'dep': 'nsub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1456958790293614080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>@keito_sanchez Jaja no creo en el fuego se coc...</td>\n",
       "      <td>@keito_sanchez[ROOT] jaja[flat] no[advmod] CR...</td>\n",
       "      <td>{0: {'text': '@keito_sanchez', 'lemma': '@keit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1454156646947692032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['ver', 'creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>Yo creo que eso no va pasar es solo un deseo; ...</td>\n",
       "      <td>yo[nsubj] CREO[ROOT] que[mark] eso[nsubj] no[...</td>\n",
       "      <td>{0: {'text': 'Yo', 'lemma': 'yo', 'dep': 'nsub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1449192019574672896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['parecer', 'creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>@ArturoAroni Me parece que esa tapa es trucha....</td>\n",
       "      <td>@arturoaroni[ROOT] me[iobj] PARECE[ROOT] que[...</td>\n",
       "      <td>{0: {'text': '@ArturoAroni', 'lemma': '@Arturo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1454928340004090112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['parecer', 'creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>@RoyalCaribbean Mi primer crucero, viajé el  #...</td>\n",
       "      <td>@royalcaribbean[obj] mi[det] primer[amod] cru...</td>\n",
       "      <td>{0: {'text': '@RoyalCaribbean', 'lemma': '@Roy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1454900755404623872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['parecer', 'creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>@ActualidadRT Como se parecen a Jesús ! empeza...</td>\n",
       "      <td>@actualidadrt[ROOT] como[mark] se[expl:pv] PA...</td>\n",
       "      <td>{0: {'text': '@ActualidadRT', 'lemma': '@Actua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1451926101287129088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>@SinEmbargoMX Estos poliquiteros \"sabelotodo\"\\...</td>\n",
       "      <td>@sinembargomx[ROOT] estos[det] poliquiteros[n...</td>\n",
       "      <td>{0: {'text': '@SinEmbargoMX', 'lemma': '@SinEm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>1456835186818260992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>@oscar_canton  😂😂😂 hora los diputados mamarrac...</td>\n",
       "      <td>@oscar_canton[obl]  [dep] 😂[nsubj] 😂[fixed] 😂...</td>\n",
       "      <td>{0: {'text': '@oscar_canton', 'lemma': '@oscar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>1450445453741498112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['mandar', 'creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>@KKazzari @LulaBarba @beltrandelrio @AndyFayri...</td>\n",
       "      <td>@kkazzari[ROOT] @lulabarba[flat] @beltrandelr...</td>\n",
       "      <td>{0: {'text': '@KKazzari', 'lemma': '@KKazzari'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>1448340889651322880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['pedir', 'recordar', 'creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>@virgi_m13 Yo creo recordar de ir a un miting ...</td>\n",
       "      <td>@virgi_m13[ROOT] yo[nsubj] CREO[ROOT] RECORDA...</td>\n",
       "      <td>{0: {'text': '@virgi_m13', 'lemma': '@virgi_m1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>1447147986790739968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>@Picupipu1 Perdón que entre en la conversación...</td>\n",
       "      <td>@picupipu1[ROOT] perdón[ROOT] que[mark] ENTRE...</td>\n",
       "      <td>{0: {'text': '@Picupipu1', 'lemma': '@Picupipu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>1450554797279559936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>@mario_dico50 @FelipeCalderon @PartidoMorenaMx...</td>\n",
       "      <td>@mario_dico50[advmod] @felipecalderon[flat] @...</td>\n",
       "      <td>{0: {'text': '@mario_dico50', 'lemma': '@mario...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>1452392811819580928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['mostrar', 'creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>@AnaInesMartinez @Punto_Penal Tremenda desiluc...</td>\n",
       "      <td>@ANAINESMARTINEZ[CCOMP] @punto_penal[flat] tr...</td>\n",
       "      <td>{0: {'text': '@AnaInesMartinez', 'lemma': '@An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>1452385102223269888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['mostrar', 'creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>@soybucaros @balonalairepod @BballPeace @Fecol...</td>\n",
       "      <td>@soybucaros[ROOT] @balonalairepod[flat] @bbal...</td>\n",
       "      <td>{0: {'text': '@soybucaros', 'lemma': '@soybuca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>1456256234605142016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['desear', 'creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>@AraRufo @zendalibros Pues estoy contigo. Polé...</td>\n",
       "      <td>@ararufo[dep] @zendalibros[ROOT] pues[mark] e...</td>\n",
       "      <td>{0: {'text': '@AraRufo', 'lemma': '@AraRufo', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>1455527101495397888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['sentir', 'creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>manera? Crees que puedes acudir a mí para desp...</td>\n",
       "      <td>manera[ROOT] ? CREES[ROOT] que[mark] puedes[a...</td>\n",
       "      <td>{0: {'text': 'manera', 'lemma': 'manera', 'dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>1455824725876396032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['negar', 'creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>@huyelobo @AMdHL @TyelpeIthildim @filosofotodo...</td>\n",
       "      <td>@huyelobo[ROOT] @amdhl[flat] @tyelpeithildim[...</td>\n",
       "      <td>{0: {'text': '@huyelobo', 'lemma': '@huyelobo'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>1449991705290288896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>@justiciagob Q morro,!!!! Pero si es denigrant...</td>\n",
       "      <td>@justiciagob[ROOT] q[flat] morro[flat] , ! ! ...</td>\n",
       "      <td>{0: {'text': '@justiciagob', 'lemma': '@justic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>1449918710660182016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>No cree está cuenta por alguien, pero UD por mi!</td>\n",
       "      <td>no[advmod] CREE[ROOT] está[det] CUENTA[CCOMP]...</td>\n",
       "      <td>{0: {'text': 'No', 'lemma': 'no', 'dep': 'advm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>1455985210366038016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['acordar', 'creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>@ZCFoficial @CDBadajoz Yo creo que 1-2  #Zamor...</td>\n",
       "      <td>@zcfoficial[ROOT] @cdbadajoz[punct] yo[nsubj]...</td>\n",
       "      <td>{0: {'text': '@ZCFoficial', 'lemma': '@ZCFofic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>1455958816344973056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>@carolina_moine @martintetaz @vicentcap @JMile...</td>\n",
       "      <td>@carolina_moine[ROOT] @martintetaz[conj] @vic...</td>\n",
       "      <td>{0: {'text': '@carolina_moine', 'lemma': '@car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>1452354503282500096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>@r_tian_ Creo en en lugar de quejarte, lee un ...</td>\n",
       "      <td>@r_tian[nsubj] _ CREO[ROOT] en[mark] en[mark]...</td>\n",
       "      <td>{0: {'text': '@r_tian', 'lemma': '@r_tian', 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>1448757032409092096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>@luisantonio_r Pero si eres periodista ‘prepar...</td>\n",
       "      <td>@luisantonio_r[nsubj] pero[advmod] si[mark] e...</td>\n",
       "      <td>{0: {'text': '@luisantonio_r', 'lemma': '@luis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>1454526914828374016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['contar', 'creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>@CarlosLoret 6Pueblo no el gobierno cuando hay...</td>\n",
       "      <td>@carlosloret[nsubj] 6pueblo[flat] no[advmod] ...</td>\n",
       "      <td>{0: {'text': '@CarlosLoret', 'lemma': '@Carlos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>1447005451351174912</td>\n",
       "      <td>que</td>\n",
       "      <td>['creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>@amazon quién os creéis que sois para dejar mi...</td>\n",
       "      <td>@amazon[ROOT] quién[nsubj] os[expl:pv] CREÉIS...</td>\n",
       "      <td>{0: {'text': '@amazon', 'lemma': '@amazon', 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>1455928987851664896</td>\n",
       "      <td>que</td>\n",
       "      <td>['creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>Me daba un poco de miedo Fisiología por la pro...</td>\n",
       "      <td>me[iobj] daba[ROOT] un[det] poco[obj] de[case...</td>\n",
       "      <td>{0: {'text': 'Me', 'lemma': 'yo', 'dep': 'iobj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>1456980031587208960</td>\n",
       "      <td>x</td>\n",
       "      <td>['lograr', 'creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>@volaguer_ @d_rochaf18 Esta de la chingada cre...</td>\n",
       "      <td>@volaguer[ROOT] _[flat] @d_rochaf18[flat] est...</td>\n",
       "      <td>{0: {'text': '@volaguer', 'lemma': '@volaguer'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>1449581309232304128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['suponer', 'creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>Que si tienen metas de multas y cepos, quizá, ...</td>\n",
       "      <td>que[mark] si[mark] tienen[advcl] metas[obj] d...</td>\n",
       "      <td>{0: {'text': 'Que', 'lemma': 'que', 'dep': 'ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>1447269288146992896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['parecer', 'creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>q les parece si eliminamos @ContraloriaPma @Ge...</td>\n",
       "      <td>q[nsubj] les[obj] PARECE[advcl] si[mark] elim...</td>\n",
       "      <td>{0: {'text': 'q', 'lemma': 'q', 'dep': 'nsubj'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>1448121378415301120</td>\n",
       "      <td>que</td>\n",
       "      <td>['contar', 'creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>@tiancrislc @Felipe_DinoTEA Sip. Yo tb creo po...</td>\n",
       "      <td>@tiancrislc[ROOT] @felipe_dinotea[flat] sip[f...</td>\n",
       "      <td>{0: {'text': '@tiancrislc', 'lemma': '@tiancri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>1455599033372786944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['suponer', 'ver', 'creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>@yaquisoy @FanNaranjero @MayosNacion @MayosFan...</td>\n",
       "      <td>@yaquisoy[ROOT] @fannaranjero[flat] @mayosnac...</td>\n",
       "      <td>{0: {'text': '@yaquisoy', 'lemma': '@yaquisoy'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>1452655391146340096</td>\n",
       "      <td>que</td>\n",
       "      <td>['creer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>@omneco Hay que ser muy ingenuo en creer que 2...</td>\n",
       "      <td>@omneco[nsubj] hay[ROOT] que[cc] ser[cop] muy...</td>\n",
       "      <td>{0: {'text': '@omneco', 'lemma': '@omneco', 'd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id in_comp                           verbs head  \\\n",
       "73    1455486694006960128     NaN                       ['creer']  NaN   \n",
       "88    1456958790293614080     NaN                       ['creer']  NaN   \n",
       "107   1454156646947692032     NaN                ['ver', 'creer']  NaN   \n",
       "145   1449192019574672896     NaN            ['parecer', 'creer']  NaN   \n",
       "150   1454928340004090112     NaN            ['parecer', 'creer']  NaN   \n",
       "154   1454900755404623872     NaN            ['parecer', 'creer']  NaN   \n",
       "177   1451926101287129088     NaN                       ['creer']  NaN   \n",
       "301   1456835186818260992     NaN                       ['creer']  NaN   \n",
       "315   1450445453741498112     NaN             ['mandar', 'creer']  NaN   \n",
       "316   1448340889651322880     NaN  ['pedir', 'recordar', 'creer']  NaN   \n",
       "372   1447147986790739968     NaN                       ['creer']  NaN   \n",
       "439   1450554797279559936     NaN                       ['creer']  NaN   \n",
       "460   1452392811819580928     NaN            ['mostrar', 'creer']  NaN   \n",
       "461   1452385102223269888     NaN            ['mostrar', 'creer']  NaN   \n",
       "600   1456256234605142016     NaN             ['desear', 'creer']  NaN   \n",
       "688   1455527101495397888     NaN             ['sentir', 'creer']  NaN   \n",
       "769   1455824725876396032     NaN              ['negar', 'creer']  NaN   \n",
       "790   1449991705290288896     NaN                       ['creer']  NaN   \n",
       "798   1449918710660182016     NaN                       ['creer']  NaN   \n",
       "804   1455985210366038016     NaN            ['acordar', 'creer']  NaN   \n",
       "805   1455958816344973056     NaN                       ['creer']  NaN   \n",
       "829   1452354503282500096     NaN                       ['creer']  NaN   \n",
       "842   1448757032409092096     NaN                       ['creer']  NaN   \n",
       "859   1454526914828374016     NaN             ['contar', 'creer']  NaN   \n",
       "872   1447005451351174912     que                       ['creer']  NaN   \n",
       "901   1455928987851664896     que                       ['creer']  NaN   \n",
       "951   1456980031587208960       x             ['lograr', 'creer']  NaN   \n",
       "969   1449581309232304128     NaN            ['suponer', 'creer']  NaN   \n",
       "982   1447269288146992896     NaN            ['parecer', 'creer']  NaN   \n",
       "1081  1448121378415301120     que             ['contar', 'creer']  NaN   \n",
       "1103  1455599033372786944     NaN     ['suponer', 'ver', 'creer']  NaN   \n",
       "1154  1452655391146340096     que                       ['creer']  NaN   \n",
       "\n",
       "     ccomp_head_detail                                          text_orig  \\\n",
       "73                  {}                    Yo creo q d la brisa del mar xd   \n",
       "88                  {}  @keito_sanchez Jaja no creo en el fuego se coc...   \n",
       "107                 {}  Yo creo que eso no va pasar es solo un deseo; ...   \n",
       "145                 {}  @ArturoAroni Me parece que esa tapa es trucha....   \n",
       "150                 {}  @RoyalCaribbean Mi primer crucero, viajé el  #...   \n",
       "154                 {}  @ActualidadRT Como se parecen a Jesús ! empeza...   \n",
       "177                 {}  @SinEmbargoMX Estos poliquiteros \"sabelotodo\"\\...   \n",
       "301                 {}  @oscar_canton  😂😂😂 hora los diputados mamarrac...   \n",
       "315                 {}  @KKazzari @LulaBarba @beltrandelrio @AndyFayri...   \n",
       "316                 {}  @virgi_m13 Yo creo recordar de ir a un miting ...   \n",
       "372                 {}  @Picupipu1 Perdón que entre en la conversación...   \n",
       "439                 {}  @mario_dico50 @FelipeCalderon @PartidoMorenaMx...   \n",
       "460                 {}  @AnaInesMartinez @Punto_Penal Tremenda desiluc...   \n",
       "461                 {}  @soybucaros @balonalairepod @BballPeace @Fecol...   \n",
       "600                 {}  @AraRufo @zendalibros Pues estoy contigo. Polé...   \n",
       "688                 {}  manera? Crees que puedes acudir a mí para desp...   \n",
       "769                 {}  @huyelobo @AMdHL @TyelpeIthildim @filosofotodo...   \n",
       "790                 {}  @justiciagob Q morro,!!!! Pero si es denigrant...   \n",
       "798                 {}   No cree está cuenta por alguien, pero UD por mi!   \n",
       "804                 {}  @ZCFoficial @CDBadajoz Yo creo que 1-2  #Zamor...   \n",
       "805                 {}  @carolina_moine @martintetaz @vicentcap @JMile...   \n",
       "829                 {}  @r_tian_ Creo en en lugar de quejarte, lee un ...   \n",
       "842                 {}  @luisantonio_r Pero si eres periodista ‘prepar...   \n",
       "859                 {}  @CarlosLoret 6Pueblo no el gobierno cuando hay...   \n",
       "872                 {}  @amazon quién os creéis que sois para dejar mi...   \n",
       "901                 {}  Me daba un poco de miedo Fisiología por la pro...   \n",
       "951                 {}  @volaguer_ @d_rochaf18 Esta de la chingada cre...   \n",
       "969                 {}  Que si tienen metas de multas y cepos, quizá, ...   \n",
       "982                 {}  q les parece si eliminamos @ContraloriaPma @Ge...   \n",
       "1081                {}  @tiancrislc @Felipe_DinoTEA Sip. Yo tb creo po...   \n",
       "1103                {}  @yaquisoy @FanNaranjero @MayosNacion @MayosFan...   \n",
       "1154                {}  @omneco Hay que ser muy ingenuo en creer que 2...   \n",
       "\n",
       "                                           dependencies  \\\n",
       "73     yo[nsubj] CREO[ROOT] q[mark] D[CCOMP] la[det]...   \n",
       "88     @keito_sanchez[ROOT] jaja[flat] no[advmod] CR...   \n",
       "107    yo[nsubj] CREO[ROOT] que[mark] eso[nsubj] no[...   \n",
       "145    @arturoaroni[ROOT] me[iobj] PARECE[ROOT] que[...   \n",
       "150    @royalcaribbean[obj] mi[det] primer[amod] cru...   \n",
       "154    @actualidadrt[ROOT] como[mark] se[expl:pv] PA...   \n",
       "177    @sinembargomx[ROOT] estos[det] poliquiteros[n...   \n",
       "301    @oscar_canton[obl]  [dep] 😂[nsubj] 😂[fixed] 😂...   \n",
       "315    @kkazzari[ROOT] @lulabarba[flat] @beltrandelr...   \n",
       "316    @virgi_m13[ROOT] yo[nsubj] CREO[ROOT] RECORDA...   \n",
       "372    @picupipu1[ROOT] perdón[ROOT] que[mark] ENTRE...   \n",
       "439    @mario_dico50[advmod] @felipecalderon[flat] @...   \n",
       "460    @ANAINESMARTINEZ[CCOMP] @punto_penal[flat] tr...   \n",
       "461    @soybucaros[ROOT] @balonalairepod[flat] @bbal...   \n",
       "600    @ararufo[dep] @zendalibros[ROOT] pues[mark] e...   \n",
       "688    manera[ROOT] ? CREES[ROOT] que[mark] puedes[a...   \n",
       "769    @huyelobo[ROOT] @amdhl[flat] @tyelpeithildim[...   \n",
       "790    @justiciagob[ROOT] q[flat] morro[flat] , ! ! ...   \n",
       "798    no[advmod] CREE[ROOT] está[det] CUENTA[CCOMP]...   \n",
       "804    @zcfoficial[ROOT] @cdbadajoz[punct] yo[nsubj]...   \n",
       "805    @carolina_moine[ROOT] @martintetaz[conj] @vic...   \n",
       "829    @r_tian[nsubj] _ CREO[ROOT] en[mark] en[mark]...   \n",
       "842    @luisantonio_r[nsubj] pero[advmod] si[mark] e...   \n",
       "859    @carlosloret[nsubj] 6pueblo[flat] no[advmod] ...   \n",
       "872    @amazon[ROOT] quién[nsubj] os[expl:pv] CREÉIS...   \n",
       "901    me[iobj] daba[ROOT] un[det] poco[obj] de[case...   \n",
       "951    @volaguer[ROOT] _[flat] @d_rochaf18[flat] est...   \n",
       "969    que[mark] si[mark] tienen[advcl] metas[obj] d...   \n",
       "982    q[nsubj] les[obj] PARECE[advcl] si[mark] elim...   \n",
       "1081   @tiancrislc[ROOT] @felipe_dinotea[flat] sip[f...   \n",
       "1103   @yaquisoy[ROOT] @fannaranjero[flat] @mayosnac...   \n",
       "1154   @omneco[nsubj] hay[ROOT] que[cc] ser[cop] muy...   \n",
       "\n",
       "                                                details  \n",
       "73    {0: {'text': 'Yo', 'lemma': 'yo', 'dep': 'nsub...  \n",
       "88    {0: {'text': '@keito_sanchez', 'lemma': '@keit...  \n",
       "107   {0: {'text': 'Yo', 'lemma': 'yo', 'dep': 'nsub...  \n",
       "145   {0: {'text': '@ArturoAroni', 'lemma': '@Arturo...  \n",
       "150   {0: {'text': '@RoyalCaribbean', 'lemma': '@Roy...  \n",
       "154   {0: {'text': '@ActualidadRT', 'lemma': '@Actua...  \n",
       "177   {0: {'text': '@SinEmbargoMX', 'lemma': '@SinEm...  \n",
       "301   {0: {'text': '@oscar_canton', 'lemma': '@oscar...  \n",
       "315   {0: {'text': '@KKazzari', 'lemma': '@KKazzari'...  \n",
       "316   {0: {'text': '@virgi_m13', 'lemma': '@virgi_m1...  \n",
       "372   {0: {'text': '@Picupipu1', 'lemma': '@Picupipu...  \n",
       "439   {0: {'text': '@mario_dico50', 'lemma': '@mario...  \n",
       "460   {0: {'text': '@AnaInesMartinez', 'lemma': '@An...  \n",
       "461   {0: {'text': '@soybucaros', 'lemma': '@soybuca...  \n",
       "600   {0: {'text': '@AraRufo', 'lemma': '@AraRufo', ...  \n",
       "688   {0: {'text': 'manera', 'lemma': 'manera', 'dep...  \n",
       "769   {0: {'text': '@huyelobo', 'lemma': '@huyelobo'...  \n",
       "790   {0: {'text': '@justiciagob', 'lemma': '@justic...  \n",
       "798   {0: {'text': 'No', 'lemma': 'no', 'dep': 'advm...  \n",
       "804   {0: {'text': '@ZCFoficial', 'lemma': '@ZCFofic...  \n",
       "805   {0: {'text': '@carolina_moine', 'lemma': '@car...  \n",
       "829   {0: {'text': '@r_tian', 'lemma': '@r_tian', 'd...  \n",
       "842   {0: {'text': '@luisantonio_r', 'lemma': '@luis...  \n",
       "859   {0: {'text': '@CarlosLoret', 'lemma': '@Carlos...  \n",
       "872   {0: {'text': '@amazon', 'lemma': '@amazon', 'd...  \n",
       "901   {0: {'text': 'Me', 'lemma': 'yo', 'dep': 'iobj...  \n",
       "951   {0: {'text': '@volaguer', 'lemma': '@volaguer'...  \n",
       "969   {0: {'text': 'Que', 'lemma': 'que', 'dep': 'ma...  \n",
       "982   {0: {'text': 'q', 'lemma': 'q', 'dep': 'nsubj'...  \n",
       "1081  {0: {'text': '@tiancrislc', 'lemma': '@tiancri...  \n",
       "1103  {0: {'text': '@yaquisoy', 'lemma': '@yaquisoy'...  \n",
       "1154  {0: {'text': '@omneco', 'lemma': '@omneco', 'd...  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop elements with ccomp head not containing VOI\n",
    "not_in = ndata.loc[~ndata['head'].isin(verbs), :]\n",
    "print(not_in.shape[0])\n",
    "not_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "4538a29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1125"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndata = ndata.drop(index=not_in.index).reset_index()\n",
    "ndata.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "57dcdde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_range_info(tweet):\n",
    "    # TODO 3/11: update docs\n",
    "    \"\"\"Get the next verb after ccomp head and count the amount of words between them\"\"\"\n",
    "    head = tweet['head']\n",
    "    \n",
    "    v1, v1_idx = tweet['ccomp_head_detail'][head][0]\n",
    "    ccomp, ccomp_idx = tweet['ccomp_head_detail'][head][1]\n",
    "    v2 = None\n",
    "    \n",
    "#     print(f'Head: {head}, v1 index: {v1_idx}, ccomp: {ccomp}, ccomp index: {ccomp_idx}\\n')\n",
    "    \n",
    "    ccomp_dist = 0\n",
    "    v2_dist = 0\n",
    "    \n",
    "    for i,w in tweet['details'].items():\n",
    "#         print(i, w)\n",
    "        \n",
    "        # start after v1/ccomp_head\n",
    "        if i <= v1_idx:\n",
    "            continue\n",
    "        \n",
    "        if (v2 is None) and (w['pos'] in VERB_POS):\n",
    "#             print(f'*** V2 found: {w[\"text\"], i} ***')\n",
    "            v2 = (w['text'], i)\n",
    "            \n",
    "        # only count words\n",
    "        if w['pos'] != 'PUNCT':\n",
    "            if i < ccomp_idx:\n",
    "                ccomp_dist += 1\n",
    "            if v2 is None:\n",
    "                v2_dist += 1\n",
    "    \n",
    "    info = {\n",
    "        'ccomp': (ccomp, ccomp_idx),\n",
    "        'ccomp_dist': ccomp_dist,\n",
    "        'v2': v2, \n",
    "        'v2_dist': v2_dist if v2 is not None else None\n",
    "    }\n",
    "    \n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "92a4df8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                                           1454942423797305088\n",
       "in_comp                                                            NaN\n",
       "verbs                                    ['decir', 'mostrar', 'creer']\n",
       "ccomp_head                                                       decir\n",
       "ccomp_head_detail          {'decir': (('dicen', 4), ('seguiría', 27))}\n",
       "text_orig            @rodrigolussich y @DaniAmbrosino ustedes dicen...\n",
       "details              {0: {'text': '@rodrigolussich', 'lemma': '@rod...\n",
       "Name: 12, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = ndata.iloc[12]\n",
    "display(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b3170a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@rodrigolussich y @DaniAmbrosino ustedes dicen q la @chinasuarez sería aún más T R O L A de lo q ya le mostró al 🌍🌎y le seguiría escribiendo a Icardi (a pesar de q creo ya se enteró de q el sigue casado)? Yo No creo...tiene hij@s!\n",
      "#ElShowDeLosEscandalones\n"
     ]
    }
   ],
   "source": [
    "print(s['text_orig'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1785b153",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head: decir, v1 index: 4, ccomp: seguiría, ccomp index: 27\n",
      "\n",
      "0 {'text': '@rodrigolussich', 'lemma': '@rodrigolussich', 'dep': 'ROOT', 'pos': 'PROPN', 'morph': }\n",
      "1 {'text': 'y', 'lemma': 'y', 'dep': 'cc', 'pos': 'CCONJ', 'morph': }\n",
      "2 {'text': '@DaniAmbrosino', 'lemma': '@DaniAmbrosino', 'dep': 'conj', 'pos': 'PROPN', 'morph': }\n",
      "3 {'text': 'ustedes', 'lemma': 'tú', 'dep': 'nsubj', 'pos': 'PRON', 'morph': Case=Acc,Nom|Number=Plur|Person=2|Polite=Form|PronType=Prs}\n",
      "4 {'text': 'dicen', 'lemma': 'decir', 'dep': 'ROOT', 'pos': 'VERB', 'morph': Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin}\n",
      "5 {'text': 'q', 'lemma': 'q', 'dep': 'mark', 'pos': 'SCONJ', 'morph': }\n",
      "6 {'text': 'la', 'lemma': 'el', 'dep': 'det', 'pos': 'DET', 'morph': Definite=Def|Gender=Fem|Number=Sing|PronType=Art}\n",
      "7 {'text': '@chinasuarez', 'lemma': '@chinasuarez', 'dep': 'nsubj', 'pos': 'PROPN', 'morph': }\n",
      "8 {'text': 'sería', 'lemma': 'ser', 'dep': 'cop', 'pos': 'AUX', 'morph': Mood=Cnd|Number=Sing|Person=3|VerbForm=Fin}\n",
      "9 {'text': 'aún', 'lemma': 'aún', 'dep': 'advmod', 'pos': 'ADV', 'morph': }\n",
      "10 {'text': 'más', 'lemma': 'más', 'dep': 'advmod', 'pos': 'ADV', 'morph': Degree=Cmp}\n",
      "11 {'text': 'T', 'lemma': 'T', 'dep': 'ccomp', 'pos': 'PROPN', 'morph': }\n",
      "12 {'text': 'R', 'lemma': 'R', 'dep': 'flat', 'pos': 'PROPN', 'morph': }\n",
      "13 {'text': 'O', 'lemma': 'O', 'dep': 'flat', 'pos': 'CCONJ', 'morph': }\n",
      "14 {'text': 'L', 'lemma': 'L', 'dep': 'flat', 'pos': 'PROPN', 'morph': }\n",
      "15 {'text': 'A', 'lemma': 'A', 'dep': 'flat', 'pos': 'PROPN', 'morph': }\n",
      "16 {'text': 'de', 'lemma': 'de', 'dep': 'mark', 'pos': 'ADP', 'morph': }\n",
      "17 {'text': 'lo', 'lemma': 'él', 'dep': 'det', 'pos': 'PRON', 'morph': Case=Acc|Definite=Def|Gender=Masc|Number=Sing|Person=3|PrepCase=Npr|PronType=Prs}\n",
      "18 {'text': 'q', 'lemma': 'q', 'dep': 'obj', 'pos': 'PRON', 'morph': PronType=Int,Rel}\n",
      "19 {'text': 'ya', 'lemma': 'ya', 'dep': 'advmod', 'pos': 'ADV', 'morph': }\n",
      "20 {'text': 'le', 'lemma': 'él', 'dep': 'obj', 'pos': 'PRON', 'morph': Case=Dat|Number=Sing|Person=3|PronType=Prs}\n",
      "21 {'text': 'mostró', 'lemma': 'mostrar', 'dep': 'advcl', 'pos': 'VERB', 'morph': Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin}\n",
      "*** V2 found: ('mostró', 21) ***\n",
      "22 {'text': 'al', 'lemma': 'al', 'dep': 'case', 'pos': 'ADP', 'morph': Definite=Def|Gender=Masc|Number=Sing|PronType=Art}\n",
      "23 {'text': '🌍', 'lemma': '🌍', 'dep': 'obj', 'pos': 'PROPN', 'morph': }\n",
      "24 {'text': '🌎', 'lemma': '🌎', 'dep': 'obj', 'pos': 'PROPN', 'morph': }\n",
      "25 {'text': 'y', 'lemma': 'y', 'dep': 'obj', 'pos': 'PROPN', 'morph': }\n",
      "26 {'text': 'le', 'lemma': 'él', 'dep': 'dep', 'pos': 'PRON', 'morph': Case=Dat|Number=Sing|Person=3|PronType=Prs}\n",
      "27 {'text': 'seguiría', 'lemma': 'seguir', 'dep': 'ccomp', 'pos': 'VERB', 'morph': Mood=Cnd|Number=Sing|Person=3|VerbForm=Fin}\n",
      "28 {'text': 'escribiendo', 'lemma': 'escribir', 'dep': 'xcomp', 'pos': 'VERB', 'morph': VerbForm=Ger}\n",
      "29 {'text': 'a', 'lemma': 'a', 'dep': 'case', 'pos': 'ADP', 'morph': }\n",
      "30 {'text': 'Icardi', 'lemma': 'Icardi', 'dep': 'obj', 'pos': 'PROPN', 'morph': }\n",
      "31 {'text': '(', 'lemma': '(', 'dep': 'punct', 'pos': 'PUNCT', 'morph': PunctSide=Ini|PunctType=Brck}\n",
      "32 {'text': 'a', 'lemma': 'a', 'dep': 'mark', 'pos': 'ADP', 'morph': }\n",
      "33 {'text': 'pesar', 'lemma': 'pesar', 'dep': 'fixed', 'pos': 'NOUN', 'morph': }\n",
      "34 {'text': 'de', 'lemma': 'de', 'dep': 'fixed', 'pos': 'ADP', 'morph': }\n",
      "35 {'text': 'q', 'lemma': 'q', 'dep': 'fixed', 'pos': 'SCONJ', 'morph': }\n",
      "36 {'text': 'creo', 'lemma': 'creer', 'dep': 'parataxis', 'pos': 'VERB', 'morph': Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin}\n",
      "37 {'text': 'ya', 'lemma': 'ya', 'dep': 'advmod', 'pos': 'ADV', 'morph': }\n",
      "38 {'text': 'se', 'lemma': 'él', 'dep': 'expl:pv', 'pos': 'PRON', 'morph': Case=Acc|Person=3|PrepCase=Npr|PronType=Prs|Reflex=Yes}\n",
      "39 {'text': 'enteró', 'lemma': 'enterar', 'dep': 'xcomp', 'pos': 'VERB', 'morph': Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin}\n",
      "40 {'text': 'de', 'lemma': 'de', 'dep': 'mark', 'pos': 'ADP', 'morph': }\n",
      "41 {'text': 'q', 'lemma': 'q', 'dep': 'mark', 'pos': 'SCONJ', 'morph': }\n",
      "42 {'text': 'el', 'lemma': 'el', 'dep': 'nsubj', 'pos': 'DET', 'morph': Definite=Def|Gender=Masc|Number=Sing|PronType=Art}\n",
      "43 {'text': 'sigue', 'lemma': 'seguir', 'dep': 'ccomp', 'pos': 'VERB', 'morph': Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin}\n",
      "44 {'text': 'casado', 'lemma': 'casado', 'dep': 'obj', 'pos': 'ADJ', 'morph': Gender=Masc|Number=Sing|VerbForm=Part}\n",
      "45 {'text': ')', 'lemma': ')', 'dep': 'punct', 'pos': 'PUNCT', 'morph': PunctSide=Fin|PunctType=Brck}\n",
      "46 {'text': '?', 'lemma': '?', 'dep': 'punct', 'pos': 'PUNCT', 'morph': PunctSide=Fin|PunctType=Qest}\n",
      "47 {'text': 'Yo', 'lemma': 'yo', 'dep': 'nsubj', 'pos': 'PRON', 'morph': Case=Nom|Number=Sing|Person=1|PronType=Prs}\n",
      "48 {'text': 'No', 'lemma': 'no', 'dep': 'advmod', 'pos': 'ADV', 'morph': Polarity=Neg}\n",
      "49 {'text': 'creo', 'lemma': 'creer', 'dep': 'ROOT', 'pos': 'VERB', 'morph': Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin}\n",
      "50 {'text': '...', 'lemma': '...', 'dep': 'punct', 'pos': 'PUNCT', 'morph': PunctType=Comm}\n",
      "51 {'text': 'tiene', 'lemma': 'tener', 'dep': 'advcl', 'pos': 'VERB', 'morph': Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin}\n",
      "52 {'text': 'hij@s', 'lemma': 'hij@s', 'dep': 'obj', 'pos': 'PROPN', 'morph': }\n",
      "53 {'text': '!', 'lemma': '!', 'dep': 'punct', 'pos': 'PUNCT', 'morph': PunctSide=Fin|PunctType=Excl}\n",
      "54 {'text': '\\n', 'lemma': '\\n', 'dep': 'dep', 'pos': 'SPACE', 'morph': }\n",
      "55 {'text': '#', 'lemma': '#', 'dep': 'nmod', 'pos': 'SYM', 'morph': }\n",
      "56 {'text': 'ElShowDeLosEscandalones', 'lemma': 'ElShowDeLosEscandalones', 'dep': 'obj', 'pos': 'PROPN', 'morph': }\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'v2': ('mostró', 21), 'v2_dist': 16, 'ccomp_dist': 22}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_range_info(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "776be957",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_info = ndata.apply(get_range_info, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "acdd9e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccomp = range_info.apply(lambda x: x['ccomp']).rename('ccomp')\n",
    "ccomp_dist = range_info.apply(lambda x: x['ccomp_dist']).rename('ccomp_dist')\n",
    "v2 = range_info.apply(lambda x: x['v2']).rename('v2')\n",
    "v2_dist = range_info.apply(lambda x: x['v2_dist']).rename('v2_dist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d2cdbf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdata = pd.concat(\n",
    "    [ndata.loc[:, ['tweet_id','in_comp','verbs','head']],\n",
    "     ccomp,\n",
    "     ccomp_dist, \n",
    "     v2, \n",
    "     v2_dist, \n",
    "     ndata.loc[:, ['text_orig','dependencies','ccomp_head_detail','details']]\n",
    "    ], axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "9a4d749a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_comp</th>\n",
       "      <th>verbs</th>\n",
       "      <th>head</th>\n",
       "      <th>ccomp</th>\n",
       "      <th>ccomp_dist</th>\n",
       "      <th>v2</th>\n",
       "      <th>v2_dist</th>\n",
       "      <th>text_orig</th>\n",
       "      <th>dependencies</th>\n",
       "      <th>ccomp_head_detail</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1453514708506525952</td>\n",
       "      <td>que</td>\n",
       "      <td>['entender', 'creer']</td>\n",
       "      <td>entender</td>\n",
       "      <td>(creen, 6)</td>\n",
       "      <td>2</td>\n",
       "      <td>(creen, 6)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>@nabbp08 @IvanCepedaCast No entiendo porqué al...</td>\n",
       "      <td>@nabbp08[ROOT] @ivancepedacast[flat] no[advmo...</td>\n",
       "      <td>{'entender': (('entiendo', 3), ('creen', 6)), ...</td>\n",
       "      <td>{0: {'text': '@nabbp08', 'lemma': '@nabbp08', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1453514708506525952</td>\n",
       "      <td>que</td>\n",
       "      <td>['entender', 'creer']</td>\n",
       "      <td>creer</td>\n",
       "      <td>(tiene, 21)</td>\n",
       "      <td>10</td>\n",
       "      <td>(tiene, 21)</td>\n",
       "      <td>10.0</td>\n",
       "      <td>@nabbp08 @IvanCepedaCast No entiendo porqué al...</td>\n",
       "      <td>@nabbp08[ROOT] @ivancepedacast[flat] no[advmo...</td>\n",
       "      <td>{'entender': (('entiendo', 3), ('creen', 6)), ...</td>\n",
       "      <td>{0: {'text': '@nabbp08', 'lemma': '@nabbp08', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1455655561773690880</td>\n",
       "      <td>que</td>\n",
       "      <td>['mostrar', 'creer']</td>\n",
       "      <td>creer</td>\n",
       "      <td>(idiotas, 38)</td>\n",
       "      <td>5</td>\n",
       "      <td>(hacía, 43)</td>\n",
       "      <td>10.0</td>\n",
       "      <td>@alferdez habla de país y su deuda. Muestra in...</td>\n",
       "      <td>@alferdez[nsubj] habla[ROOT] de[case] país[ob...</td>\n",
       "      <td>{'creer': (('Creerá', 32), ('idiotas', 38))}</td>\n",
       "      <td>{0: {'text': '@alferdez', 'lemma': '@alferdez'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1455544578203913984</td>\n",
       "      <td>que</td>\n",
       "      <td>['pedir', 'entender', 'creer']</td>\n",
       "      <td>creer</td>\n",
       "      <td>(entendido, 7)</td>\n",
       "      <td>4</td>\n",
       "      <td>(entendido, 7)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>@diego_espacio @E_FLEISCHMAN Creo q ni tú has ...</td>\n",
       "      <td>@diego_espacio[ROOT] @e_fleischman[flat] CREO...</td>\n",
       "      <td>{'creer': (('Creo', 2), ('entendido', 7)), 'en...</td>\n",
       "      <td>{0: {'text': '@diego_espacio', 'lemma': '@dieg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1455544578203913984</td>\n",
       "      <td>que</td>\n",
       "      <td>['pedir', 'entender', 'creer']</td>\n",
       "      <td>entender</td>\n",
       "      <td>(preguntado, 11)</td>\n",
       "      <td>3</td>\n",
       "      <td>(preguntado, 11)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>@diego_espacio @E_FLEISCHMAN Creo q ni tú has ...</td>\n",
       "      <td>@diego_espacio[ROOT] @e_fleischman[flat] CREO...</td>\n",
       "      <td>{'creer': (('Creo', 2), ('entendido', 7)), 'en...</td>\n",
       "      <td>{0: {'text': '@diego_espacio', 'lemma': '@dieg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id in_comp                           verbs      head  \\\n",
       "0  1453514708506525952     que           ['entender', 'creer']  entender   \n",
       "1  1453514708506525952     que           ['entender', 'creer']     creer   \n",
       "2  1455655561773690880     que            ['mostrar', 'creer']     creer   \n",
       "3  1455544578203913984     que  ['pedir', 'entender', 'creer']     creer   \n",
       "4  1455544578203913984     que  ['pedir', 'entender', 'creer']  entender   \n",
       "\n",
       "              ccomp  ccomp_dist                v2  v2_dist  \\\n",
       "0        (creen, 6)           2        (creen, 6)      2.0   \n",
       "1       (tiene, 21)          10       (tiene, 21)     10.0   \n",
       "2     (idiotas, 38)           5       (hacía, 43)     10.0   \n",
       "3    (entendido, 7)           4    (entendido, 7)      4.0   \n",
       "4  (preguntado, 11)           3  (preguntado, 11)      3.0   \n",
       "\n",
       "                                           text_orig  \\\n",
       "0  @nabbp08 @IvanCepedaCast No entiendo porqué al...   \n",
       "1  @nabbp08 @IvanCepedaCast No entiendo porqué al...   \n",
       "2  @alferdez habla de país y su deuda. Muestra in...   \n",
       "3  @diego_espacio @E_FLEISCHMAN Creo q ni tú has ...   \n",
       "4  @diego_espacio @E_FLEISCHMAN Creo q ni tú has ...   \n",
       "\n",
       "                                        dependencies  \\\n",
       "0   @nabbp08[ROOT] @ivancepedacast[flat] no[advmo...   \n",
       "1   @nabbp08[ROOT] @ivancepedacast[flat] no[advmo...   \n",
       "2   @alferdez[nsubj] habla[ROOT] de[case] país[ob...   \n",
       "3   @diego_espacio[ROOT] @e_fleischman[flat] CREO...   \n",
       "4   @diego_espacio[ROOT] @e_fleischman[flat] CREO...   \n",
       "\n",
       "                                   ccomp_head_detail  \\\n",
       "0  {'entender': (('entiendo', 3), ('creen', 6)), ...   \n",
       "1  {'entender': (('entiendo', 3), ('creen', 6)), ...   \n",
       "2       {'creer': (('Creerá', 32), ('idiotas', 38))}   \n",
       "3  {'creer': (('Creo', 2), ('entendido', 7)), 'en...   \n",
       "4  {'creer': (('Creo', 2), ('entendido', 7)), 'en...   \n",
       "\n",
       "                                             details  \n",
       "0  {0: {'text': '@nabbp08', 'lemma': '@nabbp08', ...  \n",
       "1  {0: {'text': '@nabbp08', 'lemma': '@nabbp08', ...  \n",
       "2  {0: {'text': '@alferdez', 'lemma': '@alferdez'...  \n",
       "3  {0: {'text': '@diego_espacio', 'lemma': '@dieg...  \n",
       "4  {0: {'text': '@diego_espacio', 'lemma': '@dieg...  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "65f041f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norm(tweet):\n",
    "    # TODO 3/11: update docs\n",
    "    \"\"\"Normalize original text to be easier for qualitative analysis; relies on other analysis methods\"\"\"\n",
    "    norm = ''\n",
    "    que_variations = {'que','q','k','ke'}\n",
    "    \n",
    "    for t in tweet:\n",
    "        tuni = unidecode(t.text).lower() # unidecoded to check for 'que' variations using only English characters\n",
    "        text = ''\n",
    "        \n",
    "        if t.is_punct:\n",
    "            text = t.text\n",
    "            \n",
    "        elif tuni in que_variations:\n",
    "            text = t.text.upper()\n",
    "            \n",
    "#         elif t.dep_ == 'ccomp':\n",
    "#             head = f'{t.head} -> {t.text}'\n",
    "#             ccomp_head.append(t.head)\n",
    "        \n",
    "        elif (t.pos_=='VERB') and (t.lemma_ in verbs):\n",
    "            text = t.text.upper()\n",
    "            if t.dep_=='ccomp':\n",
    "                text = f'<<{text}>>'\n",
    "            \n",
    "        else:\n",
    "            text = t.text.lower()\n",
    "            \n",
    "        norm += ' ' + text\n",
    "    \n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "d1914392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(tweet):\n",
    "    # TODO 3/11: update docs\n",
    "    \"\"\"Normalize original text to be easier for qualitative analysis; relies on other analysis methods\"\"\"\n",
    "    QUE_VARS = {'que','q','k','ke'}\n",
    "    \n",
    "    norm = ''\n",
    "    head = tweet['head']\n",
    "    head_idx = tweet['ccomp_head_detail'][head][0][1]\n",
    "    v2, v2_idx = tweet['v2'] if tweet['v2'] is not None else (None, None)\n",
    "    ccomp, ccomp_idx = tweet['ccomp']\n",
    "    \n",
    "    for i, t in tweet['details'].items():\n",
    "        tuni = unidecode(t['text']).lower() # unidecoded to check for 'que' variations using only English characters\n",
    "        text = ''\n",
    "        \n",
    "        if t['pos'] == 'PUNCT':\n",
    "            text = t['text']\n",
    "            \n",
    "        elif i == head_idx:\n",
    "            text = '>>' + t['text'].upper()\n",
    "        \n",
    "        # only mark V2 if V2 != ccomp\n",
    "        elif (i == v2_idx) and (v2_idx != ccomp_idx):\n",
    "            text = t['text'].upper() + '[V2]'\n",
    "        \n",
    "        elif i == ccomp_idx:\n",
    "            text = t['text'].upper() + '<<'\n",
    "            \n",
    "        elif tuni in QUE_VARS:\n",
    "            text = t['text'].upper()\n",
    "            \n",
    "        else:\n",
    "            text = t['text'].lower()\n",
    "            \n",
    "        norm += ' ' + text\n",
    "    \n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "45b0d2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     @nabbp08 @ivancepedacast no >>ENTIENDO porqué...\n",
       "1     @nabbp08 @ivancepedacast no entiendo porqué a...\n",
       "2     @alferdez habla de país y su deuda . muestra ...\n",
       "3     @diego_espacio @e_fleischman >>CREO Q ni tú h...\n",
       "4     @diego_espacio @e_fleischman creo Q ni tú has...\n",
       "Name: text_norm, dtype: object"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_new = fdata.apply(normalize, axis=1).rename('text_norm')\n",
    "norm_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "fab6b38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdata = pd.concat([\n",
    "    fdata.iloc[:, :9],\n",
    "    norm_new,\n",
    "    fdata.iloc[:, 9:]\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "d75bab22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_comp</th>\n",
       "      <th>verbs</th>\n",
       "      <th>head</th>\n",
       "      <th>ccomp</th>\n",
       "      <th>ccomp_dist</th>\n",
       "      <th>v2</th>\n",
       "      <th>v2_dist</th>\n",
       "      <th>text_orig</th>\n",
       "      <th>text_norm</th>\n",
       "      <th>dependencies</th>\n",
       "      <th>ccomp_head_detail</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1453514708506525952</td>\n",
       "      <td>que</td>\n",
       "      <td>['entender', 'creer']</td>\n",
       "      <td>entender</td>\n",
       "      <td>(creen, 6)</td>\n",
       "      <td>2</td>\n",
       "      <td>(creen, 6)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>@nabbp08 @IvanCepedaCast No entiendo porqué al...</td>\n",
       "      <td>@nabbp08 @ivancepedacast no &gt;&gt;ENTIENDO porqué...</td>\n",
       "      <td>@nabbp08[ROOT] @ivancepedacast[flat] no[advmo...</td>\n",
       "      <td>{'entender': (('entiendo', 3), ('creen', 6)), ...</td>\n",
       "      <td>{0: {'text': '@nabbp08', 'lemma': '@nabbp08', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1453514708506525952</td>\n",
       "      <td>que</td>\n",
       "      <td>['entender', 'creer']</td>\n",
       "      <td>creer</td>\n",
       "      <td>(tiene, 21)</td>\n",
       "      <td>10</td>\n",
       "      <td>(tiene, 21)</td>\n",
       "      <td>10.0</td>\n",
       "      <td>@nabbp08 @IvanCepedaCast No entiendo porqué al...</td>\n",
       "      <td>@nabbp08 @ivancepedacast no entiendo porqué a...</td>\n",
       "      <td>@nabbp08[ROOT] @ivancepedacast[flat] no[advmo...</td>\n",
       "      <td>{'entender': (('entiendo', 3), ('creen', 6)), ...</td>\n",
       "      <td>{0: {'text': '@nabbp08', 'lemma': '@nabbp08', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1455655561773690880</td>\n",
       "      <td>que</td>\n",
       "      <td>['mostrar', 'creer']</td>\n",
       "      <td>creer</td>\n",
       "      <td>(idiotas, 38)</td>\n",
       "      <td>5</td>\n",
       "      <td>(hacía, 43)</td>\n",
       "      <td>10.0</td>\n",
       "      <td>@alferdez habla de país y su deuda. Muestra in...</td>\n",
       "      <td>@alferdez habla de país y su deuda . muestra ...</td>\n",
       "      <td>@alferdez[nsubj] habla[ROOT] de[case] país[ob...</td>\n",
       "      <td>{'creer': (('Creerá', 32), ('idiotas', 38))}</td>\n",
       "      <td>{0: {'text': '@alferdez', 'lemma': '@alferdez'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1455544578203913984</td>\n",
       "      <td>que</td>\n",
       "      <td>['pedir', 'entender', 'creer']</td>\n",
       "      <td>creer</td>\n",
       "      <td>(entendido, 7)</td>\n",
       "      <td>4</td>\n",
       "      <td>(entendido, 7)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>@diego_espacio @E_FLEISCHMAN Creo q ni tú has ...</td>\n",
       "      <td>@diego_espacio @e_fleischman &gt;&gt;CREO Q ni tú h...</td>\n",
       "      <td>@diego_espacio[ROOT] @e_fleischman[flat] CREO...</td>\n",
       "      <td>{'creer': (('Creo', 2), ('entendido', 7)), 'en...</td>\n",
       "      <td>{0: {'text': '@diego_espacio', 'lemma': '@dieg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1455544578203913984</td>\n",
       "      <td>que</td>\n",
       "      <td>['pedir', 'entender', 'creer']</td>\n",
       "      <td>entender</td>\n",
       "      <td>(preguntado, 11)</td>\n",
       "      <td>3</td>\n",
       "      <td>(preguntado, 11)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>@diego_espacio @E_FLEISCHMAN Creo q ni tú has ...</td>\n",
       "      <td>@diego_espacio @e_fleischman creo Q ni tú has...</td>\n",
       "      <td>@diego_espacio[ROOT] @e_fleischman[flat] CREO...</td>\n",
       "      <td>{'creer': (('Creo', 2), ('entendido', 7)), 'en...</td>\n",
       "      <td>{0: {'text': '@diego_espacio', 'lemma': '@dieg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id in_comp                           verbs      head  \\\n",
       "0  1453514708506525952     que           ['entender', 'creer']  entender   \n",
       "1  1453514708506525952     que           ['entender', 'creer']     creer   \n",
       "2  1455655561773690880     que            ['mostrar', 'creer']     creer   \n",
       "3  1455544578203913984     que  ['pedir', 'entender', 'creer']     creer   \n",
       "4  1455544578203913984     que  ['pedir', 'entender', 'creer']  entender   \n",
       "\n",
       "              ccomp  ccomp_dist                v2  v2_dist  \\\n",
       "0        (creen, 6)           2        (creen, 6)      2.0   \n",
       "1       (tiene, 21)          10       (tiene, 21)     10.0   \n",
       "2     (idiotas, 38)           5       (hacía, 43)     10.0   \n",
       "3    (entendido, 7)           4    (entendido, 7)      4.0   \n",
       "4  (preguntado, 11)           3  (preguntado, 11)      3.0   \n",
       "\n",
       "                                           text_orig  \\\n",
       "0  @nabbp08 @IvanCepedaCast No entiendo porqué al...   \n",
       "1  @nabbp08 @IvanCepedaCast No entiendo porqué al...   \n",
       "2  @alferdez habla de país y su deuda. Muestra in...   \n",
       "3  @diego_espacio @E_FLEISCHMAN Creo q ni tú has ...   \n",
       "4  @diego_espacio @E_FLEISCHMAN Creo q ni tú has ...   \n",
       "\n",
       "                                           text_norm  \\\n",
       "0   @nabbp08 @ivancepedacast no >>ENTIENDO porqué...   \n",
       "1   @nabbp08 @ivancepedacast no entiendo porqué a...   \n",
       "2   @alferdez habla de país y su deuda . muestra ...   \n",
       "3   @diego_espacio @e_fleischman >>CREO Q ni tú h...   \n",
       "4   @diego_espacio @e_fleischman creo Q ni tú has...   \n",
       "\n",
       "                                        dependencies  \\\n",
       "0   @nabbp08[ROOT] @ivancepedacast[flat] no[advmo...   \n",
       "1   @nabbp08[ROOT] @ivancepedacast[flat] no[advmo...   \n",
       "2   @alferdez[nsubj] habla[ROOT] de[case] país[ob...   \n",
       "3   @diego_espacio[ROOT] @e_fleischman[flat] CREO...   \n",
       "4   @diego_espacio[ROOT] @e_fleischman[flat] CREO...   \n",
       "\n",
       "                                   ccomp_head_detail  \\\n",
       "0  {'entender': (('entiendo', 3), ('creen', 6)), ...   \n",
       "1  {'entender': (('entiendo', 3), ('creen', 6)), ...   \n",
       "2       {'creer': (('Creerá', 32), ('idiotas', 38))}   \n",
       "3  {'creer': (('Creo', 2), ('entendido', 7)), 'en...   \n",
       "4  {'creer': (('Creo', 2), ('entendido', 7)), 'en...   \n",
       "\n",
       "                                             details  \n",
       "0  {0: {'text': '@nabbp08', 'lemma': '@nabbp08', ...  \n",
       "1  {0: {'text': '@nabbp08', 'lemma': '@nabbp08', ...  \n",
       "2  {0: {'text': '@alferdez', 'lemma': '@alferdez'...  \n",
       "3  {0: {'text': '@diego_espacio', 'lemma': '@dieg...  \n",
       "4  {0: {'text': '@diego_espacio', 'lemma': '@dieg...  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "838ce05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdata.to_excel(data_dir[0]/'added-distances-(FOR ADRIAN twitter-es-creer-5-912 (1)CLEAR ANNOTATION).xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f30a87a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
