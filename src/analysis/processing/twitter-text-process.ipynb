{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5a87de5",
   "metadata": {},
   "source": [
    "### References\n",
    "Bird, Steven, Edward Loper and Ewan Klein (2009), Natural Language Processing with Python. O’Reilly Media Inc.\n",
    "\n",
    "https://www.kaggle.com/alxmamaev/how-to-easy-preprocess-russian-text\n",
    "\n",
    "https://python-school.ru/nlp-text-preprocessing/\n",
    "\n",
    "https://pymorphy2.readthedocs.io/en/latest/user/guide.html\n",
    "\n",
    "https://stackoverflow.com/a/49242754/13557629 (finding emojis)\n",
    "\n",
    "https://www.machinelearningplus.com/nlp/lemmatization-examples-python/#wordnetlemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60629f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import regex\n",
    "import yaml\n",
    "import logging\n",
    "from logging import config\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "\n",
    "import spacy\n",
    "spacy.require_gpu()\n",
    "from torch.utils import dlpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06d3137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import importlib.util as imp\n",
    "import sys\n",
    "\n",
    "spec_conn = imp.spec_from_file_location(\n",
    "    'twitter_connection',\n",
    "    '../twitter-connection/__init__.py')\n",
    "sc = imp.module_from_spec(spec_conn)\n",
    "sys.modules[spec_conn.name] = sc\n",
    "spec_conn.loader.exec_module(sc)\n",
    "\n",
    "spec_data = imp.spec_from_file_location(\n",
    "    'twitter_data',\n",
    "    '../twitter-connection/twitter_data/__init__.py')\n",
    "sd = imp.module_from_spec(spec_data)\n",
    "sys.modules[spec_data.name] = sd\n",
    "spec_data.loader.exec_module(sd)\n",
    "\n",
    "from twitter_connection.util import utils\n",
    "from twitter_connection import processing\n",
    "from twitter_data import twitter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d9b286a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(utils.get_project_root()/'log_config.yml', 'r') as f:\n",
    "        lc = yaml.safe_load(f)\n",
    "        config.dictConfig(lc)\n",
    "        \n",
    "        logger = logging.getLogger('processing')\n",
    "except Exception as e:\n",
    "    print(e.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142ae914",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Reload module\n",
    "\"\"\"\n",
    "importlib.reload(twitter_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acf49809",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_conf = utils.get_config()\n",
    "conf = utils.get_config('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d45bc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_conj_path = utils.get_project_root()/gen_conf['file_paths']['verb_conjug']\n",
    "cleaned_folder = '12062021'\n",
    "cleaned_path = utils.get_save_path(data_from='tweets', where='c', lang='es', is_test=False)/cleaned_folder\n",
    "processed_folder = '12062021'\n",
    "processed_path = utils.get_save_path(data_from='tweets', where='p', lang='es', is_test=False)/processed_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52df70a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb_type</th>\n",
       "      <th>verb</th>\n",
       "      <th>indicativo</th>\n",
       "      <th>imperativo</th>\n",
       "      <th>subjuntivo</th>\n",
       "      <th>gerundio</th>\n",
       "      <th>gerundio_compuesto</th>\n",
       "      <th>infinitivo</th>\n",
       "      <th>infinitivo_compuesto</th>\n",
       "      <th>participio_pasado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stative</td>\n",
       "      <td>ver</td>\n",
       "      <td>veía  visto  verías  vi  vimos  verían  ves  v...</td>\n",
       "      <td>vean   ve   vea   veamos   ved</td>\n",
       "      <td>veáis  visto  vieras  vieren  viesen  veas  vi...</td>\n",
       "      <td>viendo</td>\n",
       "      <td>visto</td>\n",
       "      <td>ver</td>\n",
       "      <td>visto</td>\n",
       "      <td>visto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stative</td>\n",
       "      <td>jurar</td>\n",
       "      <td>jurarán  juramos  jurarías  jurabas  juraría  ...</td>\n",
       "      <td>jurad   jura   juren   jure   juremos</td>\n",
       "      <td>jurare  jurareis  jurase  jurara  juraren  jur...</td>\n",
       "      <td>jurando</td>\n",
       "      <td>jurado</td>\n",
       "      <td>jurar</td>\n",
       "      <td>jurado</td>\n",
       "      <td>jurado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  verb_type   verb                                         indicativo  \\\n",
       "0   Stative    ver  veía  visto  verías  vi  vimos  verían  ves  v...   \n",
       "1   Stative  jurar  jurarán  juramos  jurarías  jurabas  juraría  ...   \n",
       "\n",
       "                               imperativo  \\\n",
       "0         vean   ve   vea   veamos   ved    \n",
       "1  jurad   jura   juren   jure   juremos    \n",
       "\n",
       "                                          subjuntivo gerundio  \\\n",
       "0  veáis  visto  vieras  vieren  viesen  veas  vi...   viendo   \n",
       "1  jurare  jurareis  jurase  jurara  juraren  jur...  jurando   \n",
       "\n",
       "  gerundio_compuesto infinitivo infinitivo_compuesto participio_pasado  \n",
       "0              visto        ver                visto             visto  \n",
       "1             jurado      jurar               jurado            jurado  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "es_conjugs = pd.read_excel(es_conj_path)\n",
    "display(es_conjugs.head(2))\n",
    "\n",
    "es_verbs = set(es_conjugs['verb'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18316b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text_orig</th>\n",
       "      <th>author_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_place_id</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>mentions</th>\n",
       "      <th>text_norm</th>\n",
       "      <th>retweet_reply_like_quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-08 03:15:45+00:00</td>\n",
       "      <td>Esta derrota de Quindio confirma que el Superd...</td>\n",
       "      <td>141323312.0</td>\n",
       "      <td>es</td>\n",
       "      <td>1.457547e+18</td>\n",
       "      <td>0116b409205a5237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Esta derrota de Quindio confirma que el Superd...</td>\n",
       "      <td>(0, 0, 4, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-08 03:15:11+00:00</td>\n",
       "      <td>Muajaja ese broder confirmó lo q les dije... L...</td>\n",
       "      <td>49454158.0</td>\n",
       "      <td>es</td>\n",
       "      <td>1.457547e+18</td>\n",
       "      <td>011455904ec2ab81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Muajaja ese broder confirmo lo q les dije... L...</td>\n",
       "      <td>(0, 0, 0, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-11-08 03:08:56+00:00</td>\n",
       "      <td>@gabrielintica @rebecajc Mis 22 años siendo c-...</td>\n",
       "      <td>26833188.0</td>\n",
       "      <td>es</td>\n",
       "      <td>1.457546e+18</td>\n",
       "      <td>6eb95eddb81a6b4b</td>\n",
       "      <td>['1457523752795844611']</td>\n",
       "      <td>[{'start': 0, 'end': 14, 'username': 'gabrieli...</td>\n",
       "      <td>Mis 22 anos siendo c-nora lo confirman.</td>\n",
       "      <td>(0, 0, 0, 0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  created_at  \\\n",
       "0  2021-11-08 03:15:45+00:00   \n",
       "1  2021-11-08 03:15:11+00:00   \n",
       "2  2021-11-08 03:08:56+00:00   \n",
       "\n",
       "                                           text_orig    author_id lang  \\\n",
       "0  Esta derrota de Quindio confirma que el Superd...  141323312.0   es   \n",
       "1  Muajaja ese broder confirmó lo q les dije... L...   49454158.0   es   \n",
       "2  @gabrielintica @rebecajc Mis 22 años siendo c-...   26833188.0   es   \n",
       "\n",
       "       tweet_id    tweet_place_id        referenced_tweets  \\\n",
       "0  1.457547e+18  0116b409205a5237                      NaN   \n",
       "1  1.457547e+18  011455904ec2ab81                      NaN   \n",
       "2  1.457546e+18  6eb95eddb81a6b4b  ['1457523752795844611']   \n",
       "\n",
       "                                            mentions  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  [{'start': 0, 'end': 14, 'username': 'gabrieli...   \n",
       "\n",
       "                                           text_norm retweet_reply_like_quote  \n",
       "0  Esta derrota de Quindio confirma que el Superd...             (0, 0, 4, 0)  \n",
       "1  Muajaja ese broder confirmo lo q les dije... L...             (0, 0, 0, 0)  \n",
       "2            Mis 22 anos siendo c-nora lo confirman.             (0, 0, 0, 0)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 408362 entries, 0 to 408361\n",
      "Data columns (total 10 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   created_at                408362 non-null  object \n",
      " 1   text_orig                 408362 non-null  object \n",
      " 2   author_id                 408362 non-null  float64\n",
      " 3   lang                      408362 non-null  object \n",
      " 4   tweet_id                  408362 non-null  float64\n",
      " 5   tweet_place_id            408358 non-null  object \n",
      " 6   referenced_tweets         253215 non-null  object \n",
      " 7   mentions                  259972 non-null  object \n",
      " 8   text_norm                 408362 non-null  object \n",
      " 9   retweet_reply_like_quote  408362 non-null  object \n",
      "dtypes: float64(2), object(8)\n",
      "memory usage: 31.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets = pd.read_csv(es_cleaned_path/'tweets.csv', sep='~', lineterminator='\\n')\n",
    "display(tweets.head(3))\n",
    "display(tweets.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69158802",
   "metadata": {},
   "source": [
    "### Running through spacy pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34781066",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36084/2393763045.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Disable 'ner' (Named Entity Recognizer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnlp_es\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spacy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'es'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ner'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# nlp_pt = spacy.load(conf['spacy']['pt'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.8/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mRETURNS\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mLanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \"\"\"\n\u001b[0;32m---> 50\u001b[0;31m     return util.load_model(\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     )\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.8/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mget_lang_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"blank:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# installed as package\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# path to model data directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.8/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_package\u001b[0;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \"\"\"\n\u001b[1;32m    356\u001b[0m     \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.8/site-packages/es_dep_news_trf/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(**overrides)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_init_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.8/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_init_py\u001b[0;34m(init_file, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE052\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m     return load_model_from_path(\n\u001b[0m\u001b[1;32m    517\u001b[0m         \u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.8/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_path\u001b[0;34m(model_path, meta, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.8/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mfrom_disk\u001b[0;34m(self, path, exclude)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0;31m# Convert to list here in case exclude is (default) tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m             \u001b[0mexclude\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"vocab\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeserializers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_link_components\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.8/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mfrom_disk\u001b[0;34m(path, readers, exclude)\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0;31m# Split to support file names like meta.json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m             \u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.8/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(p, proc)\u001b[0m\n\u001b[1;32m   1875\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_disk\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1876\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1877\u001b[0;31m             deserializers[name] = lambda p, proc=proc: proc.from_disk(\n\u001b[0m\u001b[1;32m   1878\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vocab\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.8/site-packages/spacy_transformers/pipeline_component.py\u001b[0m in \u001b[0;36mfrom_disk\u001b[0;34m(self, path, exclude)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;34m\"model\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         }\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.8/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mfrom_disk\u001b[0;34m(path, readers, exclude)\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0;31m# Split to support file names like meta.json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m             \u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.8/site-packages/spacy_transformers/pipeline_component.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             tokenizer, transformer = huggingface_from_pretrained(\n\u001b[0m\u001b[1;32m    392\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokenizer_config\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.8/site-packages/spacy_transformers/util.py\u001b[0m in \u001b[0;36mhuggingface_from_pretrained\u001b[0;34m(source, config)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mstr_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mtransformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_current_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCupyOps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         raise ValueError(\n\u001b[1;32m    383\u001b[0m             \u001b[0;34mf\"Unrecognized configuration class {config.__class__} for this kind of AutoModel: {cls.__name__}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mno_init_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_enable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fast_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfrom_tf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, add_pooling_layer)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_position_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_vocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_embeddings, embedding_dim, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse, _weight, device, dtype)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_grad_by_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfactory_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Disable 'ner' (Named Entity Recognizer)\n",
    "nlp_es = spacy.load(conf['spacy']['es'], disable=['ner'])\n",
    "# nlp_pt = spacy.load(conf['spacy']['pt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3877dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verbs(tokenized):\n",
    "    verbs = ', '.join(set(t.lemma_ for t in tokenized if (t.pos_=='VERB') and (t.lemma_ in es_verbs)))\n",
    "    return verbs if len(verbs)>0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562f9b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dep(tokenized):\n",
    "    return ' '.join([f'{t.text}({t.dep_ if t.pos_!=\"PUNCT\" else \"\"})' for t in tokenized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb12e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_details(tokenized):\n",
    "    return ' '.join([f'{t.text}[{t.lemma_}|{t.pos_}|{t.is_stop}]' for t in tokenized if t.pos_!='PUNCT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bde2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def have_verbs(df):\n",
    "    have = df['text_norm'].apply(get_verbs).notna()\n",
    "    return df.loc[have, :].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3125a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_batch(tokenized: list, name):\n",
    "    batch = have_verbs(pd.concat(tokenized, ignore_index=True))\n",
    "    \n",
    "    verbs = batch['text_norm'].apply(get_verbs).rename('verbs')\n",
    "    dep = batch['text_norm'].apply(get_dep).rename('dependencies')\n",
    "    details = batch['text_norm'].apply(get_details).rename('lemma_pos_stopword')\n",
    "    \n",
    "    batch = pd.concat([verbs, batch.loc[:, 'tweet_id'], dep, details], axis=1)\n",
    "    \n",
    "    utils.save_csv(es_save_path, batch, name+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d85239",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_processed = []\n",
    "processed = 0\n",
    "saved = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eabbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.make_dir(es_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6459cf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "err = 0\n",
    "batch_size = 500\n",
    "batches = int(np.ceil(tweets.shape[0]/batch_size))\n",
    "\n",
    "logger.info(f'Running {tweets.shape[0]-processed} tweets through spaCy pipeline')\n",
    "logger.debug(f'Batch size: {batch_size}, batches: {batches}')\n",
    "\n",
    "for i, d in enumerate(np.array_split(tweets.loc[:, ['tweet_id', 'text_norm']], batches)):\n",
    "    # Tweets already processed\n",
    "    if i*batch_size < processed:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        spacy_processed.append(\n",
    "            pd.concat([d['tweet_id'], d['text_norm'].apply(nlp_es)], \n",
    "                      axis=1))\n",
    "        \n",
    "        processed+=batch_size\n",
    "        logger.debug(f'Processed: {processed}')\n",
    "        \n",
    "        if (processed%10000)<batch_size:\n",
    "            logger.debug(f'Saving batch of {sum([p.shape[0] for p in spacy_processed])}')\n",
    "            # Save progress and free up memory\n",
    "            save_batch(spacy_processed, name=f'tweets-processed-{saved}')\n",
    "            saved+=1\n",
    "            \n",
    "            spacy_processed.clear()\n",
    "\n",
    "    except Exception as e:\n",
    "        err+=1\n",
    "        print(f'{i} is broken: {e.args}')\n",
    "        \n",
    "        if err>2:\n",
    "            break\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d812aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_batch(spacy_processed, name=f'tweets-processed-{saved}')\n",
    "saved+=1\n",
    "            \n",
    "spacy_processed.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf0fd94",
   "metadata": {},
   "source": [
    "### Merging Processed Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb4e0a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'twitter_connection.util.utils' from '/home/rimov/Documents/Code/NLP/lin-que-dropping/processing/../twitter-connection/util/utils.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b330211",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tweets_path = Path(es_save_path).rglob('*processed*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1fdc365",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36084/1868410355.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprocessed_tweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocessed_tweets_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \"\"\"\n\u001b[0;32m--> 274\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "processed_tweets = pd.concat([utils.get_csv(p) for p in processed_tweets_path]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f47fbb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 298492 entries, 0 to 298491\n",
      "Data columns (total 4 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   verbs               298492 non-null  string \n",
      " 1   tweet_id            298492 non-null  float64\n",
      " 2   dependencies        298492 non-null  string \n",
      " 3   lemma_pos_stopword  298492 non-null  string \n",
      "dtypes: float64(1), string(3)\n",
      "memory usage: 9.1 MB\n"
     ]
    }
   ],
   "source": [
    "processed_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f0a5ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 298492 entries, 0 to 298491\n",
      "Data columns (total 13 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   verbs                     298492 non-null  string \n",
      " 1   tweet_id                  298492 non-null  float64\n",
      " 2   dependencies              298492 non-null  string \n",
      " 3   lemma_pos_stopword        298492 non-null  string \n",
      " 4   created_at                298492 non-null  object \n",
      " 5   text_orig                 298492 non-null  object \n",
      " 6   author_id                 298492 non-null  float64\n",
      " 7   lang                      298492 non-null  object \n",
      " 8   tweet_place_id            298491 non-null  object \n",
      " 9   referenced_tweets         180174 non-null  object \n",
      " 10  mentions                  185057 non-null  object \n",
      " 11  text_norm                 298492 non-null  object \n",
      " 12  retweet_reply_like_quote  298492 non-null  object \n",
      "dtypes: float64(2), object(8), string(3)\n",
      "memory usage: 31.9+ MB\n"
     ]
    }
   ],
   "source": [
    "merged = pd.merge(processed_tweets, tweets, how='left', on='tweet_id')\n",
    "merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0c68f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename any misnamed columns\n",
    "merged.rename(columns={'author_id': 'user_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a46b181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 298492 entries, 0 to 298491\n",
      "Data columns (total 12 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   tweet_id                  298492 non-null  float64\n",
      " 1   verbs                     298492 non-null  string \n",
      " 2   text_orig                 298492 non-null  object \n",
      " 3   text_norm                 298492 non-null  object \n",
      " 4   dependencies              298492 non-null  string \n",
      " 5   lemma_pos_stopword        298492 non-null  string \n",
      " 6   retweet_reply_like_quote  298492 non-null  object \n",
      " 7   created_at                298492 non-null  object \n",
      " 8   user_id                   298492 non-null  float64\n",
      " 9   tweet_place_id            298491 non-null  object \n",
      " 10  mentions                  185057 non-null  object \n",
      " 11  referenced_tweets         180174 non-null  object \n",
      "dtypes: float64(2), object(7), string(3)\n",
      "memory usage: 29.6+ MB\n"
     ]
    }
   ],
   "source": [
    "merged = merged.loc[:, conf['col_order']]\n",
    "merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4395a259",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_csv(es_save_path, merged, 'tweets-processed-combined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32fe979",
   "metadata": {},
   "source": [
    "### Breaking Up by Verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14d27d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'twitter_connection.util.utils' from '/home/rimov/Documents/Code/NLP/lin-que-dropping/processing/../twitter-connection/util/utils.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d9efe4",
   "metadata": {},
   "source": [
    "merged = utils.get_csv(es_save_path/'tweets-processed-combined.csv')\n",
    "merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9daffb5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>verbs</th>\n",
       "      <th>text_orig</th>\n",
       "      <th>text_norm</th>\n",
       "      <th>dependencies</th>\n",
       "      <th>lemma_pos_stopword</th>\n",
       "      <th>retweet_reply_like_quote</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet_place_id</th>\n",
       "      <th>mentions</th>\n",
       "      <th>referenced_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.451193e+18</td>\n",
       "      <td>[sentir, pedir]</td>\n",
       "      <td>.@CitroenEspana Cactus con 5,5 años. Me empiez...</td>\n",
       "      <td>.Cactus con 5,5 anos. Me empieza a salir oxido...</td>\n",
       "      <td>.Cactus(ROOT) con(case) 5,5(nummod) anos(nmod)...</td>\n",
       "      <td>.Cactus(.Cactus|PROPN|False) con(con|ADP|True)...</td>\n",
       "      <td>(1, 1, 1, 0)</td>\n",
       "      <td>2021-10-21 14:26:05+00:00</td>\n",
       "      <td>3.979609e+08</td>\n",
       "      <td>731c9d11275a5436</td>\n",
       "      <td>[{'start': 1, 'end': 15, 'username': 'CitroenE...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.451193e+18</td>\n",
       "      <td>[sentir]</td>\n",
       "      <td>Me toy bebiendo un té, y siento como que toy s...</td>\n",
       "      <td>Me toy bebiendo un te, y siento como que toy s...</td>\n",
       "      <td>Me(iobj) toy(ROOT) bebiendo(xcomp) un(det) te(...</td>\n",
       "      <td>Me(yo|PRON|True) toy(tar|VERB|False) bebiendo(...</td>\n",
       "      <td>(0, 1, 0, 0)</td>\n",
       "      <td>2021-10-21 14:24:35+00:00</td>\n",
       "      <td>1.238228e+18</td>\n",
       "      <td>01fcc4a23f17e1ed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.451192e+18</td>\n",
       "      <td>[sentir]</td>\n",
       "      <td>El problema más grave que tiene hoy el Maestro...</td>\n",
       "      <td>El problema mas grave que tiene hoy el Maestro...</td>\n",
       "      <td>El(det) problema(nsubj) mas(advmod) grave(amod...</td>\n",
       "      <td>El(el|DET|True) problema(problema|NOUN|False) ...</td>\n",
       "      <td>(0, 0, 0, 0)</td>\n",
       "      <td>2021-10-21 14:22:15+00:00</td>\n",
       "      <td>2.349312e+08</td>\n",
       "      <td>01d487de3c4e0807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id            verbs  \\\n",
       "0  1.451193e+18  [sentir, pedir]   \n",
       "1  1.451193e+18         [sentir]   \n",
       "2  1.451192e+18         [sentir]   \n",
       "\n",
       "                                           text_orig  \\\n",
       "0  .@CitroenEspana Cactus con 5,5 años. Me empiez...   \n",
       "1  Me toy bebiendo un té, y siento como que toy s...   \n",
       "2  El problema más grave que tiene hoy el Maestro...   \n",
       "\n",
       "                                           text_norm  \\\n",
       "0  .Cactus con 5,5 anos. Me empieza a salir oxido...   \n",
       "1  Me toy bebiendo un te, y siento como que toy s...   \n",
       "2  El problema mas grave que tiene hoy el Maestro...   \n",
       "\n",
       "                                        dependencies  \\\n",
       "0  .Cactus(ROOT) con(case) 5,5(nummod) anos(nmod)...   \n",
       "1  Me(iobj) toy(ROOT) bebiendo(xcomp) un(det) te(...   \n",
       "2  El(det) problema(nsubj) mas(advmod) grave(amod...   \n",
       "\n",
       "                                  lemma_pos_stopword retweet_reply_like_quote  \\\n",
       "0  .Cactus(.Cactus|PROPN|False) con(con|ADP|True)...             (1, 1, 1, 0)   \n",
       "1  Me(yo|PRON|True) toy(tar|VERB|False) bebiendo(...             (0, 1, 0, 0)   \n",
       "2  El(el|DET|True) problema(problema|NOUN|False) ...             (0, 0, 0, 0)   \n",
       "\n",
       "                  created_at       user_id    tweet_place_id  \\\n",
       "0  2021-10-21 14:26:05+00:00  3.979609e+08  731c9d11275a5436   \n",
       "1  2021-10-21 14:24:35+00:00  1.238228e+18  01fcc4a23f17e1ed   \n",
       "2  2021-10-21 14:22:15+00:00  2.349312e+08  01d487de3c4e0807   \n",
       "\n",
       "                                            mentions referenced_tweets  \n",
       "0  [{'start': 1, 'end': 15, 'username': 'CitroenE...               NaN  \n",
       "1                                                NaN               NaN  \n",
       "2                                                NaN               NaN  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged['verbs'] = merged['verbs'].str.split(', ')\n",
    "merged.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "67eda838",
   "metadata": {},
   "outputs": [],
   "source": [
    "for verb in es_verbs:\n",
    "    vtype = es_conjugs.loc[es_conjugs['verb']==verb, 'verb_type'].iloc[0].lower()\n",
    "    has_verb = merged['verbs'].apply(lambda verbs: True if verb in set(verbs) else False)\n",
    "\n",
    "    df = merged[has_verb].copy()\n",
    "    \n",
    "    path = utils.get_save_path('p', lang='es')/processed_folder/vtype\n",
    "    \n",
    "    utils.make_dir(path)\n",
    "    utils.save_excel(path, df, f'twitter-es-{verb}-26-07-2021')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430ed350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ca3490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e4f7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d1c728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354cf181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88d344d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cad1e590",
   "metadata": {},
   "source": [
    "### Extracting emojis\n",
    "I believe emojis play a role in language ambiguity, so is necessary to save them in preparation for the lemmatization, which will either cause errors or remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1bbde77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install emoji --upgrade\n",
    "\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "00f9b0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_emoji(tweets):\n",
    "    ts = []\n",
    "    emojis = []\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        words = ''\n",
    "        \n",
    "        for word in tweet.split():\n",
    "            # Read as unicode chars\n",
    "            trans = regex.findall(r'\\X', word)\n",
    "            w = ''\n",
    "        \n",
    "            for c in trans:\n",
    "                if (c in emoji.UNICODE_EMOJI_ENGLISH) or (c=='❤️'):\n",
    "                    emojis.append(c)\n",
    "                    continue\n",
    "                \n",
    "                w+=c\n",
    "            \n",
    "            if len(w) != 0:\n",
    "                words = words + ' ' + w\n",
    "        \n",
    "        ts.append(words)\n",
    "    \n",
    "    return {'text':ts, 'emojis':emojis}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4476d71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ Fabulous Leadership!]</td>\n",
       "      <td>[🇺🇲, 🇺🇲, 🇺🇲, 😊, 😊]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ America is draining itself. I had expected B...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ Glad you are enjoying the beautiful South West]</td>\n",
       "      <td>[😍]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ And the long anticipated badly needed spanki...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ I stand with you. Thank you for all you do.]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text              emojis\n",
       "0                            [ Fabulous Leadership!]  [🇺🇲, 🇺🇲, 🇺🇲, 😊, 😊]\n",
       "1  [ America is draining itself. I had expected B...                  []\n",
       "2  [ Glad you are enjoying the beautiful South West]                 [😍]\n",
       "3  [ And the long anticipated badly needed spanki...                  []\n",
       "4     [ I stand with you. Thank you for all you do.]                  []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ Не выносите себе сами приговор!)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ добрый вечер Радий! (в Италии тоже кто в кур...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ Вот это я понимаю - хорошие новости!]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ Настоящий глава, не то что некоторые!☝️]</td>\n",
       "      <td>[✊]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ Ходить к мерзким людям на мерзкие (теле)пере...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text emojis\n",
       "0                [ Не выносите себе сами приговор!)]     []\n",
       "1  [ добрый вечер Радий! (в Италии тоже кто в кур...     []\n",
       "2            [ Вот это я понимаю - хорошие новости!]     []\n",
       "3         [ Настоящий глава, не то что некоторые!☝️]    [✊]\n",
       "4  [ Ходить к мерзким людям на мерзкие (теле)пере...     []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Converts a series with above 'text', 'emojis' dicts into a df\n",
    "split_en = pd.DataFrame(\n",
    "    list(en_text.apply(extract_emoji)))\n",
    "split_ru = pd.DataFrame(\n",
    "    list(ru_text.apply(extract_emoji)))\n",
    "\n",
    "display(split_en.head())\n",
    "display(split_ru.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "62101aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1003024039621820417</td>\n",
       "      <td>[ Fabulous Leadership!]</td>\n",
       "      <td>[🇺🇲, 🇺🇲, 🇺🇲, 😊, 😊]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1005180474</td>\n",
       "      <td>[ America is draining itself. I had expected B...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1006460630692450304</td>\n",
       "      <td>[ Glad you are enjoying the beautiful South West]</td>\n",
       "      <td>[😍]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author_id                                               text  \\\n",
       "0  1003024039621820417                            [ Fabulous Leadership!]   \n",
       "1           1005180474  [ America is draining itself. I had expected B...   \n",
       "2  1006460630692450304  [ Glad you are enjoying the beautiful South West]   \n",
       "\n",
       "               emojis  \n",
       "0  [🇺🇲, 🇺🇲, 🇺🇲, 😊, 😊]  \n",
       "1                  []  \n",
       "2                 [😍]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1005065863060475904</td>\n",
       "      <td>[ Не выносите себе сами приговор!)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1012429847531065349</td>\n",
       "      <td>[ добрый вечер Радий! (в Италии тоже кто в кур...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1013485198787440640</td>\n",
       "      <td>[ Вот это я понимаю - хорошие новости!]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author_id                                               text  \\\n",
       "0  1005065863060475904                [ Не выносите себе сами приговор!)]   \n",
       "1  1012429847531065349  [ добрый вечер Радий! (в Италии тоже кто в кур...   \n",
       "2  1013485198787440640            [ Вот это я понимаю - хорошие новости!]   \n",
       "\n",
       "  emojis  \n",
       "0     []  \n",
       "1     []  \n",
       "2     []  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "en_text = en_text.to_frame().reset_index().drop(columns='text').join(split_en)\n",
    "ru_text = ru_text.to_frame().reset_index().drop(columns='text').join(split_ru)\n",
    "display(en_text.head(3))\n",
    "display(ru_text.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a4b955db",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_text = pd.concat(\n",
    "    [en_text,\n",
    "     en_text.loc[:, 'emojis'].apply(len).rename('emoji_len')], \n",
    "    axis=1, join='inner')\n",
    "ru_text = pd.concat(\n",
    "    [ru_text,\n",
    "     ru_text.loc[:, 'emojis'].apply(len).rename('emoji_len')], \n",
    "    axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6834e480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoji_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>501659753</td>\n",
       "      <td>[ Thank you, you too,  Aww bless you thank you...</td>\n",
       "      <td>[🥰, 😘, 🥰, 😘, 🥰, 😘, 😘, 🥰, 😘, 🥰, 🥰, 😘, ❤️, 🥰, 😘,...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1241523214028685313</td>\n",
       "      <td>[ Well we know project veritas uncovered cnn a...</td>\n",
       "      <td>[😲, 🤯, 🤯, 🤯, 🤯, 🤯, 🤯, 🤯, 🤯, 🤯, 🤯, 🤯, 🤯, 🤯, 🤯, ...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>2231639652</td>\n",
       "      <td>[ The Scrabble Champion Of The House Then !! H...</td>\n",
       "      <td>[😉, 😉, 💋, ❤️, 💋, 🤗, 🤗, 🤗, ❤️, 💋, 🤗, 🤗, 🤗, ❤️, ❤️]</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1017486629861289984</td>\n",
       "      <td>[ Happy Thursday! Jammin' job Champ Including ...</td>\n",
       "      <td>[🎊, 💪, 👍, 👊, 🏆, ❗, 🎊, 💕, ❤, 😘, 😊]</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>2840137376</td>\n",
       "      <td>[ Recover your hacked, disabled or locked acco...</td>\n",
       "      <td>[📡, 📌, 📌, 📌, 📌, 📌, 📌, 📌, 📌, 📌, 👌]</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1188279481879932928</td>\n",
       "      <td>[ You only have to do a little bit of research...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>1378070190949330948</td>\n",
       "      <td>[ don't know what the point of this is, but al...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1188879217552814082</td>\n",
       "      <td>[ Maybe u ought to get ur hands on a copy of t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>119212393</td>\n",
       "      <td>[ If you're an American scared of Russia or Ch...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>998706493741584384</td>\n",
       "      <td>[ Such a good morning! Look so nice Wendy x]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>563 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               author_id                                               text  \\\n",
       "439            501659753  [ Thank you, you too,  Aww bless you thank you...   \n",
       "89   1241523214028685313  [ Well we know project veritas uncovered cnn a...   \n",
       "302           2231639652  [ The Scrabble Champion Of The House Then !! H...   \n",
       "6    1017486629861289984  [ Happy Thursday! Jammin' job Champ Including ...   \n",
       "343           2840137376  [ Recover your hacked, disabled or locked acco...   \n",
       "..                   ...                                                ...   \n",
       "57   1188279481879932928  [ You only have to do a little bit of research...   \n",
       "245  1378070190949330948  [ don't know what the point of this is, but al...   \n",
       "58   1188879217552814082  [ Maybe u ought to get ur hands on a copy of t...   \n",
       "59             119212393  [ If you're an American scared of Russia or Ch...   \n",
       "562   998706493741584384       [ Such a good morning! Look so nice Wendy x]   \n",
       "\n",
       "                                                emojis  emoji_len  \n",
       "439  [🥰, 😘, 🥰, 😘, 🥰, 😘, 😘, 🥰, 😘, 🥰, 🥰, 😘, ❤️, 🥰, 😘,...         23  \n",
       "89   [😲, 🤯, 🤯, 🤯, 🤯, 🤯, 🤯, 🤯, 🤯, 🤯, 🤯, 🤯, 🤯, 🤯, 🤯, ...         17  \n",
       "302  [😉, 😉, 💋, ❤️, 💋, 🤗, 🤗, 🤗, ❤️, 💋, 🤗, 🤗, 🤗, ❤️, ❤️]         15  \n",
       "6                    [🎊, 💪, 👍, 👊, 🏆, ❗, 🎊, 💕, ❤, 😘, 😊]         11  \n",
       "343                  [📡, 📌, 📌, 📌, 📌, 📌, 📌, 📌, 📌, 📌, 👌]         11  \n",
       "..                                                 ...        ...  \n",
       "57                                                  []          0  \n",
       "245                                                 []          0  \n",
       "58                                                  []          0  \n",
       "59                                                  []          0  \n",
       "562                                                 []          0  \n",
       "\n",
       "[563 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoji_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1325355166057566209</td>\n",
       "      <td>[ Ну, трава тож разная бывает!,  Да ладно! Не ...</td>\n",
       "      <td>[😉, 😁, ☝, 😉, 😁, 😉, 😁, ☝, 🤔]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1183942687885533184</td>\n",
       "      <td>[ В Питере хоть дождь спасает положение,  Согл...</td>\n",
       "      <td>[😉, 🤗, 😉, 😉, 😉, 😉, 🤝, 👋🏽]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1241741410954600448</td>\n",
       "      <td>[ Ты почитай комменты выше сашок. Поголовно ка...</td>\n",
       "      <td>[🤣, 🤣, 🤣, 😂, 😂, 😂]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>900730534002925569</td>\n",
       "      <td>[ Не, я лучше одну возьму, но что бы и пригото...</td>\n",
       "      <td>[🤣, 🤣, 🤣, 🤣, 🤣]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>809880868567261184</td>\n",
       "      <td>[ Нет.Поверь ветерану движения.,  Это жестокий...</td>\n",
       "      <td>[😂, 🤔, 😂, 💐, 😘]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1317141671264571395</td>\n",
       "      <td>[ Нет. На эти, с примерно таким же сервисом - ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1315635580533911552</td>\n",
       "      <td>[ Шпионил за процветающими рэспубликами и выве...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1312337640</td>\n",
       "      <td>[ Захотела решить выйти...))]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1308082843621511169</td>\n",
       "      <td>[ в питере полиция задержала-было уже?]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>994590409769848833</td>\n",
       "      <td>[ Мне кажется, что вы долбоёб. И в логику не у...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               author_id                                               text  \\\n",
       "131  1325355166057566209  [ Ну, трава тож разная бывает!,  Да ладно! Не ...   \n",
       "53   1183942687885533184  [ В Питере хоть дождь спасает положение,  Согл...   \n",
       "78   1241741410954600448  [ Ты почитай комменты выше сашок. Поголовно ка...   \n",
       "336   900730534002925569  [ Не, я лучше одну возьму, но что бы и пригото...   \n",
       "317   809880868567261184  [ Нет.Поверь ветерану движения.,  Это жестокий...   \n",
       "..                   ...                                                ...   \n",
       "127  1317141671264571395  [ Нет. На эти, с примерно таким же сервисом - ...   \n",
       "126  1315635580533911552  [ Шпионил за процветающими рэспубликами и выве...   \n",
       "125           1312337640                      [ Захотела решить выйти...))]   \n",
       "124  1308082843621511169            [ в питере полиция задержала-было уже?]   \n",
       "359   994590409769848833  [ Мне кажется, что вы долбоёб. И в логику не у...   \n",
       "\n",
       "                          emojis  emoji_len  \n",
       "131  [😉, 😁, ☝, 😉, 😁, 😉, 😁, ☝, 🤔]          9  \n",
       "53     [😉, 🤗, 😉, 😉, 😉, 😉, 🤝, 👋🏽]          8  \n",
       "78            [🤣, 🤣, 🤣, 😂, 😂, 😂]          6  \n",
       "336              [🤣, 🤣, 🤣, 🤣, 🤣]          5  \n",
       "317              [😂, 🤔, 😂, 💐, 😘]          5  \n",
       "..                           ...        ...  \n",
       "127                           []          0  \n",
       "126                           []          0  \n",
       "125                           []          0  \n",
       "124                           []          0  \n",
       "359                           []          0  \n",
       "\n",
       "[360 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(en_text.sort_values('emoji_len', ascending=False))\n",
    "display(ru_text.sort_values('emoji_len', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8891e887",
   "metadata": {},
   "source": [
    "### Extracting Superfluous Characters\n",
    "Research suggests superfluous characters (repeated letters, non-standard punctuation) convey important cues in texts. Will keep track of specific punctuation (.!?). Furthermore, noticed that some mentions (@xxxxx) have gotten through and need to clean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7996918",
   "metadata": {},
   "source": [
    "# TODO: DESCRIBE IS SKEWED BY 0s, ADJUST CALCS IF USING STATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "85193acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df = en_text.copy()\n",
    "ru_df = ru_text.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5a0db527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All text to lowercase\n",
    "en_df.loc[:, 'text'] = en_df.loc[:, 'text'].apply(lambda x: [w.lower() for w in x])\n",
    "ru_df.loc[:, 'text'] = ru_df.loc[:, 'text'].apply(lambda x: [w.lower() for w in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "afd8cb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoji_len</th>\n",
       "      <th>amt_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1232360804004945921</td>\n",
       "      <td>[ same! i need to read through the proposed in...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1349182046569181185</td>\n",
       "      <td>[ actually bro spanish flu is the h1n1 virus. ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>501659753</td>\n",
       "      <td>[ thank you, you too,  aww bless you thank you...</td>\n",
       "      <td>[🥰, 😘, 🥰, 😘, 🥰, 😘, 😘, 🥰, 😘, 🥰, 🥰, 😘, ❤️, 🥰, 😘,...</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>3140037589</td>\n",
       "      <td>[ but it’s still pretty rare isn’t it ? i’ve n...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>1377312703992238088</td>\n",
       "      <td>[ looking totally stunning wend wow .lovely wh...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author_id                                               text  \\\n",
       "82   1232360804004945921  [ same! i need to read through the proposed in...   \n",
       "193  1349182046569181185  [ actually bro spanish flu is the h1n1 virus. ...   \n",
       "439            501659753  [ thank you, you too,  aww bless you thank you...   \n",
       "371           3140037589  [ but it’s still pretty rare isn’t it ? i’ve n...   \n",
       "240  1377312703992238088  [ looking totally stunning wend wow .lovely wh...   \n",
       "\n",
       "                                                emojis  emoji_len  amt_tweets  \n",
       "82                                                  []          0          18  \n",
       "193                                                 []          0          11  \n",
       "439  [🥰, 😘, 🥰, 😘, 🥰, 😘, 😘, 🥰, 😘, 🥰, 🥰, 😘, ❤️, 🥰, 😘,...         23          10  \n",
       "371                                                 []          0           8  \n",
       "240                                                 []          0           8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoji_len</th>\n",
       "      <th>amt_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>950066462588391425</td>\n",
       "      <td>[ читатели наших блогов уже давно прекрасно зн...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>2638582010</td>\n",
       "      <td>[ гордишься чмошеством? бывает...)),  офицеры ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1243254820385034243</td>\n",
       "      <td>[ и что дальше? госрегулирование включат?,  те...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1245394688447844353</td>\n",
       "      <td>[ божэ, какое говнище...,  а вы что за хуй? от...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>3577303277</td>\n",
       "      <td>[ ❗️наташе тышкевич назначили запрет определен...</td>\n",
       "      <td>[🤷‍♀️, 🤷‍♀️, 🤷‍♀️]</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author_id                                               text  \\\n",
       "344   950066462588391425  [ читатели наших блогов уже давно прекрасно зн...   \n",
       "220           2638582010  [ гордишься чмошеством? бывает...)),  офицеры ...   \n",
       "81   1243254820385034243  [ и что дальше? госрегулирование включат?,  те...   \n",
       "83   1245394688447844353  [ божэ, какое говнище...,  а вы что за хуй? от...   \n",
       "251           3577303277  [ ❗️наташе тышкевич назначили запрет определен...   \n",
       "\n",
       "                 emojis  emoji_len  amt_tweets  \n",
       "344                  []          0          13  \n",
       "220                  []          0           9  \n",
       "81                   []          0           9  \n",
       "83                   []          0           9  \n",
       "251  [🤷‍♀️, 🤷‍♀️, 🤷‍♀️]          3           8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Want to keep track of amount of tweets per user\n",
    "en_df = en_df.join(en_df.loc[:, 'text'].map(len).rename('amt_tweets'), how='inner')\n",
    "ru_df = ru_df.join(ru_df.loc[:, 'text'].map(len).rename('amt_tweets'), how='inner')\n",
    "\n",
    "display(en_df.sort_values('amt_tweets', ascending=False).head())\n",
    "display(ru_df.sort_values('amt_tweets', ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7cf0ead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_punct_pat = r'([.!?]+)'\n",
    "remove_punct_pat = r'[^\\s\\w]+'\n",
    "rep_lett_pat = r'(\\w)\\1{2,}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c2e763e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_punct(tweets):\n",
    "    punct = 0\n",
    "    punct_groups = 0\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        for g in regex.findall(count_punct_pat, tweet):\n",
    "            if len(g)==0:\n",
    "                continue\n",
    "                \n",
    "            punct_groups += 1\n",
    "            punct += len(g)\n",
    "    \n",
    "    return punct, float(punct)/punct_groups if punct_groups != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ade4e04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_rep_char(tweets):\n",
    "    char = ''\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        for c in regex.findall(rep_lett_pat, tweet):\n",
    "            char += c\n",
    "    \n",
    "    return len(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7825cd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_punct(tweets):\n",
    "    \n",
    "    for i, tweet in enumerate(tweets):\n",
    "        for g in regex.findall(remove_punct_pat, tweet):\n",
    "            tweet = tweet.replace(g, '')\n",
    "            \n",
    "            if len(tweet)==0:\n",
    "                del tweets[i]\n",
    "            else:\n",
    "                tweets[i] = tweet\n",
    "                \n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e982e739",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                              [ fabulous leadership!]\n",
       "1    [ america is draining itself. i had expected b...\n",
       "2    [ glad you are enjoying the beautiful south west]\n",
       "3    [ and the long anticipated badly needed spanki...\n",
       "4       [ i stand with you. thank you for all you do.]\n",
       "Name: text, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(en_df.loc[:, 'text'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d2a0df79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoji_len</th>\n",
       "      <th>amt_tweets</th>\n",
       "      <th>puncts</th>\n",
       "      <th>avg_puncts</th>\n",
       "      <th>repeat_letters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1003024039621820417</td>\n",
       "      <td>[ fabulous leadership!]</td>\n",
       "      <td>[🇺🇲, 🇺🇲, 🇺🇲, 😊, 😊]</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1005180474</td>\n",
       "      <td>[ america is draining itself. i had expected b...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1006460630692450304</td>\n",
       "      <td>[ glad you are enjoying the beautiful south west]</td>\n",
       "      <td>[😍]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100680355</td>\n",
       "      <td>[ and the long anticipated badly needed spanki...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1011442510869114880</td>\n",
       "      <td>[ i stand with you. thank you for all you do.]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author_id                                               text  \\\n",
       "0  1003024039621820417                            [ fabulous leadership!]   \n",
       "1           1005180474  [ america is draining itself. i had expected b...   \n",
       "2  1006460630692450304  [ glad you are enjoying the beautiful south west]   \n",
       "3            100680355  [ and the long anticipated badly needed spanki...   \n",
       "4  1011442510869114880     [ i stand with you. thank you for all you do.]   \n",
       "\n",
       "               emojis  emoji_len  amt_tweets  puncts  avg_puncts  \\\n",
       "0  [🇺🇲, 🇺🇲, 🇺🇲, 😊, 😊]          5           1       1         1.0   \n",
       "1                  []          0           1       1         1.0   \n",
       "2                 [😍]          1           1       0         0.0   \n",
       "3                  []          0           1       3         3.0   \n",
       "4                  []          0           1       2         1.0   \n",
       "\n",
       "   repeat_letters  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoji_len</th>\n",
       "      <th>amt_tweets</th>\n",
       "      <th>puncts</th>\n",
       "      <th>avg_puncts</th>\n",
       "      <th>repeat_letters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1005065863060475904</td>\n",
       "      <td>[ не выносите себе сами приговор!)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1012429847531065349</td>\n",
       "      <td>[ добрый вечер радий! (в италии тоже кто в кур...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1013485198787440640</td>\n",
       "      <td>[ вот это я понимаю - хорошие новости!]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1014106378355519488</td>\n",
       "      <td>[ настоящий глава, не то что некоторые!☝️]</td>\n",
       "      <td>[✊]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020634776103944192</td>\n",
       "      <td>[ ходить к мерзким людям на мерзкие (теле)пере...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author_id                                               text  \\\n",
       "0  1005065863060475904                [ не выносите себе сами приговор!)]   \n",
       "1  1012429847531065349  [ добрый вечер радий! (в италии тоже кто в кур...   \n",
       "2  1013485198787440640            [ вот это я понимаю - хорошие новости!]   \n",
       "3  1014106378355519488         [ настоящий глава, не то что некоторые!☝️]   \n",
       "4  1020634776103944192  [ ходить к мерзким людям на мерзкие (теле)пере...   \n",
       "\n",
       "  emojis  emoji_len  amt_tweets  puncts  avg_puncts  repeat_letters  \n",
       "0     []          0           1       1         1.0               0  \n",
       "1     []          0           2       2         1.0               0  \n",
       "2     []          0           1       1         1.0               0  \n",
       "3    [✊]          1           1       1         1.0               0  \n",
       "4     []          0           3       4         1.0               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adding columns for punctutations, average punctuations, repeat letters\n",
    "en_df = pd.concat(\n",
    "    [en_df, \n",
    "     pd.DataFrame(en_df.loc[:, 'text'].map(count_punct).to_list(), columns=['puncts', 'avg_puncts']),\n",
    "     en_df.loc[:, 'text'].map(count_rep_char).rename('repeat_letters')], \n",
    "    axis=1, join='inner')\n",
    "ru_df = pd.concat(\n",
    "    [ru_df, \n",
    "     pd.DataFrame(ru_df.loc[:, 'text'].map(count_punct).to_list(), columns=['puncts', 'avg_puncts']),\n",
    "     ru_df.loc[:, 'text'].map(count_rep_char).rename('repeat_letters')], \n",
    "    axis=1, join='inner')\n",
    "\n",
    "display(en_df.head())\n",
    "display(ru_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0f9ce2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoji_len</th>\n",
       "      <th>amt_tweets</th>\n",
       "      <th>puncts</th>\n",
       "      <th>avg_puncts</th>\n",
       "      <th>repeat_letters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1003024039621820417</td>\n",
       "      <td>[ fabulous leadership]</td>\n",
       "      <td>[🇺🇲, 🇺🇲, 🇺🇲, 😊, 😊]</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1005180474</td>\n",
       "      <td>[ america is draining itself i had expected bi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1006460630692450304</td>\n",
       "      <td>[ glad you are enjoying the beautiful south west]</td>\n",
       "      <td>[😍]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author_id                                               text  \\\n",
       "0  1003024039621820417                             [ fabulous leadership]   \n",
       "1           1005180474  [ america is draining itself i had expected bi...   \n",
       "2  1006460630692450304  [ glad you are enjoying the beautiful south west]   \n",
       "\n",
       "               emojis  emoji_len  amt_tweets  puncts  avg_puncts  \\\n",
       "0  [🇺🇲, 🇺🇲, 🇺🇲, 😊, 😊]          5           1       1         1.0   \n",
       "1                  []          0           1       1         1.0   \n",
       "2                 [😍]          1           1       0         0.0   \n",
       "\n",
       "   repeat_letters  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoji_len</th>\n",
       "      <th>amt_tweets</th>\n",
       "      <th>puncts</th>\n",
       "      <th>avg_puncts</th>\n",
       "      <th>repeat_letters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1005065863060475904</td>\n",
       "      <td>[ не выносите себе сами приговор]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1012429847531065349</td>\n",
       "      <td>[ добрый вечер радий в италии тоже кто в куртк...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1013485198787440640</td>\n",
       "      <td>[ вот это я понимаю  хорошие новости]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author_id                                               text  \\\n",
       "0  1005065863060475904                  [ не выносите себе сами приговор]   \n",
       "1  1012429847531065349  [ добрый вечер радий в италии тоже кто в куртк...   \n",
       "2  1013485198787440640              [ вот это я понимаю  хорошие новости]   \n",
       "\n",
       "  emojis  emoji_len  amt_tweets  puncts  avg_puncts  repeat_letters  \n",
       "0     []          0           1       1         1.0               0  \n",
       "1     []          0           2       2         1.0               0  \n",
       "2     []          0           1       1         1.0               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Removing punctuation from text to normalize a bit\n",
    "en_df.loc[:, 'text'] = en_df.loc[:, 'text'].map(extract_punct)\n",
    "ru_df.loc[:, 'text'] = ru_df.loc[:, 'text'].map(extract_punct)\n",
    "\n",
    "display(en_df.head(3))\n",
    "display(ru_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "55c30531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                               [ fabulous leadership]\n",
       "1    [ america is draining itself i had expected bi...\n",
       "2    [ glad you are enjoying the beautiful south west]\n",
       "3    [ and the long anticipated badly needed spanki...\n",
       "4         [ i stand with you thank you for all you do]\n",
       "Name: text, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(en_df.loc[:, 'text'].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03cc624",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3a7cf37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pymorphy2\n",
    "# !pip install -U pymorphy2-dicts-ru\n",
    "\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "18e9dea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6959f1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_lem = WordNetLemmatizer()\n",
    "ru_lem = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f536ea",
   "metadata": {},
   "source": [
    "#### Tokenizing and POS tagging\n",
    "Part of speech tagging for EN tweets, as the lemmatizer doesn't do so automatically unlike pymorphy for RU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "441b704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_lemmad = en_df.copy()\n",
    "ru_lemmad = ru_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "403796c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def en_set_pos_tag(tweets):\n",
    "    ts = []\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        ts.extend(\n",
    "            nltk.pos_tag(\n",
    "                nltk.word_tokenize(tweet)))\n",
    "    \n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "53d08431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ru_tokenize(tweets):\n",
    "    tokenized = []\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        tokenized.extend(nltk.tokenize.word_tokenize(tweet, language='russian'))\n",
    "        \n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dd692c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoji_len</th>\n",
       "      <th>amt_tweets</th>\n",
       "      <th>puncts</th>\n",
       "      <th>avg_puncts</th>\n",
       "      <th>repeat_letters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1003024039621820417</td>\n",
       "      <td>[(fabulous, JJ), (leadership, NN)]</td>\n",
       "      <td>[🇺🇲, 🇺🇲, 🇺🇲, 😊, 😊]</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1005180474</td>\n",
       "      <td>[(america, NN), (is, VBZ), (draining, VBG), (i...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1006460630692450304</td>\n",
       "      <td>[(glad, NN), (you, PRP), (are, VBP), (enjoying...</td>\n",
       "      <td>[😍]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100680355</td>\n",
       "      <td>[(and, CC), (the, DT), (long, JJ), (anticipate...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1011442510869114880</td>\n",
       "      <td>[(i, JJ), (stand, VBP), (with, IN), (you, PRP)...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author_id                                               text  \\\n",
       "0  1003024039621820417                 [(fabulous, JJ), (leadership, NN)]   \n",
       "1           1005180474  [(america, NN), (is, VBZ), (draining, VBG), (i...   \n",
       "2  1006460630692450304  [(glad, NN), (you, PRP), (are, VBP), (enjoying...   \n",
       "3            100680355  [(and, CC), (the, DT), (long, JJ), (anticipate...   \n",
       "4  1011442510869114880  [(i, JJ), (stand, VBP), (with, IN), (you, PRP)...   \n",
       "\n",
       "               emojis  emoji_len  amt_tweets  puncts  avg_puncts  \\\n",
       "0  [🇺🇲, 🇺🇲, 🇺🇲, 😊, 😊]          5           1       1         1.0   \n",
       "1                  []          0           1       1         1.0   \n",
       "2                 [😍]          1           1       0         0.0   \n",
       "3                  []          0           1       3         3.0   \n",
       "4                  []          0           1       2         1.0   \n",
       "\n",
       "   repeat_letters  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoji_len</th>\n",
       "      <th>amt_tweets</th>\n",
       "      <th>puncts</th>\n",
       "      <th>avg_puncts</th>\n",
       "      <th>repeat_letters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1005065863060475904</td>\n",
       "      <td>[не, выносите, себе, сами, приговор]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1012429847531065349</td>\n",
       "      <td>[добрый, вечер, радий, в, италии, тоже, кто, в...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1013485198787440640</td>\n",
       "      <td>[вот, это, я, понимаю, хорошие, новости]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1014106378355519488</td>\n",
       "      <td>[настоящий, глава, не, то, что, некоторые️]</td>\n",
       "      <td>[✊]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020634776103944192</td>\n",
       "      <td>[ходить, к, мерзким, людям, на, мерзкие, телеп...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author_id                                               text  \\\n",
       "0  1005065863060475904               [не, выносите, себе, сами, приговор]   \n",
       "1  1012429847531065349  [добрый, вечер, радий, в, италии, тоже, кто, в...   \n",
       "2  1013485198787440640           [вот, это, я, понимаю, хорошие, новости]   \n",
       "3  1014106378355519488        [настоящий, глава, не, то, что, некоторые️]   \n",
       "4  1020634776103944192  [ходить, к, мерзким, людям, на, мерзкие, телеп...   \n",
       "\n",
       "  emojis  emoji_len  amt_tweets  puncts  avg_puncts  repeat_letters  \n",
       "0     []          0           1       1         1.0               0  \n",
       "1     []          0           2       2         1.0               0  \n",
       "2     []          0           1       1         1.0               0  \n",
       "3    [✊]          1           1       1         1.0               0  \n",
       "4     []          0           3       4         1.0               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ru_lemmad.loc[:, 'text'] = ru_lemmad.loc[:, 'text'].map(ru_tokenize)\n",
    "en_lemmad.loc[:, 'text'] = en_lemmad.loc[:, 'text'].map(en_set_pos_tag)\n",
    "\n",
    "display(en_lemmad.head(5))\n",
    "display(ru_lemmad.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbfc32f",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e95f555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map of the appropriate POS tags to pass into the lemmatizer\n",
    "pos_tag = {'J': wordnet.ADJ, 'N': wordnet.NOUN, 'V': wordnet.VERB, 'R': wordnet.ADV}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "895a793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(tweet, lang):\n",
    "    if lang=='ru':\n",
    "        return [ru_lem.parse(w)[0].normal_form for w in tweet]\n",
    "    \n",
    "    lemm = []\n",
    "    \n",
    "    for w in tweet:\n",
    "        word = w[0]\n",
    "        pos = w[1][0]\n",
    "        \n",
    "        try:\n",
    "            lemm.append(en_lem.lemmatize(word, pos_tag.get(pos)))\n",
    "        except KeyError:\n",
    "            continue\n",
    "        \n",
    "    return lemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9a225cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_lemmad.loc[:, 'text'] = en_lemmad.loc[:, 'text'].apply(lemmatize, lang='en')\n",
    "ru_lemmad.loc[:, 'text'] = ru_lemmad.loc[:, 'text'].apply(lemmatize, lang='ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d13a5bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoji_len</th>\n",
       "      <th>amt_tweets</th>\n",
       "      <th>puncts</th>\n",
       "      <th>avg_puncts</th>\n",
       "      <th>repeat_letters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1003024039621820417</td>\n",
       "      <td>[fabulous, leadership]</td>\n",
       "      <td>[🇺🇲, 🇺🇲, 🇺🇲, 😊, 😊]</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1005180474</td>\n",
       "      <td>[america, be, drain, i, have, expect, biden, d...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1006460630692450304</td>\n",
       "      <td>[glad, be, enjoy, beautiful, south, west]</td>\n",
       "      <td>[😍]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100680355</td>\n",
       "      <td>[long, anticipated, badly, need, spanking, begin]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1011442510869114880</td>\n",
       "      <td>[i, stand, thank, do]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author_id                                               text  \\\n",
       "0  1003024039621820417                             [fabulous, leadership]   \n",
       "1           1005180474  [america, be, drain, i, have, expect, biden, d...   \n",
       "2  1006460630692450304          [glad, be, enjoy, beautiful, south, west]   \n",
       "3            100680355  [long, anticipated, badly, need, spanking, begin]   \n",
       "4  1011442510869114880                              [i, stand, thank, do]   \n",
       "\n",
       "               emojis  emoji_len  amt_tweets  puncts  avg_puncts  \\\n",
       "0  [🇺🇲, 🇺🇲, 🇺🇲, 😊, 😊]          5           1       1         1.0   \n",
       "1                  []          0           1       1         1.0   \n",
       "2                 [😍]          1           1       0         0.0   \n",
       "3                  []          0           1       3         3.0   \n",
       "4                  []          0           1       2         1.0   \n",
       "\n",
       "   repeat_letters  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoji_len</th>\n",
       "      <th>amt_tweets</th>\n",
       "      <th>puncts</th>\n",
       "      <th>avg_puncts</th>\n",
       "      <th>repeat_letters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1005065863060475904</td>\n",
       "      <td>[не, выносить, себя, сам, приговор]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1012429847531065349</td>\n",
       "      <td>[добрый, вечер, радий, в, италия, тоже, кто, в...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1013485198787440640</td>\n",
       "      <td>[вот, это, я, понимать, хороший, новость]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1014106378355519488</td>\n",
       "      <td>[настоящий, глава, не, то, что, некоторые️]</td>\n",
       "      <td>[✊]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020634776103944192</td>\n",
       "      <td>[ходить, к, мерзкий, человек, на, мерзкий, тел...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author_id                                               text  \\\n",
       "0  1005065863060475904                [не, выносить, себя, сам, приговор]   \n",
       "1  1012429847531065349  [добрый, вечер, радий, в, италия, тоже, кто, в...   \n",
       "2  1013485198787440640          [вот, это, я, понимать, хороший, новость]   \n",
       "3  1014106378355519488        [настоящий, глава, не, то, что, некоторые️]   \n",
       "4  1020634776103944192  [ходить, к, мерзкий, человек, на, мерзкий, тел...   \n",
       "\n",
       "  emojis  emoji_len  amt_tweets  puncts  avg_puncts  repeat_letters  \n",
       "0     []          0           1       1         1.0               0  \n",
       "1     []          0           2       2         1.0               0  \n",
       "2     []          0           1       1         1.0               0  \n",
       "3    [✊]          1           1       1         1.0               0  \n",
       "4     []          0           3       4         1.0               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(en_lemmad.head(5))\n",
    "display(ru_lemmad.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b467681d",
   "metadata": {},
   "source": [
    "#### Removing stopwords\n",
    "Stop words were needed for sentence analysis in POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "059bb475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "en_stopwords = set(stopwords.words('english'))\n",
    "ru_stopwords = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d934ad14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cf9b0d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ru_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f3e0d29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add apostrophe-less variations of stopwords for english\n",
    "words = set()\n",
    "\n",
    "for word in en_stopwords:\n",
    "    words.add(word.replace('\\'', ''))\n",
    "\n",
    "en_stopwords.update(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "180a31fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Adding 'ё' word-variations, which are missing from the stopwords here\n",
    "words = {'всё', 'ещё', 'её'}\n",
    "\n",
    "ru_stopwords.update(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6c652069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting and removing stopwords\n",
    "def extract_stop(tweet, lang):\n",
    "    count = 0\n",
    "    cleaned = []\n",
    "    \n",
    "    cleaned = [word for word in tweet if word not in en_stopwords]\\\n",
    "        if lang=='en'\\\n",
    "        else [word for word in tweet if word not in ru_stopwords]\n",
    "    \n",
    "    count = len(tweet) - len(cleaned) \n",
    "    return (cleaned, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "222ce6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[fabulous, leadership]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[america, drain, expect, biden, good]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[glad, enjoy, beautiful, south, west]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    text  stopwords\n",
       "0                 [fabulous, leadership]          0\n",
       "1  [america, drain, expect, biden, good]          4\n",
       "2  [glad, enjoy, beautiful, south, west]          1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[выносить, приговор]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[добрый, вечер, радий, италия, куртка, коротки...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[это, понимать, хороший, новость]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stopwords\n",
       "0                               [выносить, приговор]          3\n",
       "1  [добрый, вечер, радий, италия, куртка, коротки...         10\n",
       "2                  [это, понимать, хороший, новость]          2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "en_cleaned = pd.DataFrame(en_lemmad.loc[:, 'text'].apply(extract_stop, lang='en').to_list(), columns=['text', 'stopwords'])\n",
    "ru_cleaned = pd.DataFrame(ru_lemmad.loc[:, 'text'].apply(extract_stop, lang='ru').to_list(), columns=['text', 'stopwords'])\n",
    "\n",
    "display(en_cleaned.head(3))\n",
    "display(ru_cleaned.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e9e1b8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoji_len</th>\n",
       "      <th>amt_tweets</th>\n",
       "      <th>puncts</th>\n",
       "      <th>avg_puncts</th>\n",
       "      <th>repeat_letters</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1003024039621820417</td>\n",
       "      <td>[fabulous, leadership]</td>\n",
       "      <td>[🇺🇲, 🇺🇲, 🇺🇲, 😊, 😊]</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1005180474</td>\n",
       "      <td>[america, drain, expect, biden, good]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1006460630692450304</td>\n",
       "      <td>[glad, enjoy, beautiful, south, west]</td>\n",
       "      <td>[😍]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author_id                                   text  \\\n",
       "0  1003024039621820417                 [fabulous, leadership]   \n",
       "1           1005180474  [america, drain, expect, biden, good]   \n",
       "2  1006460630692450304  [glad, enjoy, beautiful, south, west]   \n",
       "\n",
       "               emojis  emoji_len  amt_tweets  puncts  avg_puncts  \\\n",
       "0  [🇺🇲, 🇺🇲, 🇺🇲, 😊, 😊]          5           1       1         1.0   \n",
       "1                  []          0           1       1         1.0   \n",
       "2                 [😍]          1           1       0         0.0   \n",
       "\n",
       "   repeat_letters  stopwords  \n",
       "0               0          0  \n",
       "1               0          4  \n",
       "2               0          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoji_len</th>\n",
       "      <th>amt_tweets</th>\n",
       "      <th>puncts</th>\n",
       "      <th>avg_puncts</th>\n",
       "      <th>repeat_letters</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1005065863060475904</td>\n",
       "      <td>[выносить, приговор]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1012429847531065349</td>\n",
       "      <td>[добрый, вечер, радий, италия, куртка, коротки...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1013485198787440640</td>\n",
       "      <td>[это, понимать, хороший, новость]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author_id                                               text  \\\n",
       "0  1005065863060475904                               [выносить, приговор]   \n",
       "1  1012429847531065349  [добрый, вечер, радий, италия, куртка, коротки...   \n",
       "2  1013485198787440640                  [это, понимать, хороший, новость]   \n",
       "\n",
       "  emojis  emoji_len  amt_tweets  puncts  avg_puncts  repeat_letters  stopwords  \n",
       "0     []          0           1       1         1.0               0          3  \n",
       "1     []          0           2       2         1.0               0         10  \n",
       "2     []          0           1       1         1.0               0          2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "en_lemmad.loc[:, 'text'] = en_cleaned.loc[:, 'text']\n",
    "ru_lemmad.loc[:, 'text'] = ru_cleaned.loc[:, 'text']\n",
    "\n",
    "en_lemmad = pd.concat(\n",
    "    [en_lemmad,\n",
    "     en_cleaned.loc[:, 'stopwords']], \n",
    "    axis=1, join='inner')\n",
    "ru_lemmad = pd.concat(\n",
    "    [ru_lemmad,\n",
    "     ru_cleaned.loc[:, 'stopwords']], \n",
    "    axis=1, join='inner')\n",
    "\n",
    "display(en_lemmad.head(3))\n",
    "display(ru_lemmad.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8481e2",
   "metadata": {},
   "source": [
    "### Final Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "893bf1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_info(text):\n",
    "    words = len(text)\n",
    "    chars = 0\n",
    "    \n",
    "    for word in text:\n",
    "        chars += len(word)\n",
    "    \n",
    "    return words, chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "85f04edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amt_words</th>\n",
       "      <th>amt_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>351</td>\n",
       "      <td>2057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>137</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>105</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>95</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>94</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     amt_words  amt_chars\n",
       "82         351       2057\n",
       "371        137        730\n",
       "86         105        634\n",
       "74          95        465\n",
       "27          94        439"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amt_words</th>\n",
       "      <th>amt_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>198</td>\n",
       "      <td>1406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>156</td>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>122</td>\n",
       "      <td>819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>89</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>87</td>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     amt_words  amt_chars\n",
       "344        198       1406\n",
       "41         156        961\n",
       "81         122        819\n",
       "251         89        623\n",
       "139         87        571"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "en_lengths = pd.DataFrame(en_lemmad.loc[:, 'text'].map(get_text_info).to_list(), columns=['amt_words', 'amt_chars'])\n",
    "ru_lengths = pd.DataFrame(ru_lemmad.loc[:, 'text'].map(get_text_info).to_list(), columns=['amt_words', 'amt_chars'])\n",
    "\n",
    "display(en_lengths.sort_values('amt_words', ascending=False).head())\n",
    "display(ru_lengths.sort_values('amt_words', ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "648b111e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoji_len</th>\n",
       "      <th>amt_tweets</th>\n",
       "      <th>puncts</th>\n",
       "      <th>avg_puncts</th>\n",
       "      <th>repeat_letters</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>amt_words</th>\n",
       "      <th>amt_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1232360804004945921</td>\n",
       "      <td>[need, read, propose, instruction, try, figure...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>76</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>351</td>\n",
       "      <td>2057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1349182046569181185</td>\n",
       "      <td>[actually, bro, spanish, flu, h1n1, virus, shi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>83</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>501659753</td>\n",
       "      <td>[thank, aww, bless, thank, even, thank, even, ...</td>\n",
       "      <td>[🥰, 😘, 🥰, 😘, 🥰, 😘, 😘, 🥰, 😘, 🥰, 🥰, 😘, ❤️, 🥰, 😘,...</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>37</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>3140037589</td>\n",
       "      <td>[still, pretty, rare, ive, never, even, heard,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>137</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>1377312703992238088</td>\n",
       "      <td>[look, totally, stun, wend, wow, lovely, wheat...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>94</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author_id                                               text  \\\n",
       "82   1232360804004945921  [need, read, propose, instruction, try, figure...   \n",
       "193  1349182046569181185  [actually, bro, spanish, flu, h1n1, virus, shi...   \n",
       "439            501659753  [thank, aww, bless, thank, even, thank, even, ...   \n",
       "371           3140037589  [still, pretty, rare, ive, never, even, heard,...   \n",
       "240  1377312703992238088  [look, totally, stun, wend, wow, lovely, wheat...   \n",
       "\n",
       "                                                emojis  emoji_len  amt_tweets  \\\n",
       "82                                                  []          0          18   \n",
       "193                                                 []          0          11   \n",
       "439  [🥰, 😘, 🥰, 😘, 🥰, 😘, 😘, 🥰, 😘, 🥰, 🥰, 😘, ❤️, 🥰, 😘,...         23          10   \n",
       "371                                                 []          0           8   \n",
       "240                                                 []          0           8   \n",
       "\n",
       "     puncts  avg_puncts  repeat_letters  stopwords  amt_words  amt_chars  \n",
       "82       76    1.000000               0        100        351       2057  \n",
       "193      17    1.133333               0         23         83        374  \n",
       "439       1    1.000000               0         14         37        163  \n",
       "371      27    1.000000               0         35        137        730  \n",
       "240       7    1.000000               0         13         94        480  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoji_len</th>\n",
       "      <th>amt_tweets</th>\n",
       "      <th>puncts</th>\n",
       "      <th>avg_puncts</th>\n",
       "      <th>repeat_letters</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>amt_words</th>\n",
       "      <th>amt_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>950066462588391425</td>\n",
       "      <td>[читатель, наш, блог, давно, прекрасно, знать,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>198</td>\n",
       "      <td>1406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>2638582010</td>\n",
       "      <td>[гордиться, чмошество, бывать, офицер, казарма...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>68</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1243254820385034243</td>\n",
       "      <td>[далёкий, госрегулирование, включить, тест, ко...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>1.192308</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>122</td>\n",
       "      <td>819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1245394688447844353</td>\n",
       "      <td>[божэ, говнищий, хуй, откуда, взяться, писать,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>43</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>3577303277</td>\n",
       "      <td>[️наташа, тышкевич, назначить, запрет, определ...</td>\n",
       "      <td>[🤷‍♀️, 🤷‍♀️, 🤷‍♀️]</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>89</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author_id                                               text  \\\n",
       "344   950066462588391425  [читатель, наш, блог, давно, прекрасно, знать,...   \n",
       "220           2638582010  [гордиться, чмошество, бывать, офицер, казарма...   \n",
       "81   1243254820385034243  [далёкий, госрегулирование, включить, тест, ко...   \n",
       "83   1245394688447844353  [божэ, говнищий, хуй, откуда, взяться, писать,...   \n",
       "251           3577303277  [️наташа, тышкевич, назначить, запрет, определ...   \n",
       "\n",
       "                 emojis  emoji_len  amt_tweets  puncts  avg_puncts  \\\n",
       "344                  []          0          13      19    1.000000   \n",
       "220                  []          0           9      42    2.800000   \n",
       "81                   []          0           9      31    1.192308   \n",
       "83                   []          0           9      16    1.333333   \n",
       "251  [🤷‍♀️, 🤷‍♀️, 🤷‍♀️]          3           8       6    1.000000   \n",
       "\n",
       "     repeat_letters  stopwords  amt_words  amt_chars  \n",
       "344               0        163        198       1406  \n",
       "220               1         33         68        480  \n",
       "81                0         89        122        819  \n",
       "83                0         26         43        251  \n",
       "251               0         28         89        623  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "en_final = en_lemmad.join(en_lengths, how='left')\n",
    "ru_final = ru_lemmad.join(ru_lengths, how='left')\n",
    "\n",
    "display(en_final.sort_values('amt_tweets', ascending=False).head())\n",
    "display(ru_final.sort_values('amt_tweets', ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "42b0f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving\n",
    "with open('en_processed.txt', 'w') as d:\n",
    "    d.writelines(en_final.to_json(orient='table', force_ascii=False))\n",
    "    \n",
    "with open('ru_processed.txt', 'w') as d:\n",
    "    d.writelines(ru_final.to_json(orient='table', force_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe2e172",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
