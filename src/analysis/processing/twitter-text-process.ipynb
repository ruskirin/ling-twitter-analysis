{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5a87de5",
   "metadata": {},
   "source": [
    "### References\n",
    "Bird, Steven, Edward Loper and Ewan Klein (2009), Natural Language Processing with Python. O’Reilly Media Inc.\n",
    "\n",
    "https://www.kaggle.com/alxmamaev/how-to-easy-preprocess-russian-text\n",
    "\n",
    "https://python-school.ru/nlp-text-preprocessing/\n",
    "\n",
    "https://pymorphy2.readthedocs.io/en/latest/user/guide.html\n",
    "\n",
    "https://stackoverflow.com/a/49242754/13557629 (finding emojis)\n",
    "\n",
    "https://www.machinelearningplus.com/nlp/lemmatization-examples-python/#wordnetlemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60629f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import regex\n",
    "import yaml\n",
    "from unidecode import unidecode\n",
    "import logging\n",
    "from logging import config\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "import processing\n",
    "\n",
    "import spacy\n",
    "spacy.require_gpu()\n",
    "from torch.utils import dlpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06d3137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "\n",
    "spec_src = importlib.util.spec_from_file_location(\n",
    "    'src', \n",
    "    '../../__init__.py')\n",
    "m = importlib.util.module_from_spec(spec_src)\n",
    "sys.modules[spec_src.name] = m\n",
    "spec_src.loader.exec_module(m)\n",
    "\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d9b286a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Opened config file at: /home/rimov/Documents/Code/NLP/lin-que-dropping/config/general_config.yml\n"
     ]
    }
   ],
   "source": [
    "desc = 'Processed format agreed on; process all the tweets'\n",
    "logger = utils.get_logger('process-all-tweets', desc=desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b309e102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.utils' from '/home/rimov/Documents/Code/NLP/lin-que-dropping/src/analysis/processing/../../utils.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Reload module\n",
    "\"\"\"\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acf49809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Opened config file at: /home/rimov/Documents/Code/NLP/lin-que-dropping/config/general_config.yml\n",
      "INFO:root:Opened config file at: /home/rimov/Documents/Code/NLP/lin-que-dropping/config/processing_config.yml\n"
     ]
    }
   ],
   "source": [
    "gen_conf = utils.get_config()\n",
    "conf = utils.get_config('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d45bc08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb_type</th>\n",
       "      <th>verb</th>\n",
       "      <th>indicativo</th>\n",
       "      <th>imperativo</th>\n",
       "      <th>subjuntivo</th>\n",
       "      <th>gerundio</th>\n",
       "      <th>gerundio_compuesto</th>\n",
       "      <th>infinitivo</th>\n",
       "      <th>infinitivo_compuesto</th>\n",
       "      <th>participio_pasado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stative</td>\n",
       "      <td>ver</td>\n",
       "      <td>veía  visto  verías  vi  vimos  verían  ves  v...</td>\n",
       "      <td>vean   ve   vea   veamos   ved</td>\n",
       "      <td>veáis  visto  vieras  vieren  viesen  veas  vi...</td>\n",
       "      <td>viendo</td>\n",
       "      <td>visto</td>\n",
       "      <td>ver</td>\n",
       "      <td>visto</td>\n",
       "      <td>visto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stative</td>\n",
       "      <td>jurar</td>\n",
       "      <td>jurarán  juramos  jurarías  jurabas  juraría  ...</td>\n",
       "      <td>jurad   jura   juren   jure   juremos</td>\n",
       "      <td>jurare  jurareis  jurase  jurara  juraren  jur...</td>\n",
       "      <td>jurando</td>\n",
       "      <td>jurado</td>\n",
       "      <td>jurar</td>\n",
       "      <td>jurado</td>\n",
       "      <td>jurado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  verb_type   verb                                         indicativo  \\\n",
       "0   Stative    ver  veía  visto  verías  vi  vimos  verían  ves  v...   \n",
       "1   Stative  jurar  jurarán  juramos  jurarías  jurabas  juraría  ...   \n",
       "\n",
       "                               imperativo  \\\n",
       "0         vean   ve   vea   veamos   ved    \n",
       "1  jurad   jura   juren   jure   juremos    \n",
       "\n",
       "                                          subjuntivo gerundio  \\\n",
       "0  veáis  visto  vieras  vieren  viesen  veas  vi...   viendo   \n",
       "1  jurare  jurareis  jurase  jurara  juraren  jur...  jurando   \n",
       "\n",
       "  gerundio_compuesto infinitivo infinitivo_compuesto participio_pasado  \n",
       "0              visto        ver                visto             visto  \n",
       "1             jurado      jurar               jurado            jurado  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "es_conj_path = utils.get_project_root()/gen_conf['file_paths']['verb_conjug']\n",
    "es_conjugs = pd.read_excel(es_conj_path)\n",
    "display(es_conjugs.head(2))\n",
    "\n",
    "es_verbs = set(es_conjugs['verb'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f3c1218",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_path_c = utils.get_save_path('c', 'twitter', lang='es', is_test=False)\n",
    "std_path_p = utils.get_save_path('p', 'twitter', lang='es', is_test=False)\n",
    "data_folders = ['07112021-at-2210-combined', '20210726-combined']\n",
    "data_paths = [std_path_c/path for path in data_folders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44c6a11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Opened config file at: /home/rimov/Documents/Code/NLP/lin-que-dropping/config/general_config.yml\n"
     ]
    }
   ],
   "source": [
    "# Save folders below are partitioned by date folders (when processing done)\n",
    "save_date = utils.get_str_datetime_now()\n",
    "# Name of folder in which to save data\n",
    "save_folder = 'combined-2021-07-26-and-11-07'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92299a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = utils.make_dir(std_path_p, save_folder, save_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bea974af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Opened config file at: /home/rimov/Documents/Code/NLP/lin-que-dropping/config/general_config.yml\n",
      "INFO:root:Opened config file at: /home/rimov/Documents/Code/NLP/lin-que-dropping/config/general_config.yml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframes opened: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text_orig</th>\n",
       "      <th>author_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_place_id</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>mentions</th>\n",
       "      <th>text_norm</th>\n",
       "      <th>retweet_reply_like_quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-08 03:15:45+00:00</td>\n",
       "      <td>Esta derrota de Quindio confirma que el Superd...</td>\n",
       "      <td>141323312.0</td>\n",
       "      <td>es</td>\n",
       "      <td>1.457547e+18</td>\n",
       "      <td>0116b409205a5237</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Esta derrota de Quindio confirma que el Superd...</td>\n",
       "      <td>(0, 0, 4, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-08 03:15:11+00:00</td>\n",
       "      <td>Muajaja ese broder confirmó lo q les dije... L...</td>\n",
       "      <td>49454158.0</td>\n",
       "      <td>es</td>\n",
       "      <td>1.457547e+18</td>\n",
       "      <td>011455904ec2ab81</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Muajaja ese broder confirmo lo q les dije... L...</td>\n",
       "      <td>(0, 0, 0, 0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  created_at  \\\n",
       "0  2021-11-08 03:15:45+00:00   \n",
       "1  2021-11-08 03:15:11+00:00   \n",
       "\n",
       "                                           text_orig    author_id lang  \\\n",
       "0  Esta derrota de Quindio confirma que el Superd...  141323312.0   es   \n",
       "1  Muajaja ese broder confirmó lo q les dije... L...   49454158.0   es   \n",
       "\n",
       "       tweet_id    tweet_place_id referenced_tweets mentions  \\\n",
       "0  1.457547e+18  0116b409205a5237              <NA>     <NA>   \n",
       "1  1.457547e+18  011455904ec2ab81              <NA>     <NA>   \n",
       "\n",
       "                                           text_norm retweet_reply_like_quote  \n",
       "0  Esta derrota de Quindio confirma que el Superd...             (0, 0, 4, 0)  \n",
       "1  Muajaja ese broder confirmo lo q les dije... L...             (0, 0, 0, 0)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 408362 entries, 0 to 408361\n",
      "Data columns (total 10 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   created_at                408362 non-null  object \n",
      " 1   text_orig                 408362 non-null  string \n",
      " 2   author_id                 408362 non-null  float64\n",
      " 3   lang                      408362 non-null  object \n",
      " 4   tweet_id                  408362 non-null  float64\n",
      " 5   tweet_place_id            408358 non-null  string \n",
      " 6   referenced_tweets         253215 non-null  string \n",
      " 7   mentions                  259972 non-null  string \n",
      " 8   text_norm                 408362 non-null  string \n",
      " 9   retweet_reply_like_quote  408362 non-null  string \n",
      "dtypes: float64(2), object(2), string(6)\n",
      "memory usage: 31.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>lang</th>\n",
       "      <th>text_orig</th>\n",
       "      <th>author_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet_place_id</th>\n",
       "      <th>mentions</th>\n",
       "      <th>text_norm</th>\n",
       "      <th>retweet_reply_like_quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['1455906589513293832']</td>\n",
       "      <td>es</td>\n",
       "      <td>@elguisodebagre Pero es en todo.... sinó mira ...</td>\n",
       "      <td>166276984</td>\n",
       "      <td>1.455907e+18</td>\n",
       "      <td>2021-11-03 14:38:30+00:00</td>\n",
       "      <td>0a738ff13a08a7dd</td>\n",
       "      <td>[{'start': 0, 'end': 15, 'username': 'elguisod...</td>\n",
       "      <td>Pero es en todo.... sino mira un ex club, que ...</td>\n",
       "      <td>(0, 0, 0, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>es</td>\n",
       "      <td>La #CC no ha escrito aún 1 carilla dl proyecto...</td>\n",
       "      <td>1442589489872834569</td>\n",
       "      <td>1.455907e+18</td>\n",
       "      <td>2021-11-03 14:38:11+00:00</td>\n",
       "      <td>014f394f11cda9e4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>La #CC no ha escrito aun 1 carilla dl proyecto...</td>\n",
       "      <td>(0, 0, 0, 0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         referenced_tweets lang  \\\n",
       "0  ['1455906589513293832']   es   \n",
       "1                     <NA>   es   \n",
       "\n",
       "                                           text_orig            author_id  \\\n",
       "0  @elguisodebagre Pero es en todo.... sinó mira ...            166276984   \n",
       "1  La #CC no ha escrito aún 1 carilla dl proyecto...  1442589489872834569   \n",
       "\n",
       "       tweet_id                 created_at    tweet_place_id  \\\n",
       "0  1.455907e+18  2021-11-03 14:38:30+00:00  0a738ff13a08a7dd   \n",
       "1  1.455907e+18  2021-11-03 14:38:11+00:00  014f394f11cda9e4   \n",
       "\n",
       "                                            mentions  \\\n",
       "0  [{'start': 0, 'end': 15, 'username': 'elguisod...   \n",
       "1                                               <NA>   \n",
       "\n",
       "                                           text_norm retweet_reply_like_quote  \n",
       "0  Pero es en todo.... sino mira un ex club, que ...             (0, 0, 0, 0)  \n",
       "1  La #CC no ha escrito aun 1 carilla dl proyecto...             (0, 0, 0, 0)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 116025 entries, 0 to 116024\n",
      "Data columns (total 10 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   referenced_tweets         77510 non-null   string \n",
      " 1   lang                      116025 non-null  object \n",
      " 2   text_orig                 116025 non-null  string \n",
      " 3   author_id                 116025 non-null  int64  \n",
      " 4   tweet_id                  116025 non-null  float64\n",
      " 5   created_at                116025 non-null  object \n",
      " 6   tweet_place_id            116020 non-null  string \n",
      " 7   mentions                  79994 non-null   string \n",
      " 8   text_norm                 116025 non-null  string \n",
      " 9   retweet_reply_like_quote  116025 non-null  string \n",
      "dtypes: float64(1), int64(1), object(2), string(6)\n",
      "memory usage: 8.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets = [utils.get_csv('twitter', data_path/'tweets.csv', sep='~', lineterminator='\\n') for data_path in data_paths]\n",
    "print(f'Dataframes opened: {len(tweets)}')\n",
    "\n",
    "for t in tweets:\n",
    "    display(t.head(2))\n",
    "    display(t.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a22f17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10 entries, 98417 to 77663\n",
      "Data columns (total 10 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   created_at                10 non-null     object \n",
      " 1   text_orig                 10 non-null     string \n",
      " 2   author_id                 10 non-null     float64\n",
      " 3   lang                      10 non-null     object \n",
      " 4   tweet_id                  10 non-null     float64\n",
      " 5   tweet_place_id            10 non-null     string \n",
      " 6   referenced_tweets         8 non-null      string \n",
      " 7   mentions                  8 non-null      string \n",
      " 8   text_norm                 10 non-null     string \n",
      " 9   retweet_reply_like_quote  10 non-null     string \n",
      "dtypes: float64(2), object(2), string(6)\n",
      "memory usage: 880.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "sample1 = tweets[0].sample(5)\n",
    "sample2 = tweets[1].sample(5)\n",
    "\n",
    "sample = pd.concat([sample1, sample2])\n",
    "sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73e66916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 524387 entries, 0 to 116024\n",
      "Data columns (total 10 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   created_at                524387 non-null  object \n",
      " 1   text_orig                 524387 non-null  string \n",
      " 2   author_id                 524387 non-null  float64\n",
      " 3   lang                      524387 non-null  object \n",
      " 4   tweet_id                  524387 non-null  float64\n",
      " 5   tweet_place_id            524378 non-null  string \n",
      " 6   referenced_tweets         330725 non-null  string \n",
      " 7   mentions                  339966 non-null  string \n",
      " 8   text_norm                 524387 non-null  string \n",
      " 9   retweet_reply_like_quote  524387 non-null  string \n",
      "dtypes: float64(2), object(2), string(6)\n",
      "memory usage: 44.0+ MB\n"
     ]
    }
   ],
   "source": [
    "if len(tweets) > 1:\n",
    "    tweets = pd.concat(tweets)\n",
    "    tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b3578f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.drop(columns=['text_norm', 'lang'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33493323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 510186 entries, 0 to 510185\n",
      "Data columns (total 8 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   created_at                510186 non-null  object \n",
      " 1   text_orig                 510186 non-null  string \n",
      " 2   author_id                 510186 non-null  float64\n",
      " 3   tweet_id                  510186 non-null  float64\n",
      " 4   tweet_place_id            510177 non-null  string \n",
      " 5   referenced_tweets         321333 non-null  string \n",
      " 6   mentions                  330252 non-null  string \n",
      " 7   retweet_reply_like_quote  510186 non-null  string \n",
      "dtypes: float64(2), object(1), string(5)\n",
      "memory usage: 31.1+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets = tweets.drop_duplicates(subset='tweet_id', ignore_index=True)\n",
    "tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69158802",
   "metadata": {},
   "source": [
    "### Running through spaCy pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34781066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable 'ner' (Named Entity Recognizer)\n",
    "nlp_es = spacy.load(conf['spacy']['es'], disable=['ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9117387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text_orig</th>\n",
       "      <th>author_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_place_id</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>mentions</th>\n",
       "      <th>retweet_reply_like_quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>411680</th>\n",
       "      <td>2021-11-05 05:11:21+00:00</td>\n",
       "      <td>@carlesenric @Macarena_Olona @ElsaGarciad no c...</td>\n",
       "      <td>2.556683e+08</td>\n",
       "      <td>1.456489e+18</td>\n",
       "      <td>cbdb0e7018443220</td>\n",
       "      <td>['1456402105124675586']</td>\n",
       "      <td>[{'start': 0, 'end': 12, 'username': 'carlesen...</td>\n",
       "      <td>(0, 0, 7, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29860</th>\n",
       "      <td>2021-11-05 15:55:58+00:00</td>\n",
       "      <td>Coño vi Dune y me pareció un Star Wars aburrid...</td>\n",
       "      <td>6.917859e+07</td>\n",
       "      <td>1.456652e+18</td>\n",
       "      <td>01a9a39529b27f36</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>(0, 0, 2, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235543</th>\n",
       "      <td>2021-10-30 17:57:49+00:00</td>\n",
       "      <td>Mi cuerpo me odia , onda me siento como el ogt...</td>\n",
       "      <td>1.367898e+09</td>\n",
       "      <td>1.454508e+18</td>\n",
       "      <td>0108c69f708ae783</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>(0, 0, 0, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212760</th>\n",
       "      <td>2021-10-28 19:47:00+00:00</td>\n",
       "      <td>Me acuerdo de ese día y la cachetada que lleva...</td>\n",
       "      <td>8.200432e+17</td>\n",
       "      <td>1.453811e+18</td>\n",
       "      <td>0016b0ca4701a899</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>(0, 0, 0, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498199</th>\n",
       "      <td>2021-11-05 00:20:11+00:00</td>\n",
       "      <td>@leuryma16 Dato las estrellas en hollywood tu ...</td>\n",
       "      <td>5.285408e+07</td>\n",
       "      <td>1.456416e+18</td>\n",
       "      <td>01fcc4a23f17e1ed</td>\n",
       "      <td>['1456413208034652163']</td>\n",
       "      <td>[{'start': 0, 'end': 10, 'username': 'leuryma1...</td>\n",
       "      <td>(0, 1, 1, 0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at  \\\n",
       "411680  2021-11-05 05:11:21+00:00   \n",
       "29860   2021-11-05 15:55:58+00:00   \n",
       "235543  2021-10-30 17:57:49+00:00   \n",
       "212760  2021-10-28 19:47:00+00:00   \n",
       "498199  2021-11-05 00:20:11+00:00   \n",
       "\n",
       "                                                text_orig     author_id  \\\n",
       "411680  @carlesenric @Macarena_Olona @ElsaGarciad no c...  2.556683e+08   \n",
       "29860   Coño vi Dune y me pareció un Star Wars aburrid...  6.917859e+07   \n",
       "235543  Mi cuerpo me odia , onda me siento como el ogt...  1.367898e+09   \n",
       "212760  Me acuerdo de ese día y la cachetada que lleva...  8.200432e+17   \n",
       "498199  @leuryma16 Dato las estrellas en hollywood tu ...  5.285408e+07   \n",
       "\n",
       "            tweet_id    tweet_place_id        referenced_tweets  \\\n",
       "411680  1.456489e+18  cbdb0e7018443220  ['1456402105124675586']   \n",
       "29860   1.456652e+18  01a9a39529b27f36                     <NA>   \n",
       "235543  1.454508e+18  0108c69f708ae783                     <NA>   \n",
       "212760  1.453811e+18  0016b0ca4701a899                     <NA>   \n",
       "498199  1.456416e+18  01fcc4a23f17e1ed  ['1456413208034652163']   \n",
       "\n",
       "                                                 mentions  \\\n",
       "411680  [{'start': 0, 'end': 12, 'username': 'carlesen...   \n",
       "29860                                                <NA>   \n",
       "235543                                               <NA>   \n",
       "212760                                               <NA>   \n",
       "498199  [{'start': 0, 'end': 10, 'username': 'leuryma1...   \n",
       "\n",
       "       retweet_reply_like_quote  \n",
       "411680             (0, 0, 7, 0)  \n",
       "29860              (0, 0, 2, 0)  \n",
       "235543             (0, 0, 0, 0)  \n",
       "212760             (0, 0, 0, 0)  \n",
       "498199             (0, 1, 1, 0)  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = tweets.sample(100, random_state=1)\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bff6b8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normd(tokenized):\n",
    "    normd = ''\n",
    "    \n",
    "    for t in tokenized:\n",
    "        token = unidecode(t.text).lower()\n",
    "        \n",
    "        if t.pos_=='PUNCT':\n",
    "            normd+=f'{t.text}'\n",
    "            continue\n",
    "        \n",
    "        if token=='que' or token=='q':\n",
    "            que = t.text.upper()\n",
    "            normd+=f' {que}'\n",
    "            continue\n",
    "        \n",
    "        if (t.pos_=='VERB') and (t.lemma_ in es_verbs):\n",
    "            verb = t.text.upper()\n",
    "            if t.dep_=='ccomp':\n",
    "                verb = f'<<{verb}>>'\n",
    "                \n",
    "            normd+=f' {verb}'\n",
    "            continue\n",
    "        \n",
    "        normd+=f' {t.text.lower()}'\n",
    "    \n",
    "    return normd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1115c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_ccomp(tokenized):\n",
    "    has = any([t.dep_=='ccomp' for t in tokenized])\n",
    "    return 'TRUE' if has else 'FALSE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "562f9b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dep(tokenized):\n",
    "    deps = ''\n",
    "    \n",
    "    for t in tokenized:\n",
    "        if t.pos_=='PUNCT':\n",
    "            deps+=f' {t.text}'\n",
    "            continue\n",
    "        \n",
    "        deps+=f' {t.text.lower()}[{t.dep_}]'\n",
    "    \n",
    "    return deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe6d1c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos(tokenized):\n",
    "    return ' '.join([f'{t.text}({t.pos_.upper()})' for t in tokenized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5cb12e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_details(tokenized):\n",
    "    return ' '.join([f'<{t.text}>({t.lemma_.lower()},{t.is_stop})' for t in tokenized if t.pos_!='PUNCT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "38459130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verbs(tokenized):\n",
    "    verbs = ', '.join(set(t.lemma_ for t in tokenized if (t.pos_=='VERB') and (t.lemma_ in es_verbs)))\n",
    "    return verbs if len(verbs)>0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93bde2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def have_verbs(df):\n",
    "    have = df['text_orig'].apply(get_verbs).notna()\n",
    "    return df.loc[have, :].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2bc3cef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_batch(tokenized: list, file_path, file_name):\n",
    "    batch = have_verbs(pd.concat(tokenized, ignore_index=False))\n",
    "    \n",
    "    verbs = batch['text_orig'].apply(get_verbs).rename('verbs')\n",
    "    normd = batch['text_orig'].apply(get_normd).rename('normalized')\n",
    "    ccomp = batch['text_orig'].apply(has_ccomp).rename('has_ccomp')\n",
    "    dep = batch['text_orig'].apply(get_dep).rename('dependencies')\n",
    "    pos = batch['text_orig'].apply(get_pos).rename('pos')\n",
    "    details = batch['text_orig'].apply(get_details).rename('details')\n",
    "    \n",
    "    batch = pd.concat([verbs, batch.loc[:, ['tweet_id', 'text_orig']], normd, ccomp, dep, pos, details], axis=1)\n",
    "    \n",
    "    utils.save_csv(file_path, batch, file_name+'.csv')\n",
    "#     utils.save_excel(file_path, batch, file_name+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8db2c529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text_orig</th>\n",
       "      <th>author_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_place_id</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>mentions</th>\n",
       "      <th>retweet_reply_like_quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>411680</th>\n",
       "      <td>2021-11-05 05:11:21+00:00</td>\n",
       "      <td>@carlesenric @Macarena_Olona @ElsaGarciad no c...</td>\n",
       "      <td>2.556683e+08</td>\n",
       "      <td>1.456489e+18</td>\n",
       "      <td>cbdb0e7018443220</td>\n",
       "      <td>['1456402105124675586']</td>\n",
       "      <td>[{'start': 0, 'end': 12, 'username': 'carlesen...</td>\n",
       "      <td>(0, 0, 7, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29860</th>\n",
       "      <td>2021-11-05 15:55:58+00:00</td>\n",
       "      <td>Coño vi Dune y me pareció un Star Wars aburrid...</td>\n",
       "      <td>6.917859e+07</td>\n",
       "      <td>1.456652e+18</td>\n",
       "      <td>01a9a39529b27f36</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>(0, 0, 2, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235543</th>\n",
       "      <td>2021-10-30 17:57:49+00:00</td>\n",
       "      <td>Mi cuerpo me odia , onda me siento como el ogt...</td>\n",
       "      <td>1.367898e+09</td>\n",
       "      <td>1.454508e+18</td>\n",
       "      <td>0108c69f708ae783</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>(0, 0, 0, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212760</th>\n",
       "      <td>2021-10-28 19:47:00+00:00</td>\n",
       "      <td>Me acuerdo de ese día y la cachetada que lleva...</td>\n",
       "      <td>8.200432e+17</td>\n",
       "      <td>1.453811e+18</td>\n",
       "      <td>0016b0ca4701a899</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>(0, 0, 0, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498199</th>\n",
       "      <td>2021-11-05 00:20:11+00:00</td>\n",
       "      <td>@leuryma16 Dato las estrellas en hollywood tu ...</td>\n",
       "      <td>5.285408e+07</td>\n",
       "      <td>1.456416e+18</td>\n",
       "      <td>01fcc4a23f17e1ed</td>\n",
       "      <td>['1456413208034652163']</td>\n",
       "      <td>[{'start': 0, 'end': 10, 'username': 'leuryma1...</td>\n",
       "      <td>(0, 1, 1, 0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at  \\\n",
       "411680  2021-11-05 05:11:21+00:00   \n",
       "29860   2021-11-05 15:55:58+00:00   \n",
       "235543  2021-10-30 17:57:49+00:00   \n",
       "212760  2021-10-28 19:47:00+00:00   \n",
       "498199  2021-11-05 00:20:11+00:00   \n",
       "\n",
       "                                                text_orig     author_id  \\\n",
       "411680  @carlesenric @Macarena_Olona @ElsaGarciad no c...  2.556683e+08   \n",
       "29860   Coño vi Dune y me pareció un Star Wars aburrid...  6.917859e+07   \n",
       "235543  Mi cuerpo me odia , onda me siento como el ogt...  1.367898e+09   \n",
       "212760  Me acuerdo de ese día y la cachetada que lleva...  8.200432e+17   \n",
       "498199  @leuryma16 Dato las estrellas en hollywood tu ...  5.285408e+07   \n",
       "\n",
       "            tweet_id    tweet_place_id        referenced_tweets  \\\n",
       "411680  1.456489e+18  cbdb0e7018443220  ['1456402105124675586']   \n",
       "29860   1.456652e+18  01a9a39529b27f36                     <NA>   \n",
       "235543  1.454508e+18  0108c69f708ae783                     <NA>   \n",
       "212760  1.453811e+18  0016b0ca4701a899                     <NA>   \n",
       "498199  1.456416e+18  01fcc4a23f17e1ed  ['1456413208034652163']   \n",
       "\n",
       "                                                 mentions  \\\n",
       "411680  [{'start': 0, 'end': 12, 'username': 'carlesen...   \n",
       "29860                                                <NA>   \n",
       "235543                                               <NA>   \n",
       "212760                                               <NA>   \n",
       "498199  [{'start': 0, 'end': 10, 'username': 'leuryma1...   \n",
       "\n",
       "       retweet_reply_like_quote  \n",
       "411680             (0, 0, 7, 0)  \n",
       "29860              (0, 0, 2, 0)  \n",
       "235543             (0, 0, 0, 0)  \n",
       "212760             (0, 0, 0, 0)  \n",
       "498199             (0, 1, 1, 0)  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = tweets.sample(1000, random_state=1)\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd134cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved dataframe (tweets-processed-0.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-1.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-2.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-3.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-4.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-5.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-6.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-7.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-8.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-9.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-10.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-11.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-12.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-13.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-14.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-15.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-16.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-17.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-18.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-19.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-20.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-21.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-22.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-23.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-24.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-25.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-26.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-27.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-28.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-29.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-30.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-31.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-32.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-33.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-34.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-35.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-36.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-37.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-38.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-39.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-40.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-41.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-42.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved dataframe (tweets-processed-43.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-44.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-45.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-46.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-47.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-48.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-49.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-50.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-51.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-52.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-53.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-54.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-55.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-56.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-57.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-58.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-59.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-60.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-61.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-62.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-63.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-64.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-65.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-66.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-67.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-68.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-69.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-70.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-71.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-72.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-73.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-74.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-75.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-76.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-77.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-78.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-79.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-80.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-81.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-82.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-83.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-84.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-85.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved dataframe (tweets-processed-86.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-87.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-88.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-89.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-90.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-91.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-92.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-93.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-94.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-95.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-96.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-97.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-98.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-99.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-100.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-101.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-102.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-103.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-104.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-105.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-106.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-107.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-108.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-109.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-110.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-111.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-112.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-113.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-114.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-115.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-116.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-117.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-118.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-119.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-120.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-121.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-122.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-123.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-124.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-125.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-126.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-127.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-128.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved dataframe (tweets-processed-129.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-130.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-131.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-132.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-133.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-134.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-135.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-136.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-137.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-138.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-139.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-140.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-141.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-142.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-143.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-144.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-145.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-146.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-147.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-148.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-149.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-150.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-151.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-152.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-153.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-154.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-155.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-156.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-157.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-158.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-159.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-160.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-161.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-162.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-163.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-164.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-165.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-166.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-167.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-168.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-169.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-170.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-171.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved dataframe (tweets-processed-172.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-173.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-174.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-175.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-176.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-177.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-178.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-179.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-180.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-181.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-182.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-183.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-184.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-185.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-186.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-187.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-188.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-189.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-190.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-191.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-192.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-193.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-194.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-195.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-196.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-197.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-198.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-199.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-200.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-201.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-202.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-203.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-204.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-205.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-206.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-207.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-208.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-209.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-210.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-211.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-212.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-213.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-214.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved dataframe (tweets-processed-215.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-216.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-217.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-218.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-219.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-220.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-221.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-222.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-223.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-224.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-225.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-226.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-227.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-228.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n",
      "INFO:root:Saved dataframe (tweets-processed-229.csv) CSV into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-03-08 15:15:06/combined-2021-07-26-and-11-07\n"
     ]
    }
   ],
   "source": [
    "keep_cols = ['tweet_id', 'created_at', 'author_id', 'tweet_place_id']\n",
    "\n",
    "batch_size = 500\n",
    "batches = int(np.ceil(tweets.shape[0]/batch_size))\n",
    "\n",
    "for i, data in enumerate(np.array_split(tweets.loc[:, ['tweet_id', 'text_orig', 'created_at', 'author_id', 'tweet_place_id']], batches)):\n",
    "    file_name = f'tweets-processed-{i}'\n",
    "    \n",
    "    procd = [pd.concat([data.loc[:, keep_cols], \n",
    "                    data.loc[:, 'text_orig'].apply(nlp_es)], \n",
    "                    axis=1)]\n",
    "    save_batch(procd, file_path=save_path, file_name=file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf0fd94",
   "metadata": {},
   "source": [
    "### Merging Processed Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb4e0a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'twitter_connection.util.utils' from '/home/rimov/Documents/Code/NLP/lin-que-dropping/processing/../twitter-connection/util/utils.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b330211",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tweets_path = Path(es_save_path).rglob('*processed*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1fdc365",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36084/1868410355.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprocessed_tweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocessed_tweets_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \"\"\"\n\u001b[0;32m--> 274\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "processed_tweets = pd.concat([utils.get_csv(p) for p in processed_tweets_path]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "29c5da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_processed = []\n",
    "processed = 0\n",
    "saved = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ad818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_batch(spacy_processed, save_path, f'tweets-processed-{saved}')\n",
    "saved+=1\n",
    "            \n",
    "spacy_processed.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f47fbb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 298492 entries, 0 to 298491\n",
      "Data columns (total 4 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   verbs               298492 non-null  string \n",
      " 1   tweet_id            298492 non-null  float64\n",
      " 2   dependencies        298492 non-null  string \n",
      " 3   lemma_pos_stopword  298492 non-null  string \n",
      "dtypes: float64(1), string(3)\n",
      "memory usage: 9.1 MB\n"
     ]
    }
   ],
   "source": [
    "processed_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71868a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "err = 0\n",
    "batch_size = 500\n",
    "batches = int(np.ceil(tweets.shape[0]/batch_size))\n",
    "\n",
    "logger.info(f'Running {tweets.shape[0]-processed} tweets through spaCy pipeline')\n",
    "logger.debug(f'Batch size: {batch_size}, batches: {batches}')\n",
    "\n",
    "for i, d in enumerate(np.array_split(tweets.loc[:, ['tweet_id', 'text_orig']], batches)):\n",
    "    # Tweets already processed\n",
    "    if i*batch_size < processed:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        spacy_processed.append(\n",
    "            pd.concat([d['tweet_id'], d['text_norm'].apply(nlp_es)], \n",
    "                      axis=1))\n",
    "        \n",
    "        processed+=batch_size\n",
    "        logger.debug(f'Processed: {processed}')\n",
    "        \n",
    "        if (processed%10000)<batch_size:\n",
    "            logger.debug(f'Saving batch of {sum([p.shape[0] for p in spacy_processed])}')\n",
    "            # Save progress and free up memory\n",
    "            save_batch(spacy_processed, name=f'tweets-processed-{saved}')\n",
    "            saved+=1\n",
    "            \n",
    "            spacy_processed.clear()\n",
    "\n",
    "    except Exception as e:\n",
    "        err+=1\n",
    "        print(f'{i} is broken: {e.args}')\n",
    "        \n",
    "        if err>2:\n",
    "            break\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f0a5ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 298492 entries, 0 to 298491\n",
      "Data columns (total 13 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   verbs                     298492 non-null  string \n",
      " 1   tweet_id                  298492 non-null  float64\n",
      " 2   dependencies              298492 non-null  string \n",
      " 3   lemma_pos_stopword        298492 non-null  string \n",
      " 4   created_at                298492 non-null  object \n",
      " 5   text_orig                 298492 non-null  object \n",
      " 6   author_id                 298492 non-null  float64\n",
      " 7   lang                      298492 non-null  object \n",
      " 8   tweet_place_id            298491 non-null  object \n",
      " 9   referenced_tweets         180174 non-null  object \n",
      " 10  mentions                  185057 non-null  object \n",
      " 11  text_norm                 298492 non-null  object \n",
      " 12  retweet_reply_like_quote  298492 non-null  object \n",
      "dtypes: float64(2), object(8), string(3)\n",
      "memory usage: 31.9+ MB\n"
     ]
    }
   ],
   "source": [
    "merged = pd.merge(processed_tweets, tweets, how='left', on='tweet_id')\n",
    "merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0c68f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename any misnamed columns\n",
    "merged.rename(columns={'author_id': 'user_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a46b181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 298492 entries, 0 to 298491\n",
      "Data columns (total 12 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   tweet_id                  298492 non-null  float64\n",
      " 1   verbs                     298492 non-null  string \n",
      " 2   text_orig                 298492 non-null  object \n",
      " 3   text_norm                 298492 non-null  object \n",
      " 4   dependencies              298492 non-null  string \n",
      " 5   lemma_pos_stopword        298492 non-null  string \n",
      " 6   retweet_reply_like_quote  298492 non-null  object \n",
      " 7   created_at                298492 non-null  object \n",
      " 8   user_id                   298492 non-null  float64\n",
      " 9   tweet_place_id            298491 non-null  object \n",
      " 10  mentions                  185057 non-null  object \n",
      " 11  referenced_tweets         180174 non-null  object \n",
      "dtypes: float64(2), object(7), string(3)\n",
      "memory usage: 29.6+ MB\n"
     ]
    }
   ],
   "source": [
    "merged = merged.loc[:, conf['col_order']]\n",
    "merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4395a259",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_csv(es_save_path, merged, 'tweets-processed-combined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32fe979",
   "metadata": {},
   "source": [
    "### Breaking Up by Verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14d27d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'processing' from '/home/rimov/Documents/Code/NLP/lin-que-dropping/src/analysis/processing/processing.py'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd02df93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Opened config file at: /home/rimov/Documents/Code/NLP/lin-que-dropping/config/general_config.yml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verbs</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text_orig</th>\n",
       "      <th>normalized</th>\n",
       "      <th>has_ccomp</th>\n",
       "      <th>dependencies</th>\n",
       "      <th>pos</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ver, querer</td>\n",
       "      <td>1.419695e+18</td>\n",
       "      <td>@MicaaFerreiraa Si, si se puede! Quiero ver ju...</td>\n",
       "      <td>@micaaferreiraa si, si se puede! QUIERO VER j...</td>\n",
       "      <td>True</td>\n",
       "      <td>@micaaferreiraa[ROOT] si[ROOT] , si[mark] se[...</td>\n",
       "      <td>@MicaaFerreiraa(PROPN) Si(INTJ) si(SCONJ) se(P...</td>\n",
       "      <td>&lt;@MicaaFerreiraa&gt;(@micaaferreiraa,False) &lt;Si&gt;(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ver</td>\n",
       "      <td>1.419695e+18</td>\n",
       "      <td>Nunca he escuchado ninguna otra nacionalidad d...</td>\n",
       "      <td>nunca he escuchado ninguna otra nacionalidad ...</td>\n",
       "      <td>False</td>\n",
       "      <td>nunca[advmod] he[aux] escuchado[ROOT] ninguna...</td>\n",
       "      <td>Nunca(ADV) he(AUX) escuchado(VERB) ninguna(DET...</td>\n",
       "      <td>&lt;Nunca&gt;(nunca,True) &lt;he&gt;(haber,True) &lt;escuchad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         verbs      tweet_id  \\\n",
       "0  ver, querer  1.419695e+18   \n",
       "1          ver  1.419695e+18   \n",
       "\n",
       "                                           text_orig  \\\n",
       "0  @MicaaFerreiraa Si, si se puede! Quiero ver ju...   \n",
       "1  Nunca he escuchado ninguna otra nacionalidad d...   \n",
       "\n",
       "                                          normalized  has_ccomp  \\\n",
       "0   @micaaferreiraa si, si se puede! QUIERO VER j...       True   \n",
       "1   nunca he escuchado ninguna otra nacionalidad ...      False   \n",
       "\n",
       "                                        dependencies  \\\n",
       "0   @micaaferreiraa[ROOT] si[ROOT] , si[mark] se[...   \n",
       "1   nunca[advmod] he[aux] escuchado[ROOT] ninguna...   \n",
       "\n",
       "                                                 pos  \\\n",
       "0  @MicaaFerreiraa(PROPN) Si(INTJ) si(SCONJ) se(P...   \n",
       "1  Nunca(ADV) he(AUX) escuchado(VERB) ninguna(DET...   \n",
       "\n",
       "                                             details  \n",
       "0  <@MicaaFerreiraa>(@micaaferreiraa,False) <Si>(...  \n",
       "1  <Nunca>(nunca,True) <he>(haber,True) <escuchad...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = utils.get_save_path('p', 'twitter', lang='es')/'2022-02-08 16:34:36'/'20210726'/'acordar'/'sample-acordar-tweets-processed.csv'\n",
    "save_path = data_path.parent\n",
    "data = utils.get_csv('twitter', data_path)\n",
    "\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d475b442",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting save of 20945 entries into /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar\n",
      "DEBUG:root:Separating by verbs: \n",
      "{'confesar', 'gritar', 'considerar', 'lamentar', 'saber', 'comprobar', 'conseguir', 'recordar', 'ordenar', 'entender', 'asegurar', 'acordar', 'pensar', 'ver', 'admitir', 'sentir', 'mostrar', 'recomendar', 'desear', 'afirmar', 'rogar', 'solicitar', 'confirmar', 'jurar', 'suspirar', 'creer', 'predecir', 'imaginar', 'querer', 'parecer', 'demostrar', 'pedir', 'negar', 'mencionar', 'ojala', 'mandar', 'prometer', 'suplicar', 'dudar', 'contar', 'responder', 'prever', 'temer', 'suponer', 'apostar', 'reclamar', 'decir', 'lograr', 'esperar', 'adivinar'}\n",
      "DEBUG:root:Saving 31 entries of (confesar)\n",
      "INFO:root:Saved dataframe (twitter-es-confesar-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/stative\n",
      "DEBUG:root:Saving 102 entries of (gritar)\n",
      "INFO:root:Saved dataframe (twitter-es-gritar-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/stative\n",
      "DEBUG:root:Saving 108 entries of (considerar)\n",
      "INFO:root:Saved dataframe (twitter-es-considerar-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/stative\n",
      "DEBUG:root:Saving 63 entries of (lamentar)\n",
      "INFO:root:Saved dataframe (twitter-es-lamentar-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/epistemic\n",
      "DEBUG:root:Saving 2330 entries of (saber)\n",
      "INFO:root:Saved dataframe (twitter-es-saber-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/epistemic\n",
      "DEBUG:root:Saving 19 entries of (comprobar)\n",
      "INFO:root:Saved dataframe (twitter-es-comprobar-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/epistemic\n",
      "DEBUG:root:Saving 223 entries of (conseguir)\n",
      "INFO:root:Saved dataframe (twitter-es-conseguir-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/stative\n",
      "DEBUG:root:Saving 447 entries of (recordar)\n",
      "INFO:root:Saved dataframe (twitter-es-recordar-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/epistemic\n",
      "DEBUG:root:Saving 36 entries of (ordenar)\n",
      "INFO:root:Saved dataframe (twitter-es-ordenar-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/volitional\n",
      "DEBUG:root:Saving 893 entries of (entender)\n",
      "INFO:root:Saved dataframe (twitter-es-entender-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/epistemic\n",
      "DEBUG:root:Saving 59 entries of (asegurar)\n",
      "INFO:root:Saved dataframe (twitter-es-asegurar-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/stative\n",
      "DEBUG:root:Saving 232 entries of (acordar)\n",
      "INFO:root:Saved dataframe (twitter-es-acordar-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/epistemic\n",
      "DEBUG:root:Saving 1237 entries of (pensar)\n",
      "INFO:root:Saved dataframe (twitter-es-pensar-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/epistemic\n",
      "DEBUG:root:Saving 5132 entries of (ver)\n",
      "INFO:root:Saved dataframe (twitter-es-ver-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/stative\n",
      "DEBUG:root:Saving 31 entries of (admitir)\n",
      "INFO:root:Saved dataframe (twitter-es-admitir-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/stative\n",
      "DEBUG:root:Saving 931 entries of (sentir)\n",
      "INFO:root:Saved dataframe (twitter-es-sentir-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/epistemic\n",
      "DEBUG:root:Saving 162 entries of (mostrar)\n",
      "INFO:root:Saved dataframe (twitter-es-mostrar-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/stative\n",
      "DEBUG:root:Saving 92 entries of (recomendar)\n",
      "INFO:root:Saved dataframe (twitter-es-recomendar-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/epistemic\n",
      "DEBUG:root:Saving 241 entries of (desear)\n",
      "INFO:root:Saved dataframe (twitter-es-desear-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/volitional\n",
      "DEBUG:root:Saving 22 entries of (afirmar)\n",
      "INFO:root:Saved dataframe (twitter-es-afirmar-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/stative\n",
      "DEBUG:root:Saving 26 entries of (rogar)\n",
      "INFO:root:Saved dataframe (twitter-es-rogar-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/volitional\n",
      "DEBUG:root:Saving 55 entries of (solicitar)\n",
      "INFO:root:Saved dataframe (twitter-es-solicitar-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/volitional\n",
      "DEBUG:root:Saving 56 entries of (confirmar)\n",
      "INFO:root:Saved dataframe (twitter-es-confirmar-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/stative\n",
      "DEBUG:root:Saving 105 entries of (jurar)\n",
      "INFO:root:Saved dataframe (twitter-es-jurar-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/stative\n",
      "DEBUG:root:Saving 2 entries of (suspirar)\n",
      "INFO:root:Saved dataframe (twitter-es-suspirar-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/stative\n",
      "DEBUG:root:Saving 1756 entries of (creer)\n",
      "INFO:root:Saved dataframe (twitter-es-creer-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/epistemic\n",
      "DEBUG:root:Saving 5 entries of (predecir)\n",
      "INFO:root:Saved dataframe (twitter-es-predecir-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/epistemic\n",
      "DEBUG:root:Saving 236 entries of (imaginar)\n",
      "INFO:root:Saved dataframe (twitter-es-imaginar-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/epistemic\n",
      "DEBUG:root:Saving 3401 entries of (querer)\n",
      "INFO:root:Saved dataframe (twitter-es-querer-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/volitional\n",
      "DEBUG:root:Saving 938 entries of (parecer)\n",
      "INFO:root:Saved dataframe (twitter-es-parecer-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/epistemic\n",
      "DEBUG:root:Saving 190 entries of (demostrar)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved dataframe (twitter-es-demostrar-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/stative\n",
      "DEBUG:root:Saving 799 entries of (pedir)\n",
      "INFO:root:Saved dataframe (twitter-es-pedir-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/volitional\n",
      "DEBUG:root:Saving 118 entries of (negar)\n",
      "INFO:root:Saved dataframe (twitter-es-negar-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/epistemic\n",
      "DEBUG:root:Saving 84 entries of (mencionar)\n",
      "INFO:root:Saved dataframe (twitter-es-mencionar-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/stative\n",
      "DEBUG:root:Saving 0 entries of (ojala)\n",
      "INFO:root:Saved dataframe (twitter-es-ojala-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/volitional\n",
      "DEBUG:root:Saving 626 entries of (mandar)\n",
      "INFO:root:Saved dataframe (twitter-es-mandar-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/volitional\n",
      "DEBUG:root:Saving 76 entries of (prometer)\n",
      "INFO:root:Saved dataframe (twitter-es-prometer-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/stative\n",
      "DEBUG:root:Saving 3 entries of (suplicar)\n",
      "INFO:root:Saved dataframe (twitter-es-suplicar-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/volitional\n",
      "DEBUG:root:Saving 101 entries of (dudar)\n",
      "INFO:root:Saved dataframe (twitter-es-dudar-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/epistemic\n",
      "DEBUG:root:Saving 388 entries of (contar)\n",
      "INFO:root:Saved dataframe (twitter-es-contar-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/stative\n",
      "DEBUG:root:Saving 262 entries of (responder)\n",
      "INFO:root:Saved dataframe (twitter-es-responder-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/stative\n",
      "DEBUG:root:Saving 7 entries of (prever)\n",
      "INFO:root:Saved dataframe (twitter-es-prever-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/epistemic\n",
      "DEBUG:root:Saving 60 entries of (temer)\n",
      "INFO:root:Saved dataframe (twitter-es-temer-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/epistemic\n",
      "DEBUG:root:Saving 134 entries of (suponer)\n",
      "INFO:root:Saved dataframe (twitter-es-suponer-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/stative\n",
      "DEBUG:root:Saving 68 entries of (apostar)\n",
      "INFO:root:Saved dataframe (twitter-es-apostar-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/epistemic\n",
      "DEBUG:root:Saving 87 entries of (reclamar)\n",
      "INFO:root:Saved dataframe (twitter-es-reclamar-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/stative\n",
      "DEBUG:root:Saving 4312 entries of (decir)\n",
      "INFO:root:Saved dataframe (twitter-es-decir-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/stative\n",
      "DEBUG:root:Saving 270 entries of (lograr)\n",
      "INFO:root:Saved dataframe (twitter-es-lograr-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/stative\n",
      "DEBUG:root:Saving 1167 entries of (esperar)\n",
      "INFO:root:Saved dataframe (twitter-es-esperar-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/volitional\n",
      "DEBUG:root:Saving 13 entries of (adivinar)\n",
      "INFO:root:Saved dataframe (twitter-es-adivinar-2022-02-09 01:46:50) xlsx into: /home/rimov/Documents/Code/NLP/lin-que-dropping/data/processed/saved/twitter/es/2022-02-08 16:34:36/20210726/acordar/epistemic\n"
     ]
    }
   ],
   "source": [
    "processing.save_by_verb(data, 'twitter', es_conj_path, save_path, 'excel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9daffb5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>verbs</th>\n",
       "      <th>text_orig</th>\n",
       "      <th>text_norm</th>\n",
       "      <th>dependencies</th>\n",
       "      <th>lemma_pos_stopword</th>\n",
       "      <th>retweet_reply_like_quote</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet_place_id</th>\n",
       "      <th>mentions</th>\n",
       "      <th>referenced_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.451193e+18</td>\n",
       "      <td>[sentir, pedir]</td>\n",
       "      <td>.@CitroenEspana Cactus con 5,5 años. Me empiez...</td>\n",
       "      <td>.Cactus con 5,5 anos. Me empieza a salir oxido...</td>\n",
       "      <td>.Cactus(ROOT) con(case) 5,5(nummod) anos(nmod)...</td>\n",
       "      <td>.Cactus(.Cactus|PROPN|False) con(con|ADP|True)...</td>\n",
       "      <td>(1, 1, 1, 0)</td>\n",
       "      <td>2021-10-21 14:26:05+00:00</td>\n",
       "      <td>3.979609e+08</td>\n",
       "      <td>731c9d11275a5436</td>\n",
       "      <td>[{'start': 1, 'end': 15, 'username': 'CitroenE...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.451193e+18</td>\n",
       "      <td>[sentir]</td>\n",
       "      <td>Me toy bebiendo un té, y siento como que toy s...</td>\n",
       "      <td>Me toy bebiendo un te, y siento como que toy s...</td>\n",
       "      <td>Me(iobj) toy(ROOT) bebiendo(xcomp) un(det) te(...</td>\n",
       "      <td>Me(yo|PRON|True) toy(tar|VERB|False) bebiendo(...</td>\n",
       "      <td>(0, 1, 0, 0)</td>\n",
       "      <td>2021-10-21 14:24:35+00:00</td>\n",
       "      <td>1.238228e+18</td>\n",
       "      <td>01fcc4a23f17e1ed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.451192e+18</td>\n",
       "      <td>[sentir]</td>\n",
       "      <td>El problema más grave que tiene hoy el Maestro...</td>\n",
       "      <td>El problema mas grave que tiene hoy el Maestro...</td>\n",
       "      <td>El(det) problema(nsubj) mas(advmod) grave(amod...</td>\n",
       "      <td>El(el|DET|True) problema(problema|NOUN|False) ...</td>\n",
       "      <td>(0, 0, 0, 0)</td>\n",
       "      <td>2021-10-21 14:22:15+00:00</td>\n",
       "      <td>2.349312e+08</td>\n",
       "      <td>01d487de3c4e0807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id            verbs  \\\n",
       "0  1.451193e+18  [sentir, pedir]   \n",
       "1  1.451193e+18         [sentir]   \n",
       "2  1.451192e+18         [sentir]   \n",
       "\n",
       "                                           text_orig  \\\n",
       "0  .@CitroenEspana Cactus con 5,5 años. Me empiez...   \n",
       "1  Me toy bebiendo un té, y siento como que toy s...   \n",
       "2  El problema más grave que tiene hoy el Maestro...   \n",
       "\n",
       "                                           text_norm  \\\n",
       "0  .Cactus con 5,5 anos. Me empieza a salir oxido...   \n",
       "1  Me toy bebiendo un te, y siento como que toy s...   \n",
       "2  El problema mas grave que tiene hoy el Maestro...   \n",
       "\n",
       "                                        dependencies  \\\n",
       "0  .Cactus(ROOT) con(case) 5,5(nummod) anos(nmod)...   \n",
       "1  Me(iobj) toy(ROOT) bebiendo(xcomp) un(det) te(...   \n",
       "2  El(det) problema(nsubj) mas(advmod) grave(amod...   \n",
       "\n",
       "                                  lemma_pos_stopword retweet_reply_like_quote  \\\n",
       "0  .Cactus(.Cactus|PROPN|False) con(con|ADP|True)...             (1, 1, 1, 0)   \n",
       "1  Me(yo|PRON|True) toy(tar|VERB|False) bebiendo(...             (0, 1, 0, 0)   \n",
       "2  El(el|DET|True) problema(problema|NOUN|False) ...             (0, 0, 0, 0)   \n",
       "\n",
       "                  created_at       user_id    tweet_place_id  \\\n",
       "0  2021-10-21 14:26:05+00:00  3.979609e+08  731c9d11275a5436   \n",
       "1  2021-10-21 14:24:35+00:00  1.238228e+18  01fcc4a23f17e1ed   \n",
       "2  2021-10-21 14:22:15+00:00  2.349312e+08  01d487de3c4e0807   \n",
       "\n",
       "                                            mentions referenced_tweets  \n",
       "0  [{'start': 1, 'end': 15, 'username': 'CitroenE...               NaN  \n",
       "1                                                NaN               NaN  \n",
       "2                                                NaN               NaN  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged['verbs'] = merged['verbs'].str.split(', ')\n",
    "merged.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "67eda838",
   "metadata": {},
   "outputs": [],
   "source": [
    "for verb in es_verbs:\n",
    "    vtype = es_conjugs.loc[es_conjugs['verb']==verb, 'verb_type'].iloc[0].lower()\n",
    "    has_verb = merged['verbs'].apply(lambda verbs: True if verb in set(verbs) else False)\n",
    "\n",
    "    df = merged[has_verb].copy()\n",
    "    \n",
    "    path = utils.get_save_path('p', lang='es')/processed_folder/vtype\n",
    "    \n",
    "    utils.make_dir(path)\n",
    "    utils.save_excel(path, df, f'twitter-es-{verb}-26-07-2021')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
