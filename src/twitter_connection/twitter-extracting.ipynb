{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c31d8097",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "<ul>\n",
    "    <li>Trending twitter<br></li>\n",
    "    https://twitter-trends.iamrohit.in/\n",
    "    <li>Removing accented characters<br></li>\n",
    "    https://stackoverflow.com/a/2633310/13557629\n",
    "    <li>Importing package from filepath</li>\n",
    "    https://stackoverflow.com/a/50395128/13557629\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "refined-cedar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "console.log('Starting front end url_querystring_target comm target');\n",
       "const comm = Jupyter.notebook.kernel.comm_manager.new_comm('url_querystring_target', {'init': 1});\n",
       "comm.send({'ipyparams_browser_url': window.location.href});\n",
       "console.log('Sent window.location.href on url_querystring_target comm target');\n",
       "\n",
       "comm.on_msg(function(msg) {\n",
       "    console.log(msg.content.data);\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipyparams\n",
    "import regex as re\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from importlib import reload\n",
    "import connection\n",
    "from datetime import datetime\n",
    "import utils\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ad1e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.setup_logger(\n",
    "    file_name='updating-extraction', \n",
    "    desc='Preparing extraction code for packaging. Moving as much of notebook code to modules as possible and documenting for ease of use for future users'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2ef280f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'connection' from '/home/rimov/Documents/Code/NLP/lin-que-dropping/src/twitter_connection/connection.py'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5314498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_conf = utils.get_config()\n",
    "conf = utils.get_config('e')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bd545c",
   "metadata": {},
   "source": [
    "### Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec9794d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The passed key name was not found: ('riccelli_key not found. Declare it as envvar or define a default value.',)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rimov/Documents/Code/NLP/lin-que-dropping/src/twitter_connection/connection.py\", line 59, in auth\n",
      "    token = key if key is not None else config(env_key_name)\n",
      "  File \"/home/rimov/anaconda3/envs/que_drop/lib/python3.10/site-packages/decouple.py\", line 245, in __call__\n",
      "    return self.config(*args, **kwargs)\n",
      "  File \"/home/rimov/anaconda3/envs/que_drop/lib/python3.10/site-packages/decouple.py\", line 107, in __call__\n",
      "    return self.get(*args, **kwargs)\n",
      "  File \"/home/rimov/anaconda3/envs/que_drop/lib/python3.10/site-packages/decouple.py\", line 92, in get\n",
      "    raise UndefinedValueError('{} not found. Declare it as envvar or define a default value.'.format(option))\n",
      "decouple.UndefinedValueError: riccelli_key not found. Declare it as envvar or define a default value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "riccelli_key\n"
     ]
    }
   ],
   "source": [
    "# TODO: key_name not working properly; python-decouple not finding .env file\n",
    "#   potentially because it's looking in a different directory\n",
    "es_conn = connection.TwitterConnection(\n",
    "    lang='es',\n",
    "    is_archive=True,\n",
    "    key_name='riccelli'\n",
    ")\n",
    "\n",
    "# pt_conn = connection.TwitterConnection() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12cb68c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conjugations = pd.read_csv(utils.get_project_root()/'data'/'twitter-conjugations-query.csv')\n",
    "conjugations = conjugations.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0630bee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of verbs that shouldn't be pulled\n",
    "finished = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0531ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = utils.get_str_datetime_now(True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f11486b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved total 4 pages for mencionar.\n",
      "Retrieved total 6 pages for gritar.\n",
      "Retrieved total 0 pages for suspirar.\n",
      "Retrieved total 4 pages for reclamar.\n",
      "Retrieved total 20 pages for contar.\n",
      "Retrieved total 20 pages for suponer.\n",
      "Retrieved total 20 pages for saber.\n",
      "Retrieved total 20 pages for pensar.\n",
      "Retrieved total 17 pages for imaginar.\n",
      "Retrieved total 20 pages for dudar.\n",
      "Retrieved total 20 pages for creer.\n",
      "Retrieved total 20 pages for recordar.\n",
      "Retrieved total 20 pages for acordar.\n",
      "Retrieved total 2 pages for temer.\n",
      "Retrieved total 8 pages for recomendar.\n",
      "Retrieved total 20 pages for parecer.\n",
      "Retrieved total 20 pages for entender.\n",
      "Retrieved total 5 pages for negar.\n",
      "Retrieved total 4 pages for apostar.\n",
      "Retrieved total 0 pages for predecir.\n",
      "Retrieved total 1 pages for prever.\n",
      "Retrieved total 20 pages for sentir.\n",
      "Retrieved total 2 pages for comprobar.\n",
      "Retrieved total 1 pages for adivinar.\n",
      "Retrieved total 3 pages for lamentar.\n",
      "Retrieved total 1 pages for rogar.\n",
      "Retrieved total 20 pages for querer.\n",
      "Retrieved total 20 pages for esperar.\n",
      "Retrieved total 20 pages for desear.\n",
      "Retrieved total 20 pages for pedir.\n",
      "Retrieved total 0 pages for ojala.\n",
      "Retrieved total 0 pages for suplicar.\n",
      "Retrieved total 2 pages for solicitar.\n",
      "Retrieved total 20 pages for mandar.\n",
      "Retrieved total 2 pages for ordenar.\n"
     ]
    }
   ],
   "source": [
    "save_path = utils.make_dir(\n",
    "    utils.get_save_path('e', 'twitter', False, 'es'), time \n",
    ")\n",
    "\n",
    "for i, topic in enumerate(conjugations):\n",
    "    # Skip verbs that were already pulled or are not desired\n",
    "    if topic['verb'] in finished:\n",
    "        continue\n",
    "    \n",
    "    pages = es_conn.paginate(save_path, \n",
    "                             (topic['verb'], topic['indicativo']), \n",
    "                             batch_size=500,\n",
    "                             batch_num=20,\n",
    "                             sleep_sec=1)\n",
    "    \n",
    "    print(f'Retrieved total {pages} pages for {topic[\"verb\"]}.')\n",
    "    \n",
    "    finished.append(topic['verb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f255e71f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
